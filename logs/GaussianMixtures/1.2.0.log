 Resolving package versions...
 Installed DataAPI ──────────── v1.1.0
 Installed GaussianMixtures ─── v0.3.0
 Installed Missings ─────────── v0.4.3
 Installed PDMats ───────────── v0.9.10
 Installed FileIO ───────────── v1.0.7
 Installed NearestNeighbors ─── v0.4.3
 Installed BinaryProvider ───── v0.5.8
 Installed StatsBase ────────── v0.32.0
 Installed URIParser ────────── v0.4.0
 Installed Blosc ────────────── v0.5.1
 Installed Rmath ────────────── v0.5.1
 Installed JLD ──────────────── v0.9.1
 Installed ScikitLearnBase ──── v0.5.0
 Installed StatsFuns ────────── v0.9.0
 Installed HDF5 ─────────────── v0.12.5
 Installed Compat ───────────── v2.2.0
 Installed OrderedCollections ─ v1.1.0
 Installed CMake ────────────── v1.1.2
 Installed DataStructures ───── v0.17.6
 Installed QuadGK ───────────── v2.1.1
 Installed Parameters ───────── v0.12.0
 Installed StaticArrays ─────── v0.12.1
 Installed SortingAlgorithms ── v0.3.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed Distances ────────── v0.8.2
 Installed Distributions ────── v0.21.8
 Installed SpecialFunctions ─── v0.8.0
 Installed BinDeps ──────────── v0.8.10
 Installed LegacyStrings ────── v0.4.1
 Installed Clustering ───────── v0.13.3
 Installed Arpack ───────────── v0.3.1
  Updating `~/.julia/environments/v1.2/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.2/Manifest.toml`
  [7d9fca2a] + Arpack v0.3.1
  [9e28174c] + BinDeps v0.8.10
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.8
  [5789e2e9] + FileIO v1.0.7
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.3
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.1.1
  [79098fc4] + Rmath v0.5.1
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.8.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.0
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake ───────────→ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc ───────────→ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 ────────────→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Building Rmath ───────────→ `~/.julia/packages/Rmath/4wt82/deps/build.log`
  Building SpecialFunctions → `~/.julia/packages/SpecialFunctions/ne2iw/deps/build.log`
  Building Arpack ──────────→ `~/.julia/packages/Arpack/cu5By/deps/build.log`
   Testing GaussianMixtures
    Status `/tmp/jl_zt2RbN/Manifest.toml`
  [7d9fca2a] Arpack v0.3.1
  [9e28174c] BinDeps v0.8.10
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.8
  [5789e2e9] FileIO v1.0.7
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.3
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.1.1
  [79098fc4] Rmath v0.5.1
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.8.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.0
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -761191.2106813154, [68121.27765917926, 31878.72234082074], [-6966.296999439288 -932.0013104066975 -5076.340796616561; 6943.434189374497 1359.6672974372925 5124.586088157055], Array{Float64,2}[[70598.46211462152 6244.474314735143 6650.908225904578; 6244.474314735145 91360.66447072447 6226.180444579147; 6650.908225904577 6226.180444579147 51811.09983495447], [29365.02828500796 -6154.675734336827 -7279.370037253707; -6154.675734336827 8351.720303487433 -6502.1879243508; -7279.370037253707 -6502.1879243508 48077.46905875519]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.2/Distributed/src/cluster.jl:1005
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       2.675080e+03
      1       1.555168e+03      -1.119912e+03 |        8
      2       1.377874e+03      -1.772939e+02 |        8
      3       1.233341e+03      -1.445329e+02 |        6
      4       1.098628e+03      -1.347128e+02 |        6
      5       9.966686e+02      -1.019596e+02 |        5
      6       9.021666e+02      -9.450197e+01 |        6
      7       8.594707e+02      -4.269588e+01 |        2
      8       8.525982e+02      -6.872492e+00 |        3
      9       8.441928e+02      -8.405457e+00 |        0
     10       8.441928e+02       0.000000e+00 |        0
K-means converged with 10 iterations (objv = 844.1927848174673)
┌ Info: K-means with 272 data points using 10 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.058483
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:625 [inlined]
└ @ Core ./broadcast.jl:625
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:625 [inlined]
└ @ Core ./broadcast.jl:625
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:625 [inlined]
└ @ Core ./broadcast.jl:625
[ Info: iteration 1, lowerbound -3.841633
[ Info: iteration 2, lowerbound -3.760648
[ Info: iteration 3, lowerbound -3.673402
[ Info: iteration 4, lowerbound -3.560586
[ Info: iteration 5, lowerbound -3.425188
[ Info: iteration 6, lowerbound -3.278137
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.121268
[ Info: iteration 8, lowerbound -2.956804
[ Info: dropping number of Gaussions to 6
[ Info: iteration 9, lowerbound -2.793405
[ Info: iteration 10, lowerbound -2.646529
[ Info: dropping number of Gaussions to 5
[ Info: iteration 11, lowerbound -2.535225
[ Info: dropping number of Gaussions to 4
[ Info: iteration 12, lowerbound -2.452804
[ Info: iteration 13, lowerbound -2.397300
[ Info: dropping number of Gaussions to 3
[ Info: iteration 14, lowerbound -2.360408
[ Info: iteration 15, lowerbound -2.329711
[ Info: iteration 16, lowerbound -2.311973
[ Info: iteration 17, lowerbound -2.307667
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302919
[ Info: iteration 19, lowerbound -2.299260
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: 47 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sat Nov 23 23:32:28 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sat Nov 23 23:32:35 2019: K-means with 272 data points using 10 iterations
11.3 data points per parameter
, Sat Nov 23 23:32:36 2019: EM with 272 data points 0 iterations avll -2.058483
5.8 data points per parameter
, Sat Nov 23 23:32:38 2019: GMM converted to Variational GMM
, Sat Nov 23 23:32:45 2019: iteration 1, lowerbound -3.841633
, Sat Nov 23 23:32:45 2019: iteration 2, lowerbound -3.760648
, Sat Nov 23 23:32:45 2019: iteration 3, lowerbound -3.673402
, Sat Nov 23 23:32:45 2019: iteration 4, lowerbound -3.560586
, Sat Nov 23 23:32:45 2019: iteration 5, lowerbound -3.425188
, Sat Nov 23 23:32:45 2019: iteration 6, lowerbound -3.278137
, Sat Nov 23 23:32:46 2019: dropping number of Gaussions to 7
, Sat Nov 23 23:32:46 2019: iteration 7, lowerbound -3.121268
, Sat Nov 23 23:32:46 2019: iteration 8, lowerbound -2.956804
, Sat Nov 23 23:32:46 2019: dropping number of Gaussions to 6
, Sat Nov 23 23:32:46 2019: iteration 9, lowerbound -2.793405
, Sat Nov 23 23:32:46 2019: iteration 10, lowerbound -2.646529
, Sat Nov 23 23:32:46 2019: dropping number of Gaussions to 5
, Sat Nov 23 23:32:46 2019: iteration 11, lowerbound -2.535225
, Sat Nov 23 23:32:46 2019: dropping number of Gaussions to 4
, Sat Nov 23 23:32:46 2019: iteration 12, lowerbound -2.452804
, Sat Nov 23 23:32:46 2019: iteration 13, lowerbound -2.397300
, Sat Nov 23 23:32:46 2019: dropping number of Gaussions to 3
, Sat Nov 23 23:32:46 2019: iteration 14, lowerbound -2.360408
, Sat Nov 23 23:32:46 2019: iteration 15, lowerbound -2.329711
, Sat Nov 23 23:32:46 2019: iteration 16, lowerbound -2.311973
, Sat Nov 23 23:32:46 2019: iteration 17, lowerbound -2.307667
, Sat Nov 23 23:32:46 2019: dropping number of Gaussions to 2
, Sat Nov 23 23:32:46 2019: iteration 18, lowerbound -2.302919
, Sat Nov 23 23:32:46 2019: iteration 19, lowerbound -2.299260
, Sat Nov 23 23:32:46 2019: iteration 20, lowerbound -2.299256
, Sat Nov 23 23:32:46 2019: iteration 21, lowerbound -2.299254
, Sat Nov 23 23:32:46 2019: iteration 22, lowerbound -2.299254
, Sat Nov 23 23:32:46 2019: iteration 23, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 24, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 25, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 26, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 27, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 28, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 29, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 30, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 31, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 32, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 33, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 34, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 35, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 36, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 37, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 38, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 39, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 40, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 41, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 42, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 43, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 44, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 45, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: iteration 46, lowerbound -2.299253
, Sat Nov 23 23:32:46 2019: 47 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601484, 95.95490777398514]
β = [178.04509222601484, 95.95490777398514]
m = [4.250300733269902 79.28686694436172; 2.0002292577753624 53.85198717246126]
ν = [180.04509222601484, 97.95490777398514]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484366 -0.007644049042327276; 0.0 0.0085817051663333], [0.37587636119485557 -0.008953123827346317; 0.0 0.012748664777409421]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -0.9980627749383432
avll from llpg:  -0.9980627749383432
avll direct:     -0.9980627749383432
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9893148332049884
avll from llpg:  -0.9893148332049886
avll direct:     -0.9893148332049886
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.0235688   -0.0256469    -0.0455175   -0.0182103   -0.0948557   -0.098791    -0.143551     0.0799085    0.134243     0.102363     0.0309949  -0.0584881    -0.166794    -0.137099     0.0118686    0.0338892    0.0191656   -0.127904     0.0266754   -0.0666716  -0.0244798    -0.0443465    -0.157726     -0.24667       0.0682665   -0.0841335 
 -0.0674088   -0.0185183     0.0118633    0.0956325   -0.048251     0.147345    -0.102389     0.136895     0.00522832   0.00681588  -0.0735841  -0.000241667   0.086444     0.162336    -0.0288725    0.120484     0.179097     0.058144     0.0348909    0.0612976  -0.228321      0.107533      0.000840425   0.0866745     0.066187     0.111726  
 -0.00519648  -0.0213552    -0.0531506   -0.103912    -0.08836     -0.0574778   -0.062651     0.166978    -0.108125     0.0385002    0.0459689  -0.0607134     0.253536     0.0510401   -0.084415    -0.218616     0.0102631    0.243826     0.147823    -0.0838657   0.0941844     0.0314573     0.0979065    -0.181281      0.110992    -0.0405736 
 -0.0454156   -0.111753     -0.147989    -0.135404     0.0745043    0.120307    -0.199454    -0.0673945    0.12837     -0.0939244   -0.0770876  -0.127812      0.0229035   -0.0811894   -0.0417186   -0.0742991   -0.158164     0.0475473    0.0854611    0.0602254   0.0649731    -0.103163      0.208347     -0.0835505    -0.263371    -0.0807607 
  0.113548     0.130325      0.114871    -0.357397    -0.275174     0.0284571   -0.0183119   -0.0629823    0.157196     0.0778921   -0.0160409   0.0573306     0.0935446   -0.0550239    0.0422749   -0.0919301   -0.101671    -0.0797128   -0.159071     0.0655894   0.163747     -0.0262373     0.12988       0.113177     -0.0242597    0.0119892 
  0.0676198    0.119272     -0.129756     0.0993321    0.317584    -0.049056    -0.0312645    0.0291841    0.168895    -0.14038     -0.0293521   0.0692377     0.0542404   -0.0612478    0.0547999    0.102637     0.170404     0.0215168    0.0622559   -0.194198   -0.126137     -0.100629      0.0264697     0.00552855   -0.0342075   -0.0253469 
  0.0601645    0.136355     -0.0190875   -0.0356097    0.111108     0.0272768   -0.037957    -0.0288429    0.145102     0.0360211    0.0361063  -0.136927      0.0204495    0.0102265   -0.203016     0.174762     0.148205    -0.124579     0.0869285    0.0390606   0.212289     -0.0390688     0.0092199    -0.127916     -0.0161119   -0.235731  
 -0.143917    -0.0980103     0.0516229    0.139809    -0.135106     0.0324716   -0.169494    -0.0120378   -0.0302354    0.0541413    0.0157317  -0.00887549    0.00186103  -0.0277043    0.0146024    0.00813514  -0.0541364   -0.0702982    0.158799    -0.0928544   0.0518536    -0.0705185    -0.0540564    -0.155317      0.186439    -0.0998943 
 -0.0030257   -0.0498243     0.078866     0.193968     0.0609747   -0.157073     0.138272     0.165219     0.0858688   -0.186846    -0.0545382  -0.0547361     0.218158    -0.0213654    0.125431     0.0869657   -0.0347289    0.0898184    0.0450279   -0.0669148   0.0880038     0.152722     -0.0231001     0.0461937     0.141126    -0.0299667 
 -0.0533594   -0.0949422    -0.153419    -0.0562844    0.0205664    0.133493     0.0488868    0.00592651  -0.1102       0.0663055   -0.0983591   0.11387      -0.0486384   -0.0431786    0.107965     0.0272521    0.128308    -0.0801825    0.0704297    0.0789917  -0.088458      0.0649549    -0.0694659     0.049305     -0.0671368   -0.0642345 
 -0.140677    -0.115353      0.0347327   -0.044348     0.0381082   -0.0208833   -0.110319    -0.0807306   -0.0645928   -0.206023     0.156566    0.00793638   -0.072339    -0.00877898   0.0840613   -0.0142805    0.137129    -0.095687     0.193016     0.0054352  -0.0537503     0.0873925     0.0299351    -0.100679     -0.265907     0.00291316
  0.00278603   0.0169879    -0.068382    -0.0481968    0.197937     0.0279662    0.0186362   -0.0776152   -0.0332606    0.062405    -0.0592706   0.150327     -0.174018     0.0159949   -0.00895887  -0.0181393    0.060366    -0.0160359   -0.114151     0.0346554  -0.0787205     0.0295839    -0.0750403    -0.233605     -0.0138945   -0.0122107 
  0.0268031   -0.148511     -0.0696949    0.146907    -0.0131184    0.0423407    0.0593839    0.0445105   -0.0304022    0.129964    -0.0126298  -0.0722217     0.0809064   -0.0872924   -0.218593    -0.0333521    0.00328937  -0.148229     0.135547     0.0912321  -0.170084     -0.000874343   0.0414839     0.059884      0.00951917   0.0156423 
 -0.197374    -0.0484647    -0.105798     0.0269741    0.0414173    0.0389226    0.0677375    0.12328     -0.0338085    0.017921    -0.0244316  -0.0616321     0.177673     0.0131861    0.0361841    0.0787898   -0.291532    -0.0168942   -0.00308317   0.175949    0.0694271    -0.0632568     0.113714     -0.056614      0.104545     0.0831736 
  0.297468     0.0152368     0.0500819    0.217325     0.00111856  -0.00100173   0.140696     0.0657785   -0.0667598   -0.0792745    0.0660379  -0.0531906    -0.0879264    0.0481777   -0.198701    -0.090632    -0.071343    -0.0702027   -0.037597     0.0230766  -0.0553907    -0.0194891    -0.162122     -0.00897958   -0.133706     0.123226  
 -0.163797     0.132354      0.104889     0.0615905   -0.0858792   -0.106296     0.102126     0.0572971   -0.142041    -0.167455     0.102071    0.065864     -0.0374452   -0.0248764   -0.0568922    0.160718     0.0228557    0.133564     0.0584707   -0.0132594  -0.0317117    -0.211554     -0.0629677     0.0763162     0.00228906  -0.149049  
  0.0644445    0.000543414  -0.115717     0.0236265    0.0234438   -0.118617     0.0190789   -0.0401376   -0.0674528    0.0721136   -0.0215733  -0.196178     -0.10544     -0.156263    -0.104189     0.0370047    0.179775     0.0491328   -0.0334537    0.0478113  -0.110355     -0.072118      0.158075      0.0837365     0.101593     0.021682  
  0.209787     0.0261887    -0.145045     0.0631446    0.0940614    0.0151831    0.0349279    0.0502925    0.0935513    0.0381804   -0.046172    0.0125254    -0.0606708    0.0214865    0.115246     0.0227317    0.146618     0.0874752   -0.0748534    0.0629238  -0.0222538    -0.0741414    -0.000117126  -0.00877778    0.0102995    0.058481  
  0.0601966   -0.0555634    -0.0171946   -0.154744    -0.10674      0.133665     0.0902761   -0.275602     0.0231253    0.0104158   -0.0184971  -0.0318928     0.0492214   -0.0908302   -0.136201    -0.0877398    0.0405684    0.050082     0.117836     0.0866247  -0.124577      0.188005      0.175633      0.000587316   0.0169115    0.0658204 
  0.10921      0.00269652    0.153659     0.0626202   -0.0599662    0.085386    -0.0141325    0.0417524   -0.182804    -0.0643141    0.025322    0.0536005     0.0372678    0.044126     0.055679    -0.166813    -0.0901528    0.00388394   0.217369     0.0153876   0.06678      -0.0305645    -0.0992469    -0.0860442    -0.055156     0.105276  
 -0.0526294   -0.011716      0.316251    -0.0243948   -0.0714762   -0.0632752   -0.0603593   -0.0838782    0.066909     0.0431288   -0.0619527  -0.0178226     0.034552    -0.0315699   -0.0781419   -0.109289     0.0966375   -0.154609    -0.163382    -0.0175592  -0.0963427     0.0100125     0.128664     -0.0746034     0.0308185    0.0175122 
 -0.0763818   -0.0160177     0.0904689   -0.16025     -0.136633     0.0336373    0.113149    -0.0446195   -0.0248292    0.0423863   -0.0993227   0.0260701     0.0399833    0.0456696   -0.0518036    0.0768352   -0.0260599   -0.080546     0.186506     0.0957797   0.0606159     0.171642     -0.20084      -0.000616772  -0.0554358   -0.122704  
  0.144049     0.141954      0.165145    -0.240156     0.0438724    0.171825     0.0725875    0.00319155   0.00790141   0.0117521   -0.120186   -0.00639608   -0.0820033    0.161382     0.0277084    0.081775    -0.0279941   -0.146392     0.0914683    0.0644174   0.0595228     0.152898     -0.023833     -0.142192      0.0451446    0.0862852 
  0.0434876    0.132766      0.071393    -0.115309     0.0413481   -0.090109     0.0854936    0.122857    -0.0880442   -0.0456718    0.0923882  -0.00731053    0.0547159   -0.0174301    0.102368    -0.187425     0.0226402    0.00220783   0.145532     0.0743587  -0.0163711    -0.043929     -0.0515685     0.0606598     0.0850423    0.0971858 
  0.105798    -0.00758147   -0.205313     0.229169    -0.0859559    0.0735988   -0.0977121   -0.0579871   -0.00758113   0.0431611    0.0869716  -0.0617652    -0.00720582  -0.115361     0.075766    -0.0131288   -0.0956567    0.0449035    0.064394    -0.266618   -0.000878798   0.0935293    -0.0779666     0.0808788    -0.0990994   -0.0736669 
 -0.0305629    0.0349301     0.0540029    0.220038     0.141856     0.0459145    0.169403    -0.0346358    0.120648    -0.124347    -0.0132939  -0.0241563     0.0492153    0.0683827    0.0314707   -0.0479985    0.0762874    0.124955    -0.152533    -0.0255777  -0.117915      0.0733039     0.139691     -0.234074      0.0590569    0.0924595 
  0.0628029   -0.134636     -0.180032     0.00871067   0.0806622    0.0305139    0.0804988   -0.0235221   -0.0152776   -0.079191     0.0765374  -0.042106     -0.110801    -0.240448     0.019451    -0.0344805    0.0180909   -0.113907     0.23226      0.162472    0.0519311    -0.154289      0.0495919    -0.00802884   -0.00600465  -0.171474  
  0.0422512    0.047034     -0.0354454   -0.0879739   -0.0978514    0.0228408   -0.00921579   0.0654797    0.0722727   -0.169577    -0.0853079   0.0116422     0.0431304   -0.0548436   -0.161411    -0.197577    -0.0788801    0.0373479    0.127813    -0.0230627   0.0784198    -0.016924     -0.0308811     0.016656     -0.198543    -0.0777614 
 -0.145316    -0.145237     -0.225369     0.126379    -0.140236     0.0771037   -0.154165     0.0472984   -0.263469    -0.0351767    0.20405     0.16766      -0.123158     0.0302833   -0.253421     0.0291434    0.249906    -0.164336    -0.207127     0.128497   -0.0123792     0.00534475   -0.150977      0.0925073     0.0229139    0.0556164 
  0.0416559    0.143904      0.134439    -0.0631975   -0.101119    -0.0871525    0.00683609  -0.083262     0.044604    -0.1485       0.0682425   0.0153123     0.113401     0.0443352    0.0953611    0.0224807    0.0319184    0.124503    -0.00550009  -0.150574    0.0854277    -0.0149248     0.00471941   -0.0233101    -0.0984939    0.300459  
  0.0160694   -0.109722      0.134656     0.171188     0.150132    -0.0490491    0.039713     0.0964675   -0.0637319    0.0455473   -0.0564982   0.0583498    -0.0837023   -0.0286552    0.0985823   -0.127376    -0.0126356    0.187542    -0.0527463   -0.0667992  -0.0790089    -0.0850311     0.034583      0.174701      0.0553589    0.0482681 
  0.00512931   0.0627274    -0.00993414   0.0577851   -0.0956751    0.0644333   -0.117151    -0.0802863    0.063162     0.132219    -0.0876208  -0.0407659     0.0223948    0.118164     0.0881104   -0.0481737   -0.1005       0.0261556   -0.018139     0.105061   -0.0291672    -0.0350811     0.0580266     0.012304      0.0374738   -0.237456  kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.433980473475034
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.434107
[ Info: iteration 2, average log likelihood -1.433958
[ Info: iteration 3, average log likelihood -1.431938
[ Info: iteration 4, average log likelihood -1.416357
[ Info: iteration 5, average log likelihood -1.395353
[ Info: iteration 6, average log likelihood -1.391107
[ Info: iteration 7, average log likelihood -1.390490
[ Info: iteration 8, average log likelihood -1.390268
[ Info: iteration 9, average log likelihood -1.390151
[ Info: iteration 10, average log likelihood -1.390073
[ Info: iteration 11, average log likelihood -1.390012
[ Info: iteration 12, average log likelihood -1.389959
[ Info: iteration 13, average log likelihood -1.389908
[ Info: iteration 14, average log likelihood -1.389857
[ Info: iteration 15, average log likelihood -1.389803
[ Info: iteration 16, average log likelihood -1.389745
[ Info: iteration 17, average log likelihood -1.389683
[ Info: iteration 18, average log likelihood -1.389623
[ Info: iteration 19, average log likelihood -1.389571
[ Info: iteration 20, average log likelihood -1.389531
[ Info: iteration 21, average log likelihood -1.389500
[ Info: iteration 22, average log likelihood -1.389475
[ Info: iteration 23, average log likelihood -1.389455
[ Info: iteration 24, average log likelihood -1.389438
[ Info: iteration 25, average log likelihood -1.389424
[ Info: iteration 26, average log likelihood -1.389411
[ Info: iteration 27, average log likelihood -1.389400
[ Info: iteration 28, average log likelihood -1.389390
[ Info: iteration 29, average log likelihood -1.389382
[ Info: iteration 30, average log likelihood -1.389375
[ Info: iteration 31, average log likelihood -1.389369
[ Info: iteration 32, average log likelihood -1.389364
[ Info: iteration 33, average log likelihood -1.389359
[ Info: iteration 34, average log likelihood -1.389355
[ Info: iteration 35, average log likelihood -1.389352
[ Info: iteration 36, average log likelihood -1.389348
[ Info: iteration 37, average log likelihood -1.389345
[ Info: iteration 38, average log likelihood -1.389342
[ Info: iteration 39, average log likelihood -1.389340
[ Info: iteration 40, average log likelihood -1.389337
[ Info: iteration 41, average log likelihood -1.389334
[ Info: iteration 42, average log likelihood -1.389332
[ Info: iteration 43, average log likelihood -1.389329
[ Info: iteration 44, average log likelihood -1.389327
[ Info: iteration 45, average log likelihood -1.389324
[ Info: iteration 46, average log likelihood -1.389321
[ Info: iteration 47, average log likelihood -1.389317
[ Info: iteration 48, average log likelihood -1.389313
[ Info: iteration 49, average log likelihood -1.389309
[ Info: iteration 50, average log likelihood -1.389304
┌ Info: EM with 100000 data points 50 iterations avll -1.389304
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4341073023217072
│     -1.4339578408306393
│      ⋮                 
└     -1.389303558561133 
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.389497
[ Info: iteration 2, average log likelihood -1.389304
[ Info: iteration 3, average log likelihood -1.388482
[ Info: iteration 4, average log likelihood -1.380074
[ Info: iteration 5, average log likelihood -1.359174
[ Info: iteration 6, average log likelihood -1.347293
[ Info: iteration 7, average log likelihood -1.342355
[ Info: iteration 8, average log likelihood -1.339054
[ Info: iteration 9, average log likelihood -1.337054
[ Info: iteration 10, average log likelihood -1.335903
[ Info: iteration 11, average log likelihood -1.335273
[ Info: iteration 12, average log likelihood -1.334886
[ Info: iteration 13, average log likelihood -1.334612
[ Info: iteration 14, average log likelihood -1.334394
[ Info: iteration 15, average log likelihood -1.334207
[ Info: iteration 16, average log likelihood -1.334029
[ Info: iteration 17, average log likelihood -1.333850
[ Info: iteration 18, average log likelihood -1.333665
[ Info: iteration 19, average log likelihood -1.333471
[ Info: iteration 20, average log likelihood -1.333267
[ Info: iteration 21, average log likelihood -1.333064
[ Info: iteration 22, average log likelihood -1.332890
[ Info: iteration 23, average log likelihood -1.332764
[ Info: iteration 24, average log likelihood -1.332683
[ Info: iteration 25, average log likelihood -1.332631
[ Info: iteration 26, average log likelihood -1.332596
[ Info: iteration 27, average log likelihood -1.332573
[ Info: iteration 28, average log likelihood -1.332557
[ Info: iteration 29, average log likelihood -1.332545
[ Info: iteration 30, average log likelihood -1.332537
[ Info: iteration 31, average log likelihood -1.332530
[ Info: iteration 32, average log likelihood -1.332525
[ Info: iteration 33, average log likelihood -1.332520
[ Info: iteration 34, average log likelihood -1.332516
[ Info: iteration 35, average log likelihood -1.332513
[ Info: iteration 36, average log likelihood -1.332510
[ Info: iteration 37, average log likelihood -1.332508
[ Info: iteration 38, average log likelihood -1.332506
[ Info: iteration 39, average log likelihood -1.332504
[ Info: iteration 40, average log likelihood -1.332502
[ Info: iteration 41, average log likelihood -1.332501
[ Info: iteration 42, average log likelihood -1.332500
[ Info: iteration 43, average log likelihood -1.332499
[ Info: iteration 44, average log likelihood -1.332498
[ Info: iteration 45, average log likelihood -1.332497
[ Info: iteration 46, average log likelihood -1.332497
[ Info: iteration 47, average log likelihood -1.332496
[ Info: iteration 48, average log likelihood -1.332496
[ Info: iteration 49, average log likelihood -1.332496
[ Info: iteration 50, average log likelihood -1.332495
┌ Info: EM with 100000 data points 50 iterations avll -1.332495
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3894972181685892
│     -1.3893041100853112
│      ⋮                 
└     -1.3324952886075097
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.332738
[ Info: iteration 2, average log likelihood -1.332502
[ Info: iteration 3, average log likelihood -1.331617
[ Info: iteration 4, average log likelihood -1.323626
[ Info: iteration 5, average log likelihood -1.303776
[ Info: iteration 6, average log likelihood -1.284787
[ Info: iteration 7, average log likelihood -1.276917
[ Info: iteration 8, average log likelihood -1.274319
[ Info: iteration 9, average log likelihood -1.273321
[ Info: iteration 10, average log likelihood -1.272743
[ Info: iteration 11, average log likelihood -1.272256
[ Info: iteration 12, average log likelihood -1.271729
[ Info: iteration 13, average log likelihood -1.271043
[ Info: iteration 14, average log likelihood -1.270116
[ Info: iteration 15, average log likelihood -1.268818
[ Info: iteration 16, average log likelihood -1.267287
[ Info: iteration 17, average log likelihood -1.266094
[ Info: iteration 18, average log likelihood -1.265454
[ Info: iteration 19, average log likelihood -1.265123
[ Info: iteration 20, average log likelihood -1.264916
[ Info: iteration 21, average log likelihood -1.264765
[ Info: iteration 22, average log likelihood -1.264651
[ Info: iteration 23, average log likelihood -1.264568
[ Info: iteration 24, average log likelihood -1.264508
[ Info: iteration 25, average log likelihood -1.264464
[ Info: iteration 26, average log likelihood -1.264429
[ Info: iteration 27, average log likelihood -1.264400
[ Info: iteration 28, average log likelihood -1.264374
[ Info: iteration 29, average log likelihood -1.264350
[ Info: iteration 30, average log likelihood -1.264326
[ Info: iteration 31, average log likelihood -1.264302
[ Info: iteration 32, average log likelihood -1.264275
[ Info: iteration 33, average log likelihood -1.264245
[ Info: iteration 34, average log likelihood -1.264207
[ Info: iteration 35, average log likelihood -1.264159
[ Info: iteration 36, average log likelihood -1.264095
[ Info: iteration 37, average log likelihood -1.264013
[ Info: iteration 38, average log likelihood -1.263906
[ Info: iteration 39, average log likelihood -1.263772
[ Info: iteration 40, average log likelihood -1.263609
[ Info: iteration 41, average log likelihood -1.263431
[ Info: iteration 42, average log likelihood -1.263260
[ Info: iteration 43, average log likelihood -1.263111
[ Info: iteration 44, average log likelihood -1.262996
[ Info: iteration 45, average log likelihood -1.262910
[ Info: iteration 46, average log likelihood -1.262844
[ Info: iteration 47, average log likelihood -1.262793
[ Info: iteration 48, average log likelihood -1.262752
[ Info: iteration 49, average log likelihood -1.262719
[ Info: iteration 50, average log likelihood -1.262689
┌ Info: EM with 100000 data points 50 iterations avll -1.262689
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3327381445520021
│     -1.332501945878243 
│      ⋮                 
└     -1.2626885403760018
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.262924
[ Info: iteration 2, average log likelihood -1.262614
[ Info: iteration 3, average log likelihood -1.261584
[ Info: iteration 4, average log likelihood -1.250056
[ Info: iteration 5, average log likelihood -1.215543
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.187672
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.185260
[ Info: iteration 8, average log likelihood -1.185583
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      6
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.164356
[ Info: iteration 10, average log likelihood -1.183194
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.165738
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.171314
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.170075
[ Info: iteration 14, average log likelihood -1.165641
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│      6
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.153535
[ Info: iteration 16, average log likelihood -1.189584
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.161951
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.162863
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.177100
[ Info: iteration 20, average log likelihood -1.167375
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      8
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.149114
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.174525
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.181900
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.162625
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.158125
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.159406
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.174084
[ Info: iteration 28, average log likelihood -1.176960
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.155534
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.159032
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.184559
[ Info: iteration 32, average log likelihood -1.163871
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      8
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.148606
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.173460
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.181959
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.162681
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.158297
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.159613
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│      8
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.174190
[ Info: iteration 40, average log likelihood -1.176959
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.155630
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.159172
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.184598
[ Info: iteration 44, average log likelihood -1.163937
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      8
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.148737
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.173522
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.181965
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.162703
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.158366
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.159712
┌ Info: EM with 100000 data points 50 iterations avll -1.159712
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2629240104347859
│     -1.2626144300483693
│      ⋮                 
└     -1.1597115404803096
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.174591
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.157288
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      8
│     11
│     12
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.145710
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│     11
│     12
│      ⋮
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.138875
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     11
│     12
│     15
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.110732
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.090703
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│     11
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.067950
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      8
│     11
│     12
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.100945
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      7
│     11
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.087899
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.095855
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      7
│      8
│     11
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.075629
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     11
│     12
│     15
│     16
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.097237
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      7
│     11
│     12
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.085357
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│     11
│     12
│     15
│     16
│     21
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.090584
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      7
│      8
│     11
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.060434
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.103781
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      7
│     11
│     12
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.085288
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      8
│     11
│     12
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.081071
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      7
│     11
│     12
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.083586
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     21
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.099432
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.056326
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.095443
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      7
│     11
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.083765
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      8
│     11
│     12
│     15
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.082753
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│     11
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.076382
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     21
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.099883
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.062618
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.095424
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      7
│     11
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.083546
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      8
│     11
│     12
│     15
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.082672
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│     11
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.076219
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     21
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.099820
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.062474
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.095374
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      7
│     11
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.083447
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      8
│     11
│     12
│     15
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.082624
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│     11
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.076123
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     21
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.099792
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.062373
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.095355
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      7
│     11
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.083368
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      8
│     11
│     12
│     15
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.082597
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│     11
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.076052
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     21
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.099774
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.062302
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.095346
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      7
│     11
│      ⋮
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.083315
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      8
│     11
│     12
│     15
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.082580
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│     11
│      ⋮
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.076007
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     21
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.099763
┌ Info: EM with 100000 data points 50 iterations avll -1.099763
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1745914769662626
│     -1.157288395403652 
│      ⋮                 
└     -1.099762523666434 
32×26 Array{┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.433980473475034 
│     -1.4341073023217072
│     -1.4339578408306393
│     -1.4319380829521406
│      ⋮                 
│     -1.082579729554271 
│     -1.0760070467954277
└     -1.099762523666434 
Float64,2}:
 -0.146007    -0.149555    -0.642534      0.123412   -0.136432      0.0138441    -0.156766     0.0686639   -0.385788     -0.0809683    0.241247     0.1427       0.0476217    0.0585427   -0.12826     -0.00614133   0.263592    -0.244203     -0.243132    -0.140426     0.0500076   0.0656827    -0.148023     0.0912805    0.0226614   -0.0139408 
 -0.155721    -0.100075     0.265259      0.15144    -0.139401      0.130958     -0.185186     0.0670062   -0.209961     -0.00194      0.189936     0.18881     -0.40487      0.0738013   -0.391717     0.0566477    0.245757    -0.08693      -0.168885     0.355343    -0.109809    0.0205773    -0.150488     0.0823555    0.0232897    0.0859767 
 -0.0440894   -0.152905    -0.00995549   -0.0366566   0.00990193    0.110923     -0.00172582  -0.0255672   -0.0375872     0.0513918   -0.0909566    0.0979207    0.00833664  -0.0658779    0.0645547   -0.0379584    0.231817    -0.0862889     0.00227318   0.0464986   -0.102545    0.0421705    -0.753159    -0.00229888  -0.135659     0.00718471
 -0.0538697   -0.0560098    0.149457     -0.0228532  -0.0524368    -0.0500832    -0.0210887   -0.0295029    0.0138131     0.0460774   -0.0775922   -0.0199934    0.0182357   -0.028707    -0.0267109   -0.0590461    0.0965299   -0.11641      -0.122821     0.024416    -0.0765922   0.051826      0.527266    -0.0223965    0.0898998   -0.0054971 
 -0.0358538   -0.133778    -0.11779      -0.135751    0.105176      0.0929975    -0.205119    -0.0550191    0.102255     -0.0959857   -0.0607124   -0.167472     0.0084699   -0.0829406   -0.0860208   -0.342906    -0.178695     0.0316632     0.0629802    0.0286261    0.0680199  -0.102765      0.288238    -0.0413645   -0.286616    -0.0775695 
 -0.0555231   -0.110764    -0.16285      -0.141377    0.0463509     0.265491     -0.228415    -0.150958     0.282495     -0.0480754   -0.0754925   -0.0946166   -0.00693246  -0.0723424   -0.0301027    0.299204    -0.183819     0.057819      0.0352566    0.0163444    0.0657047  -0.100502      0.142306    -0.126225    -0.187763    -0.0811218 
 -0.0655192   -0.0252371    0.0199986     0.0893835  -0.0440765     0.135119     -0.0910678    0.133649    -0.0451623     0.00871878  -0.0645353   -0.00128205   0.0711957    0.139087    -0.0267379    0.112807     0.169225     0.061712      0.0450959    0.0523581   -0.198469    0.10387      -0.00132426   0.0835021    0.0631134    0.107618  
  0.205959     0.0223954   -0.144409      0.0630922   0.0797626     0.0213952     0.0317734    0.0452527    0.0849102     0.0376934   -0.0577045   -0.0104316   -0.0554417    0.035812     0.121136     0.0374726    0.155769     0.110939     -0.0851132    0.0593644   -0.0295447  -0.0820537    -0.00498931   0.00275718   0.0788684    0.0300161 
  0.0302339   -0.108008    -0.0481646    -0.10792    -0.10801      -0.0530212    -0.0654012    0.187628    -0.101209     -0.112489     0.0596267    0.00105104   0.248315     0.0449043   -0.618292    -0.203202     0.0196627    0.209455      0.163027    -0.0879594    0.0949554  -0.0632411     0.0760977   -0.186273     0.110657    -0.0114378 
 -0.0110296    0.0648239   -0.0603466    -0.0957059  -0.0983643    -0.071198     -0.0566331    0.146921    -0.111404      0.141107     0.0353483   -0.149965     0.261208     0.0752955    0.571585    -0.252779    -0.0407886    0.274726      0.140866    -0.0805127    0.094916    0.175648      0.0930983   -0.144881     0.110122    -0.0827996 
 -0.284265     0.0721538   -0.102912     -0.0321259  -0.332279     -0.1187        0.00575674  -0.0325503   -0.0718843     0.16603     -0.022012    -0.215459    -0.107741    -0.189636    -0.253537    -0.0236768    0.261743     0.0474811    -0.0378102   -0.0110611   -0.0797231  -0.199991      0.00107855   0.056391     0.133878     0.0241649 
  0.389535    -0.126844    -0.105589      0.0740442   0.408401     -0.118897      0.0363968   -0.0342698   -0.0598145    -0.0365649   -0.0246637   -0.173927    -0.104237    -0.130697     0.0441153    0.108748     0.143008     0.04672      -0.0192822    0.18176     -0.135606    0.0131848     0.342365     0.0948643    0.0868247    0.0229918 
 -0.108416     0.012273     0.0895644     0.13176    -0.0235811    -0.0909777     0.00682467   0.0807918   -0.0354926    -0.0959042    0.00173949   0.0210635    0.0524301   -0.0229754    0.0216502    0.100666    -0.0249877    0.0602081     0.0895833   -0.0972587    0.0280795  -0.0704016    -0.0674108   -0.0332303    0.11101     -0.0987034 
 -0.0502013    0.0258743    0.0307567    -0.0900896   0.029553     -0.00700558   -0.0108943    0.0356306   -0.078186     -0.130219     0.107181     0.0252741   -0.00689275  -0.020638     0.0932753   -0.0982484    0.0885171   -0.0534792     0.169197     0.0394467   -0.0324791   0.0296072     0.0201027   -0.00114156  -0.0807775    0.0382957 
  0.045089    -0.272959    -0.0354034    -0.0745444  -0.151036      0.105528     -0.16274      0.0219549    0.143753     -0.124078    -0.0876226    0.217601    -0.212139    -0.0464669   -0.202046    -0.206316    -0.0607336    0.0127499     0.125623    -0.0568173    0.256484   -0.212292     -0.142288     0.0320857   -0.317549    -0.0830481 
  0.0315295    0.5205      -0.0356763    -0.130676    0.0992771    -0.0967018     0.140744     0.0756017    0.00982266   -0.313458    -0.0843229   -0.212523     0.305339    -0.054345    -0.153667    -0.187382    -0.14532      0.0367319     0.132493     0.0173749   -0.124286    0.360411      0.0570583   -0.0635614   -0.0921869   -0.0680742 
 -0.0177571    0.0465433    0.113781     -0.11345    -0.118474     -0.0122206     0.0677599   -0.062334     0.0293311    -0.0531401   -0.0226203    0.00767706   0.0781498    0.0469144    0.0242491    0.0415935    0.00421765   0.0230338     0.0868383   -0.0332837    0.0979686   0.0820985    -0.0926569   -0.0091537   -0.0657083    0.0850337 
  0.0576069    0.0210456   -0.101381     -0.0340322   0.194204      0.0108601     0.0234547   -0.0826531   -0.0480352     0.0645135   -0.0563659    0.159778    -0.172938     0.020094    -0.00872756  -0.0129285    0.0726666   -0.026763     -0.10101      0.0427496   -0.0566332   0.0164048    -0.0793291   -0.234238    -0.0146826   -0.00976822
  0.026484    -0.00648738  -0.0559388    -0.0211232  -0.0799189    -0.0808919    -0.1353       0.0757523    0.122842      0.134581     0.0328096   -0.0240105   -0.155206    -0.113312     0.0180802    0.0343792    0.0100851   -0.135129      0.0172806   -0.0671893   -0.0183526  -0.0727133    -0.107857    -0.209355     0.0682993   -0.113413  
  0.0232708   -0.0339118   -0.102693      0.0453078  -0.015159      0.0574162    -0.0020552   -0.057597     0.0132267    -0.005324     0.0286123   -0.00919007  -0.0399694   -0.0497435    0.056842    -0.0740559   -0.0412618   -0.025032      0.114859     0.149311     0.0298565  -0.0736685     0.00327994   0.0179666    0.00412964  -0.160702  
 -0.0362329   -0.153021    -0.0666482     0.139831   -0.0346827     0.0647211     0.0996371    0.0301202   -0.0313323     0.127153    -0.00136975  -0.0778866    0.0701438   -0.0939914   -0.253087    -0.0444312    0.0039363   -0.194306      0.201206     0.091478    -0.175242   -0.000648255   0.0256623    0.0659133    0.0143824    0.0177483 
  0.111109     0.135003     0.116309     -0.36112    -0.280637      0.000254009   0.0162327   -0.0329592    0.146177      0.0765556   -0.00438996   0.0496267    0.119203    -0.0358536    0.0180141   -0.130544    -0.0981936   -0.103082     -0.162991     0.0654138    0.163346   -0.0341106     0.120171     0.112576    -0.0315534    0.0379736 
  0.00884066   0.0970523    0.0295264     0.0869728   0.128421      0.0375493     0.0573476   -0.042644     0.164051     -0.0442492    0.0019724   -0.07558      0.0357399    0.0387403   -0.0772555    0.0860695    0.116388    -0.00381373   -0.024718     0.00554516   0.0614482   0.0244905     0.0737358   -0.204782     0.0168461   -0.0805656 
  0.0930184   -0.0431951   -0.027249     -0.144008   -0.0902198     0.16829       0.10235     -0.261828    -0.000138448   0.0081593   -0.0426156   -0.0301353    0.00201014  -0.0809046   -0.141269    -0.0758162    0.0571818    0.0484902     0.136362     0.0804613   -0.0751876   0.161291      0.16513     -0.00361038   0.00560329   0.0845351 
  0.0732881    0.113818    -0.120747      0.0669289   0.28233      -0.0565603    -0.0108583    0.0312207    0.155778     -0.154715    -0.0310024    0.0689166    0.0892487   -0.0218579    0.0459962    0.107256     0.166437     0.0233126     0.0285068   -0.192576    -0.127145   -0.0940391     0.0399242   -0.0147534   -0.0327267   -0.023532  
 -0.18253     -0.0518124   -0.107241      0.018354    0.0946367    -0.0223211     0.06977      0.121633    -0.0325754     0.030615    -0.00590084  -0.0644699    0.176442     0.00524881   0.0355186    0.0658685   -0.293162    -0.000307288   0.0130399    0.1509       0.0686624  -0.0552443     0.144406    -0.0669057    0.112069     0.0452521 
  0.00598568  -0.110448     0.128387      0.154932    0.148842     -0.0238776     0.0776536    0.103179    -0.0533113     0.0663405   -0.0649809    0.0896228   -0.0542611   -0.0358967    0.0916082   -0.126262    -0.00678767   0.179803     -0.0812818   -0.095413    -0.0810348  -0.107098      0.0137741    0.14632      0.0418293    0.0203966 
  0.321353     0.0143918    0.0382948     0.234782   -0.000430487  -0.00137718    0.116763     0.0654784   -0.0592185    -0.0667913    0.0627247   -0.063584    -0.0785063    0.0330859   -0.189203    -0.0780327   -0.0631932   -0.0685755    -0.0352127    0.0414026   -0.0576595   0.0136638    -0.159589     0.0109601   -0.151216     0.120365  
  0.144141     0.141676     0.18034      -0.239009    0.0447263     0.173406      0.0665634   -0.00189872  -0.0012424     0.0107565   -0.120569     0.00269841  -0.0865486    0.156796     0.0281391    0.0816195   -0.0264024   -0.159944      0.120696     0.0765316    0.0572838   0.111884     -0.0244311   -0.146607     0.00286896   0.083461  
  0.103539    -0.00142196   0.144655      0.0602802  -0.0652223     0.053108     -0.0103263    0.0427749   -0.179177     -0.0649792    0.0295491    0.0500804    0.0701694    0.0146937    0.0493373   -0.159694    -0.0869368   -0.00783626    0.212023     0.00420531   0.0311331  -0.0255795    -0.0966788   -0.0959944   -0.0508407    0.125511  
  0.115677     0.162801    -0.458405      1.04664    -0.2709        0.541534     -0.0297044   -0.0589178   -0.0915892     0.0372996    0.0889667   -0.111862    -0.00199187  -0.131336     0.0765419   -0.0559315   -0.0931017    0.0480888     0.0585389   -0.246199    -0.103939    0.0785305    -0.0890455    0.0701614   -0.473289    -0.0215425 
  0.134924    -0.161496    -0.000611225  -0.698869    0.00925753   -0.160532     -0.0616268   -0.0460543    0.126468      0.0393603    0.0659167   -0.0169434   -0.0294382   -0.092147     0.0761919    0.0337948   -0.092601     0.0597685     0.0857356   -0.278022     0.0951459   0.156963     -0.0753724    0.0610505    0.322914    -0.0963359 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.062258
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      4
│      7
│      8
│     11
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.050817
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.056621
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      4
│      7
│      8
│     11
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.050250
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.056415
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      4
│      7
│      8
│     11
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.050204
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.056513
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      4
│      7
│      8
│     11
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.050197
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      7
│      8
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.056548
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      4
│      7
│      8
│     11
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.050194
┌ Info: EM with 100000 data points 10 iterations avll -1.050194
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.975392e+05
      1       7.034839e+05      -1.940553e+05 |       32
      2       6.735472e+05      -2.993669e+04 |       32
      3       6.602513e+05      -1.329582e+04 |       32
      4       6.512000e+05      -9.051315e+03 |       32
      5       6.433316e+05      -7.868436e+03 |       32
      6       6.376729e+05      -5.658741e+03 |       32
      7       6.344293e+05      -3.243607e+03 |       32
      8       6.327918e+05      -1.637433e+03 |       32
      9       6.319575e+05      -8.343664e+02 |       32
     10       6.314933e+05      -4.641976e+02 |       32
     11       6.311742e+05      -3.190374e+02 |       32
     12       6.309692e+05      -2.050328e+02 |       32
     13       6.308143e+05      -1.548832e+02 |       32
     14       6.306848e+05      -1.295353e+02 |       32
     15       6.305934e+05      -9.140634e+01 |       32
     16       6.305275e+05      -6.583573e+01 |       32
     17       6.304633e+05      -6.419845e+01 |       31
     18       6.303936e+05      -6.970448e+01 |       32
     19       6.303153e+05      -7.834204e+01 |       32
     20       6.302199e+05      -9.535391e+01 |       32
     21       6.300832e+05      -1.366858e+02 |       32
     22       6.298523e+05      -2.309276e+02 |       32
     23       6.294489e+05      -4.034299e+02 |       32
     24       6.289855e+05      -4.633846e+02 |       32
     25       6.285575e+05      -4.280058e+02 |       32
     26       6.283070e+05      -2.505220e+02 |       32
     27       6.281322e+05      -1.747332e+02 |       32
     28       6.279793e+05      -1.529464e+02 |       32
     29       6.278092e+05      -1.700946e+02 |       32
     30       6.276275e+05      -1.816718e+02 |       32
     31       6.273811e+05      -2.464212e+02 |       32
     32       6.271107e+05      -2.703754e+02 |       32
     33       6.269585e+05      -1.522433e+02 |       32
     34       6.268841e+05      -7.436788e+01 |       32
     35       6.268438e+05      -4.035631e+01 |       32
     36       6.268219e+05      -2.182914e+01 |       32
     37       6.268050e+05      -1.692412e+01 |       30
     38       6.267912e+05      -1.384240e+01 |       28
     39       6.267810e+05      -1.018907e+01 |       28
     40       6.267732e+05      -7.781864e+00 |       29
     41       6.267659e+05      -7.255905e+00 |       28
     42       6.267597e+05      -6.201088e+00 |       29
     43       6.267551e+05      -4.628978e+00 |       23
     44       6.267521e+05      -3.045912e+00 |       26
     45       6.267494e+05      -2.640610e+00 |       25
     46       6.267463e+05      -3.102380e+00 |       22
     47       6.267444e+05      -1.897604e+00 |       21
     48       6.267424e+05      -2.055472e+00 |       20
     49       6.267410e+05      -1.372299e+00 |       16
     50       6.267389e+05      -2.070184e+00 |       22
K-means terminated without convergence after 50 iterations (objv = 626738.9206432493)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.322140
[ Info: iteration 2, average log likelihood -1.289841
[ Info: iteration 3, average log likelihood -1.260418
[ Info: iteration 4, average log likelihood -1.226574
[ Info: iteration 5, average log likelihood -1.184613
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.123656
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     13
│     15
│     27
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.075870
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      6
│     16
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.089338
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     10
│     18
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.104700
[ Info: iteration 10, average log likelihood -1.098306
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      8
│     16
│     26
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.012183
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     13
│     15
│     19
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.078898
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.109706
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.083971
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     26
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.029853
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      8
│     13
│     15
│     16
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.029135
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     10
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.091645
[ Info: iteration 18, average log likelihood -1.096803
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     18
│     26
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.040160
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      8
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.055225
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     10
│     13
│      ⋮
│     19
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.035473
[ Info: iteration 22, average log likelihood -1.108969
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     26
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.057545
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.078162
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      5
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.044736
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│     10
│     15
│     19
│     27
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.020469
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     13
│     16
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.063500
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.096574
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.066979
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      6
│     18
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.014910
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     10
│     13
│     15
│     16
│     19
│     21
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.053764
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│      8
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.109345
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.098489
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.046861
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     10
│     13
│      ⋮
│     27
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.002417
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      8
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.084853
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.097850
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.083001
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      6
│      8
│     21
│     27
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.016122
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      5
│     10
│     13
│     15
│     16
│     19
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.049870
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.117705
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     18
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.078699
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      8
│     21
│     26
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.026549
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│     10
│     15
│     19
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.051407
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.108616
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.078615
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      8
│     18
│     21
│     26
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.028241
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      5
│     10
│     15
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.063956
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     13
│     16
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.095450
[ Info: iteration 50, average log likelihood -1.101424
┌ Info: EM with 100000 data points 50 iterations avll -1.101424
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0137614    0.14087      0.123819    -0.0564324   -0.0713437   -0.0583592     0.0302435   -0.0923553   0.0601354   -0.192024     0.137023     0.0112548    0.105956      0.0574565    0.077467     0.0142211    0.0325793    0.0949509    -0.00412744  -0.118957     0.151589   -0.0229309   -0.00766081  -0.0296606   -0.0891216    0.287907  
 -0.0330367    0.0528995    0.0456332    0.212081     0.113238     0.0477736     0.178167    -0.065703    0.160366    -0.121295    -0.00994206  -0.0313006    0.0302837     0.0402242    0.0294043   -0.035091     0.06767      0.0952553    -0.111738    -0.012179    -0.107906    0.119337     0.173286    -0.192102     0.0577398    0.0786713 
  0.00587699  -0.0565685    0.0674488    0.188576     0.0740559   -0.148592      0.119576     0.162828    0.0821684   -0.18772     -0.0778538   -0.0669409    0.20738      -0.0221973    0.123703     0.100484    -0.0347266    0.0975954     0.0567487   -0.178249     0.112804    0.142727    -0.00979441   0.0367066    0.138509    -0.033865  
  0.0723565    0.113824    -0.119794     0.06916      0.281879    -0.0562906    -0.00926488   0.0311445   0.154417    -0.154867    -0.0318086    0.0674506    0.0882238    -0.022031     0.046278     0.1071       0.165604     0.0231005     0.0271659   -0.191942    -0.127326   -0.0942406    0.0397212   -0.0150821   -0.0327758   -0.0227629 
  0.0707498   -0.0182412   -0.100289     0.0288676    0.0288332   -0.106281      0.0226012   -0.0272675  -0.0585897    0.0657414   -0.0245444   -0.184739    -0.102683     -0.148411    -0.103115     0.0352334    0.199062     0.0412381    -0.0255847    0.0872382   -0.0993212  -0.0825232    0.147395     0.0721572    0.115037     0.0290083 
 -0.0346993   -0.0536965    0.171955    -0.0483922   -0.044496    -0.0280887    -0.0344101   -0.0546439   0.0315733    0.045743    -0.0754493    0.00830125   0.0208477    -0.0207133   -0.030337    -0.0781454    0.141557    -0.110932     -0.134071     0.0241053   -0.0934392   0.00350271   0.112893    -0.0410347    0.0302055    0.0352785 
  0.133885     0.0648636   -0.0391274   -0.0322393   -0.0452488    0.185494      0.00664332  -0.0372975   0.00930905   0.0289874   -0.0060886   -0.0317158   -0.0431419     0.0128754    0.0542835    0.0322754   -0.0658119   -0.0386194     0.0965901   -0.105167     0.0244268   0.111549    -0.0536094   -0.0275277   -0.0351094    0.00678444
 -0.165761     0.176619     0.09288      0.0600324   -0.01295     -0.111535      0.080985     0.0729641  -0.129704    -0.138403     0.0874649    0.0869713   -0.0365988    -0.0254785   -0.0522195    0.168438     0.0215762    0.150007      0.0578804   -0.00986695  -0.0519924  -0.201668    -0.111981     0.0512881    0.00874041  -0.156695  
 -0.14169     -0.037633     0.0341992   -0.0749364    0.0330223   -0.0199819    -0.121928    -0.074175   -0.0529143   -0.210208     0.131836     0.0468236   -0.0720593    -0.0375747    0.045072    -0.0169935    0.173178    -0.0952358     0.203258     0.0127308   -0.0715315   0.0851893    0.0413856   -0.0711713   -0.265714     0.00789811
 -0.0569362   -0.0253182    0.0837356   -0.14303     -0.116885    -0.0494867     0.0997052   -0.0382391   2.51912e-5   0.0521247   -0.136392     0.0217623    0.0374858     0.0513693   -0.0361206    0.0595114   -0.0263691   -0.0510253     0.148488     0.0617748    0.0438227   0.180767    -0.161737    -0.00999869  -0.0503212   -0.109555  
 -0.183056    -0.0513805   -0.107401     0.0197003    0.0921779   -0.0222742     0.0700755    0.122614   -0.032661     0.029858    -0.00528894  -0.0645059    0.176778      0.00585057   0.0354725    0.0653283   -0.291038     0.000613894   0.0137396    0.15064      0.0689397  -0.0553906    0.14389     -0.0674435    0.111396     0.0477135 
  0.109315     0.133035     0.116008    -0.359999    -0.279993    -0.000539879   0.0164455   -0.0363514   0.146581     0.0775428   -0.00679399   0.0463665    0.117664     -0.0361074    0.018504    -0.129404    -0.0975707   -0.106517     -0.163177     0.0656564    0.162813   -0.034476     0.120448     0.112799    -0.0310958    0.0368941 
  0.496246     0.0131354    0.0103933    0.35103     -0.00904335  -0.000223006   0.0997234    0.0956491  -0.031722    -0.0561395    0.134745    -0.0825334   -0.0810663     0.0419451   -0.207288    -0.0941448   -0.0582475   -0.0345402    -0.0441659    0.05369     -0.0588078  -0.00166569  -0.261158     0.0159568   -0.334738     0.194022  
  0.0559088    0.0207836   -0.0984652   -0.0351686    0.193238     0.0186171     0.024956    -0.0823249  -0.0429972    0.0650592   -0.0563621    0.158714    -0.172036      0.0212369   -0.00692759  -0.0124884    0.0720785   -0.0279179    -0.0999803    0.0422902   -0.0580479   0.017355    -0.0796565   -0.234305    -0.0183473   -0.011873  
  0.075323    -0.152594    -0.237774     0.016265     0.0512885    0.0263285     0.0659421   -0.207902   -0.0266838   -0.132924     0.0938768   -0.0392956   -0.133799     -0.227188     0.00781239  -0.0233826   -0.0261661   -0.162853      0.227264     0.177024     0.0576085  -0.287147     0.178051    -0.00290957  -0.00785815  -0.153435  
  0.229048     0.02314     -0.0808498    0.135097     0.0614198    0.0122618     0.0267719    0.0521511   0.0442863    0.0270551   -0.0346569   -0.023977    -0.0789527     0.0476911    0.0722513    0.0182177    0.0977607    0.0932266    -0.101659     0.0804184   -0.0244203  -0.0586953   -0.0370832   -0.0054926    0.111102     0.0633343 
 -0.14831     -0.12611     -0.164767     0.137591    -0.137225     0.0724695    -0.170472     0.0610224  -0.285218    -0.0373398    0.215079     0.165347    -0.185371      0.0632717   -0.269576     0.0251845    0.253263    -0.165416     -0.202157     0.109677    -0.0338058   0.0417632   -0.146467     0.0824911    0.0229421    0.0421231 
  0.0640211   -0.0880848    0.122068     0.146596     0.111856    -0.0177666     0.0868253    0.112022   -0.0507872    0.0414097   -0.083773     0.0727308   -0.0367762    -0.00733029   0.070298    -0.120538    -0.018051     0.144119     -0.0737056   -0.0962082   -0.0615745  -0.0988368    0.00300849   0.132554     0.0223581    0.0574158 
 -0.0229525    0.0635893   -0.00885393   0.0508245   -0.0749463    0.0569403    -0.113244    -0.11304     0.065933     0.163147    -0.0666609    0.0641532   -0.00309609    0.15914      0.0671195   -0.1585      -0.113911     0.0259526    -0.0294969    0.130309     0.0017669  -0.0336774   -0.00868147   0.0142252    0.0352624   -0.346467  
  0.0424834    0.0835528    0.050143    -0.101666     0.034068    -0.0128899     0.0902439    0.138052   -0.0960844   -0.0614187    0.0918369   -0.0198888    0.0655744    -0.00200607   0.1093      -0.188952     0.0130833   -0.0010704     0.138063     0.0668742   -0.014262   -0.023337    -0.0220048    0.0658649    0.0883781    0.0857729 
 -0.0189484   -0.14671     -0.0601962    0.134248    -0.0371147    0.0572155     0.0975672    0.0671184  -0.0353758    0.128798    -0.00157632  -0.0721136    0.0655764    -0.0906892   -0.242071    -0.0457544    0.00128874  -0.203949      0.189488     0.0903252   -0.169885   -0.0066035    0.0113215    0.0610463    0.0136886    0.0226349 
 -0.135504    -0.0971508    0.0670114    0.123228    -0.141528    -0.00532661   -0.177893     0.0103958  -0.0386412    0.0463388    0.00133763   0.00967955   0.000795651  -0.0245875    0.0139668    0.00316527  -0.0646672   -0.0746214     0.150205    -0.109307     0.0547006  -0.069735    -0.0486364   -0.179719     0.199883    -0.094521  
  0.0662084    0.12386     -0.00228524  -0.0441988    0.102402     0.0612253    -0.038641    -0.0351013   0.150462     0.0388408    0.0294634   -0.132284     0.0176784     0.0108621   -0.196432     0.186018     0.146932    -0.0963696     0.0876834    0.0390588    0.209331   -0.0394703    0.0104382   -0.162068    -0.0250605   -0.249438  
 -0.0432784   -0.123124    -0.133289    -0.136201     0.085581     0.173568     -0.210973    -0.0899216   0.176008    -0.0769535   -0.0675855   -0.141367     0.00387038   -0.0790627   -0.0622887   -0.0645263   -0.171904     0.0404069     0.0498306    0.0320626    0.0666901  -0.096964     0.223183    -0.06776     -0.256073    -0.0742478 
  0.0246547    0.00210658   0.0657121   -0.0521739   -0.0985661    0.290827      0.059548     0.0245668  -0.100867     0.0302767   -0.0737538    0.0136579    0.0516973     0.00419663  -0.0439777    0.13606      0.0486044   -0.0341767     0.0821919    0.0909331   -0.0109596   0.115018    -0.133283     0.0752777    0.0744648   -0.0114005 
 -0.0634524   -0.0276999    0.0114188    0.09043     -0.0475127    0.12592      -0.0903581    0.130924   -0.00983221   0.0147738   -0.0881202   -0.00971946   0.0686887     0.15687     -0.0229939    0.101965     0.16632      0.0712156     0.0310643    0.0522117   -0.215727    0.0977251    0.0110277    0.0691826    0.0809489    0.091116  
  0.0427186    0.0115119   -0.0310113   -0.0278274   -0.0794307   -0.0654488    -0.120021     0.0947155   0.113018     0.139858     0.023891    -0.0232853   -0.167919     -0.107761     0.0117381    0.0395182    0.0168426   -0.140059      0.0117773   -0.0560211   -0.0156925  -0.0572551   -0.145939    -0.219066     0.0561885   -0.0879926 
  0.0458614    0.125997    -0.0393425   -0.0969265   -0.019151     0.00206045   -0.00659822   0.0522228   0.0770615   -0.210479    -0.0898241   -0.00296742   0.0565687    -0.0478726   -0.16643     -0.188961    -0.0985522    0.0237837     0.127396    -0.0186719    0.0594909   0.0744345   -0.045322    -0.0147002   -0.226451    -0.0760668 
  0.110751     0.00208188   0.133136     0.0572373   -0.0545177    0.0604043    -0.00614217   0.042151   -0.169604    -0.059953     0.0271482    0.0489102    0.0610154     0.0201407    0.0473483   -0.157       -0.080785    -0.00381237    0.209034     0.00377573   0.0285345  -0.024822    -0.0977998   -0.0900193   -0.0497577    0.122904  
 -0.0256344   -0.12051     -0.148265    -0.00788204   0.0332628    0.123485      0.054276     0.105451   -0.0812369    0.0325184   -0.0598326    0.0803449   -0.0601678    -0.0999758    0.119933     0.00729015   0.115106    -0.0619595     0.114423     0.0987851   -0.0454323   0.0817928   -0.245313     0.0276795   -0.0806932   -0.0751609 
  0.100951    -0.0529804   -0.0233592   -0.146768    -0.106459     0.154244      0.0964847   -0.283442   -0.0028205    0.0128084   -0.0658131   -0.0334367    0.0104779    -0.0778023   -0.127911    -0.0785336    0.0452046    0.0616662     0.142793     0.0820956   -0.076152    0.16387      0.152238     0.00571672  -0.00114512   0.0782106 
  0.00996609  -0.0304583   -0.0537123   -0.102483    -0.106024    -0.0599214    -0.0610397    0.167955   -0.105266     0.00428145   0.0483958   -0.0677863    0.253743      0.0590733   -0.0723179   -0.225919    -0.00803599   0.238472      0.152586    -0.0845877    0.0949727   0.0473161    0.0838712   -0.166989     0.110463    -0.0442047 [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│      8
│     21
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.017895
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.963131
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      8
│     16
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.006968
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.974515
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      8
│     16
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.008359
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.974526
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      8
│     16
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.008362
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.974526
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      8
│     16
│      ⋮
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.008361
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     28
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.974525
┌ Info: EM with 100000 data points 10 iterations avll -0.974525
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.00171068  -0.091812     0.0535498   -0.0281929   -0.121096     -0.115094    -0.229189      0.0863738    0.0130991   -0.0025458   -0.019025    -0.025083    -0.0230856    0.0306098    0.066228    -0.0706154    0.0650194   -0.0286361   -0.063498     0.0310664  -0.0788755   -0.023876    -0.0529801     0.110204     0.00853459  -0.0139545 
 -0.0371733    0.115131     0.0479555   -0.0473414   -0.079692      0.190806     0.0876551     0.0939826   -0.0669915   -0.0511235   -0.054936    -0.0536193    0.0136071    0.0254475    0.055784    -0.0225608   -0.00259376  -0.0650077   -0.128788    -0.154752   -0.167554     0.0134826   -0.00450526   -0.0401043    0.0126938   -0.0692978 
 -0.056132    -0.00617181  -0.0345384    0.148626    -0.218192     -0.044583     0.0530114    -0.201048    -0.00421883  -0.120594    -0.18239      0.0420921    0.163394     0.204605     0.0365645   -0.0615542   -0.00259655  -0.26235      0.0237652   -0.0728456  -0.129629    -0.0185229   -0.0422901    -0.0739254    0.0323784   -0.164475  
 -0.0266082    0.0123868    0.213045    -0.0411526   -0.0541007    -0.0142696   -0.00780538    0.153451    -0.0275106    0.0545339    0.0262554   -0.147529    -0.0433604   -0.0441655   -0.0345398    0.0269022   -0.04345     -0.148221     0.17424      0.270657    0.0939117   -0.0341798   -0.0594371     0.0343049    0.0124116    0.100669  
  0.0807009   -0.11077      0.0308195   -0.00848393   0.116163     -0.055885    -0.00762187    0.0155739    0.214855     0.0253836    0.0829211   -0.0228276   -0.0196667    0.117678    -0.029742     0.0243527    0.0377853   -0.0124621    0.0409042   -0.0542295  -0.00131714  -0.120361     0.158683     -0.115946    -0.133201    -0.0848966 
  0.140753    -0.0282318   -0.0308696    0.153967     0.0939602     0.0319532    0.0380429     0.0737241    0.0949458   -0.045638    -0.0772338    0.0211239    0.0734317   -0.135613    -0.224255     0.106908     0.0937204   -0.137999    -0.0957941    0.209977   -0.131403    -0.158683    -0.0241183     0.121948    -0.115003     0.0324855 
  0.079169     0.129701     0.124139    -0.0690591    0.0983739    -0.0259482    0.106588     -0.0409012    0.00305483   0.0557745    0.115644    -0.0222649    0.0305438    0.17353      0.249145     0.0349643    0.0656004   -0.0302389    0.127253     0.043341    0.108402     0.00807729   0.218366      0.0410704    0.204113     0.100283  
 -0.0328372    0.052765    -0.106942     0.00512178  -0.0145094     0.0670213    0.220785      0.0721099    0.199385    -0.059816    -0.0184423    0.0291473   -0.0295188   -0.236687    -0.113613    -0.00122861   0.135365     0.0977999    0.0558379   -0.017507    0.0269142   -0.00616605  -0.164518      0.0498341   -0.0139437   -0.0661108 
 -0.0177649    0.0405549   -0.045825    -0.0658523   -0.0460121    -0.111213     0.0463343     0.106884     0.191756    -0.0212219   -0.00782971   0.0492105    0.159993    -0.103726    -0.057964    -0.0094804   -0.0977074    0.0155375   -0.0351682    0.11469     0.0092806    0.0204741    0.183998     -0.11643      0.0946372    0.116528  
  0.209805     0.173895     0.0487013   -0.234881     0.0561517    -0.167916    -0.0562663    -0.133251     0.133162     0.129288    -0.0341337   -0.0207662    0.0274482   -0.0505707   -0.0659137   -0.0250187   -0.0850299   -0.0472915    0.0595691    0.0592188   0.0395145    0.0764124   -0.143927      0.0753498    0.0263329   -0.149196  
  0.0377851   -0.0215035   -0.0266086   -0.0386074    0.0883812    -0.0258251   -0.0798462    -0.0784308    0.0230267    0.0068724    0.0287163   -0.0663377   -0.0945564    0.0224769    0.221208    -0.0255067    0.093741     0.0992539    0.0850626   -0.0403982  -0.0288012   -0.10712     -0.0420675    -0.0378513    0.0612854   -0.0236262 
  0.0727099    0.0396604    0.145096     0.0421644    0.000962871  -0.0510283   -0.0443658    -0.104415    -0.103772    -0.145768    -0.068846     0.137207    -0.0477165    0.0239463   -0.0186804    0.0920378   -0.111822    -0.0948202    0.210303     0.15785     0.0367023   -0.00835275  -0.185709     -0.096841    -0.0968052    0.0111527 
  0.115271     0.00932052   0.106619     0.0620363    0.0254737     0.0294035    0.061054      0.0593654   -0.0399655   -0.0951461   -0.122202     0.152492    -0.0807188   -0.1261      -0.0311694    0.0702461    0.0755721    0.025792     0.0542969    0.160517    0.00548801   0.0855556   -0.140031      0.115966     0.00704091   0.00119487
 -0.127799     0.0675322    0.0762229   -0.0445278   -0.000246619   0.13313     -0.111477      0.0109653    0.00244554  -0.148585    -0.0609365    0.0900301   -0.00281851  -0.0732514   -0.186304     0.085976    -0.013374    -0.333279    -0.0301363   -0.0771233  -0.112645     0.0234154    0.184586     -0.152609    -0.0641853   -0.00902402
 -0.034898    -0.0249387   -0.00248526   0.0839279    0.120826     -0.122926     0.0610819     0.0616322   -0.0639452   -0.0876115   -0.262431     0.0622617    0.0343744    0.0720053   -0.0748506    0.0238447    0.0432409   -0.148272     0.00802224   0.125671   -0.0474562    0.058152    -0.159461     -0.0304056    0.0668132   -0.19109   
 -0.0457206   -0.0333541   -0.027292     0.193663     0.138314     -0.0737431    0.008759     -0.125864     0.153335    -0.115945    -0.0850606    0.0212372    0.0273911   -0.0146865    0.0588548   -0.0806921    0.115519     0.00401029   0.0920667   -0.175822    0.0361651    0.0225111   -0.0327402    -0.116159     0.146091     0.0211898 
 -0.0308189   -0.161204    -0.00190775   0.111189    -0.181449      0.162159    -0.0455802     0.0890017   -0.0595212   -0.0278701   -0.0192777    0.0990531   -0.062646     0.143452    -0.0827737    0.154428    -0.0289762    0.151556    -0.105919     0.0394586  -0.10726      0.0591804    0.0138969    -0.0456042   -0.059936    -0.023828  
  0.125514    -0.0498674    0.102023     0.0990959    0.0128735     0.132198    -0.0301793     0.0722922   -0.0502558   -0.0458152   -0.0812361    0.00656944   0.0937502    0.0426875   -0.047345     0.114651     0.036156    -0.137684    -0.101827     0.037306    0.12279      0.0882381    0.000200798   0.0293942    0.0637882   -0.0610511 
 -0.0319779   -0.0351166    0.00425789  -0.0685014   -0.0796925     0.120975    -0.197291      0.0770208    0.113745    -0.0715252    0.00415608   0.0583469   -0.0100014    0.0902351   -0.0754391    0.159898     0.126809     0.0948399    0.121632     0.0322454  -0.114096    -0.137049     0.0307172    -0.162146    -0.0402818   -0.0155889 
  0.00854097  -0.149493     0.086528    -0.0716771    0.0988338    -0.0992427   -0.191298     -0.0940853   -0.157861    -0.00219594   0.0454634    0.00159449  -0.0668989   -0.029659     0.196357     0.0309816    0.103139    -0.13096     -0.0230612   -0.0420843  -0.123544     0.19956      0.0404708     0.287976     0.0336486   -0.0239789 
  0.00650708   0.145547     0.0842633    0.0345855   -0.299808      0.115096     0.0242346     0.0557962   -0.168677    -0.0806227   -0.0843495   -0.00129164  -0.019644     0.114863    -0.0204729    0.00615003  -0.15174     -0.0627879    0.0695361   -0.0995361   0.217238    -0.100254     0.0742473     0.0258598    0.015355    -0.0697539 
 -0.00966547   0.100129    -0.0348084    0.0055045    0.120344     -0.0972431    0.0594841     0.0879581    0.0440533   -0.152        0.165328    -0.0237105    0.269217     0.0391584   -0.170038     0.14874      0.0138115   -0.015911    -0.239583     0.127829    0.0580321    0.0376195   -0.209673      0.145997    -0.100889     0.0738258 
 -0.0434441    0.0672798    0.0926979    0.0681349   -0.219825     -0.0147808    0.0683545    -0.0791315    0.0553838    0.0753988    0.014379     0.0599395   -0.103802    -0.0901381   -0.0210989    0.0306523   -0.124461    -0.0383905   -0.173639     0.078988    0.0482358   -0.0646046   -0.117875     -0.116107    -0.102511    -0.0689671 
  0.0219079    0.0539792   -0.184297     0.0294363    0.268558      0.0963033   -0.193571      0.0556121   -0.00854019  -0.0231345    0.100837     0.0480248    0.0255286    0.0256626    0.0678494   -0.0196357   -0.102168     0.0222443   -0.118452     0.0738946   0.0759765   -0.146128    -0.0349963    -0.206855    -0.155479     0.0747826 
 -0.0557707    0.213176    -0.100415     0.137973     0.194176     -0.0699432    0.054575      0.00161587   0.0300753   -0.0987523   -0.0237185   -0.192623    -0.198091     0.00598669   0.0108428   -0.081663    -0.0780487   -0.0416131    0.127353     0.0712119   0.0144606    0.0983252   -0.0252672     0.062447    -0.113482     0.122061  
 -0.143541     0.130175     0.112373     0.0405274   -0.232872      0.0528128   -0.072223      0.0108529   -0.00915577  -0.148842     0.107229     0.0483507   -0.014234    -0.0772759   -0.0505577    0.018008     0.0250319    0.0324682    0.00108035   0.116413    0.025681     0.058284     0.0324738     0.0693645    0.0602763   -0.114849  
 -0.00764763   0.162004    -0.00227755   0.0304598    0.0966529     0.00699012   0.000590957  -0.107807     0.0442316   -0.0567703    0.00317218  -0.0563007    0.0759564   -0.0700383    0.151948     0.0378595   -0.104662     0.107671     0.00620766   0.250386    0.0748012   -0.00369899  -0.0636593    -0.0573344   -0.0247471    0.0400487 
  0.00213075  -0.163621    -0.0804019   -0.0851387   -0.0177388     0.138999     0.00900316    0.144175     0.143237    -0.0605058    0.099227     0.0577595    0.138825    -0.0459857    0.184148    -0.10652     -0.0253692    0.0786827   -0.104597     0.0179412   0.0716679   -0.030522    -0.04324      -0.051586     0.0593383   -0.224839  
  0.0504606   -0.067202    -0.0248419   -0.0848553    0.0676553     0.110279    -0.135864     -0.0629462   -0.128742     0.0186318    0.00743659  -0.140446     0.0913124   -0.0185295    0.0391066    0.117941     0.0811285    0.0695874   -0.0608747    0.169884    0.00354955  -0.0903843    0.0403365     0.0484705    0.136375     0.206092  
  0.0838836   -0.00439492   0.0559069   -0.020291    -0.0800774    -0.19333      0.0578133    -0.0401729   -0.0198306   -0.036192    -0.0930862    0.0273602   -0.00841879   0.0113995   -0.00196754   0.0651198   -0.0161638   -0.0514807    0.13296      0.0590989   0.00700913   0.0207369    0.0290295     0.0161457    0.0407687   -0.199236  
 -0.147943    -0.033325    -0.13884      0.0559861   -0.0947168    -0.0553126    0.128252      0.0161863    0.0092221   -0.107903     0.049248    -0.0452611   -0.0172498    0.00600662   0.0775206    0.0279122    0.176569    -0.184805    -0.131355     0.196926   -0.0810943    0.112276    -0.161945      0.00897875   0.011466     0.0572978 
  0.165777    -0.033998     0.0368629   -0.0171854    0.200004     -0.0679391    0.0500604     0.0783309    0.0189772   -0.149851    -0.0421635    0.0110558    0.123381     0.112886     0.267658    -0.139877     0.0290476   -0.146683    -0.207283    -0.0191605  -0.0105756   -0.0187248    0.0558914    -0.00843265   0.16754      0.0266541 kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4160686486012748
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416087
[ Info: iteration 2, average log likelihood -1.416027
[ Info: iteration 3, average log likelihood -1.415985
[ Info: iteration 4, average log likelihood -1.415939
[ Info: iteration 5, average log likelihood -1.415886
[ Info: iteration 6, average log likelihood -1.415824
[ Info: iteration 7, average log likelihood -1.415745
[ Info: iteration 8, average log likelihood -1.415626
[ Info: iteration 9, average log likelihood -1.415404
[ Info: iteration 10, average log likelihood -1.414949
[ Info: iteration 11, average log likelihood -1.414106
[ Info: iteration 12, average log likelihood -1.412917
[ Info: iteration 13, average log likelihood -1.411804
[ Info: iteration 14, average log likelihood -1.411137
[ Info: iteration 15, average log likelihood -1.410849
[ Info: iteration 16, average log likelihood -1.410741
[ Info: iteration 17, average log likelihood -1.410701
[ Info: iteration 18, average log likelihood -1.410685
[ Info: iteration 19, average log likelihood -1.410679
[ Info: iteration 20, average log likelihood -1.410676
[ Info: iteration 21, average log likelihood -1.410675
[ Info: iteration 22, average log likelihood -1.410674
[ Info: iteration 23, average log likelihood -1.410674
[ Info: iteration 24, average log likelihood -1.410673
[ Info: iteration 25, average log likelihood -1.410673
[ Info: iteration 26, average log likelihood -1.410673
[ Info: iteration 27, average log likelihood -1.410672
[ Info: iteration 28, average log likelihood -1.410672
[ Info: iteration 29, average log likelihood -1.410672
[ Info: iteration 30, average log likelihood -1.410672
[ Info: iteration 31, average log likelihood -1.410672
[ Info: iteration 32, average log likelihood -1.410672
[ Info: iteration 33, average log likelihood -1.410671
[ Info: iteration 34, average log likelihood -1.410671
[ Info: iteration 35, average log likelihood -1.410671
[ Info: iteration 36, average log likelihood -1.410671
[ Info: iteration 37, average log likelihood -1.410671
[ Info: iteration 38, average log likelihood -1.410671
[ Info: iteration 39, average log likelihood -1.410671
[ Info: iteration 40, average log likelihood -1.410671
[ Info: iteration 41, average log likelihood -1.410671
[ Info: iteration 42, average log likelihood -1.410671
[ Info: iteration 43, average log likelihood -1.410671
[ Info: iteration 44, average log likelihood -1.410671
[ Info: iteration 45, average log likelihood -1.410671
[ Info: iteration 46, average log likelihood -1.410671
[ Info: iteration 47, average log likelihood -1.410671
[ Info: iteration 48, average log likelihood -1.410670
[ Info: iteration 49, average log likelihood -1.410670
[ Info: iteration 50, average log likelihood -1.410670
┌ Info: EM with 100000 data points 50 iterations avll -1.410670
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4160872265880866
│     -1.4160273642422545
│      ⋮                 
└     -1.4106704442812057
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410685
[ Info: iteration 2, average log likelihood -1.410627
[ Info: iteration 3, average log likelihood -1.410583
[ Info: iteration 4, average log likelihood -1.410535
[ Info: iteration 5, average log likelihood -1.410478
[ Info: iteration 6, average log likelihood -1.410413
[ Info: iteration 7, average log likelihood -1.410339
[ Info: iteration 8, average log likelihood -1.410258
[ Info: iteration 9, average log likelihood -1.410175
[ Info: iteration 10, average log likelihood -1.410092
[ Info: iteration 11, average log likelihood -1.410012
[ Info: iteration 12, average log likelihood -1.409939
[ Info: iteration 13, average log likelihood -1.409875
[ Info: iteration 14, average log likelihood -1.409822
[ Info: iteration 15, average log likelihood -1.409778
[ Info: iteration 16, average log likelihood -1.409741
[ Info: iteration 17, average log likelihood -1.409711
[ Info: iteration 18, average log likelihood -1.409684
[ Info: iteration 19, average log likelihood -1.409661
[ Info: iteration 20, average log likelihood -1.409640
[ Info: iteration 21, average log likelihood -1.409621
[ Info: iteration 22, average log likelihood -1.409604
[ Info: iteration 23, average log likelihood -1.409589
[ Info: iteration 24, average log likelihood -1.409576
[ Info: iteration 25, average log likelihood -1.409565
[ Info: iteration 26, average log likelihood -1.409555
[ Info: iteration 27, average log likelihood -1.409546
[ Info: iteration 28, average log likelihood -1.409539
[ Info: iteration 29, average log likelihood -1.409532
[ Info: iteration 30, average log likelihood -1.409527
[ Info: iteration 31, average log likelihood -1.409522
[ Info: iteration 32, average log likelihood -1.409517
[ Info: iteration 33, average log likelihood -1.409513
[ Info: iteration 34, average log likelihood -1.409510
[ Info: iteration 35, average log likelihood -1.409507
[ Info: iteration 36, average log likelihood -1.409504
[ Info: iteration 37, average log likelihood -1.409501
[ Info: iteration 38, average log likelihood -1.409498
[ Info: iteration 39, average log likelihood -1.409496
[ Info: iteration 40, average log likelihood -1.409493
[ Info: iteration 41, average log likelihood -1.409491
[ Info: iteration 42, average log likelihood -1.409488
[ Info: iteration 43, average log likelihood -1.409486
[ Info: iteration 44, average log likelihood -1.409484
[ Info: iteration 45, average log likelihood -1.409482
[ Info: iteration 46, average log likelihood -1.409479
[ Info: iteration 47, average log likelihood -1.409477
[ Info: iteration 48, average log likelihood -1.409475
[ Info: iteration 49, average log likelihood -1.409472
[ Info: iteration 50, average log likelihood -1.409470
┌ Info: EM with 100000 data points 50 iterations avll -1.409470
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4106850268010835
│     -1.4106274623482606
│      ⋮                 
└     -1.4094701095333801
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409478
[ Info: iteration 2, average log likelihood -1.409419
[ Info: iteration 3, average log likelihood -1.409369
[ Info: iteration 4, average log likelihood -1.409313
[ Info: iteration 5, average log likelihood -1.409246
[ Info: iteration 6, average log likelihood -1.409167
[ Info: iteration 7, average log likelihood -1.409076
[ Info: iteration 8, average log likelihood -1.408976
[ Info: iteration 9, average log likelihood -1.408873
[ Info: iteration 10, average log likelihood -1.408771
[ Info: iteration 11, average log likelihood -1.408676
[ Info: iteration 12, average log likelihood -1.408591
[ Info: iteration 13, average log likelihood -1.408517
[ Info: iteration 14, average log likelihood -1.408454
[ Info: iteration 15, average log likelihood -1.408401
[ Info: iteration 16, average log likelihood -1.408357
[ Info: iteration 17, average log likelihood -1.408319
[ Info: iteration 18, average log likelihood -1.408286
[ Info: iteration 19, average log likelihood -1.408256
[ Info: iteration 20, average log likelihood -1.408229
[ Info: iteration 21, average log likelihood -1.408204
[ Info: iteration 22, average log likelihood -1.408179
[ Info: iteration 23, average log likelihood -1.408156
[ Info: iteration 24, average log likelihood -1.408133
[ Info: iteration 25, average log likelihood -1.408110
[ Info: iteration 26, average log likelihood -1.408088
[ Info: iteration 27, average log likelihood -1.408067
[ Info: iteration 28, average log likelihood -1.408046
[ Info: iteration 29, average log likelihood -1.408026
[ Info: iteration 30, average log likelihood -1.408007
[ Info: iteration 31, average log likelihood -1.407988
[ Info: iteration 32, average log likelihood -1.407970
[ Info: iteration 33, average log likelihood -1.407954
[ Info: iteration 34, average log likelihood -1.407938
[ Info: iteration 35, average log likelihood -1.407923
[ Info: iteration 36, average log likelihood -1.407909
[ Info: iteration 37, average log likelihood -1.407896
[ Info: iteration 38, average log likelihood -1.407883
[ Info: iteration 39, average log likelihood -1.407872
[ Info: iteration 40, average log likelihood -1.407861
[ Info: iteration 41, average log likelihood -1.407851
[ Info: iteration 42, average log likelihood -1.407841
[ Info: iteration 43, average log likelihood -1.407832
[ Info: iteration 44, average log likelihood -1.407823
[ Info: iteration 45, average log likelihood -1.407815
[ Info: iteration 46, average log likelihood -1.407808
[ Info: iteration 47, average log likelihood -1.407800
[ Info: iteration 48, average log likelihood -1.407793
[ Info: iteration 49, average log likelihood -1.407787
[ Info: iteration 50, average log likelihood -1.407780
┌ Info: EM with 100000 data points 50 iterations avll -1.407780
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.409477913979034 
│     -1.4094188830931649
│      ⋮                 
└     -1.4077802585852508
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407783
[ Info: iteration 2, average log likelihood -1.407723
[ Info: iteration 3, average log likelihood -1.407667
[ Info: iteration 4, average log likelihood -1.407600
[ Info: iteration 5, average log likelihood -1.407516
[ Info: iteration 6, average log likelihood -1.407410
[ Info: iteration 7, average log likelihood -1.407281
[ Info: iteration 8, average log likelihood -1.407132
[ Info: iteration 9, average log likelihood -1.406974
[ Info: iteration 10, average log likelihood -1.406817
[ Info: iteration 11, average log likelihood -1.406670
[ Info: iteration 12, average log likelihood -1.406539
[ Info: iteration 13, average log likelihood -1.406427
[ Info: iteration 14, average log likelihood -1.406332
[ Info: iteration 15, average log likelihood -1.406254
[ Info: iteration 16, average log likelihood -1.406190
[ Info: iteration 17, average log likelihood -1.406137
[ Info: iteration 18, average log likelihood -1.406093
[ Info: iteration 19, average log likelihood -1.406055
[ Info: iteration 20, average log likelihood -1.406024
[ Info: iteration 21, average log likelihood -1.405997
[ Info: iteration 22, average log likelihood -1.405973
[ Info: iteration 23, average log likelihood -1.405952
[ Info: iteration 24, average log likelihood -1.405933
[ Info: iteration 25, average log likelihood -1.405916
[ Info: iteration 26, average log likelihood -1.405900
[ Info: iteration 27, average log likelihood -1.405885
[ Info: iteration 28, average log likelihood -1.405872
[ Info: iteration 29, average log likelihood -1.405859
[ Info: iteration 30, average log likelihood -1.405846
[ Info: iteration 31, average log likelihood -1.405834
[ Info: iteration 32, average log likelihood -1.405822
[ Info: iteration 33, average log likelihood -1.405811
[ Info: iteration 34, average log likelihood -1.405800
[ Info: iteration 35, average log likelihood -1.405789
[ Info: iteration 36, average log likelihood -1.405779
[ Info: iteration 37, average log likelihood -1.405768
[ Info: iteration 38, average log likelihood -1.405757
[ Info: iteration 39, average log likelihood -1.405747
[ Info: iteration 40, average log likelihood -1.405737
[ Info: iteration 41, average log likelihood -1.405726
[ Info: iteration 42, average log likelihood -1.405716
[ Info: iteration 43, average log likelihood -1.405705
[ Info: iteration 44, average log likelihood -1.405695
[ Info: iteration 45, average log likelihood -1.405684
[ Info: iteration 46, average log likelihood -1.405673
[ Info: iteration 47, average log likelihood -1.405662
[ Info: iteration 48, average log likelihood -1.405652
[ Info: iteration 49, average log likelihood -1.405641
[ Info: iteration 50, average log likelihood -1.405630
┌ Info: EM with 100000 data points 50 iterations avll -1.405630
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4077830384729233
│     -1.407722932513263 
│      ⋮                 
└     -1.405629644905048 
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.405628
[ Info: iteration 2, average log likelihood -1.405556
[ Info: iteration 3, average log likelihood -1.405489
[ Info: iteration 4, average log likelihood -1.405409
[ Info: iteration 5, average log likelihood -1.405311
[ Info: iteration 6, average log likelihood -1.405189
[ Info: iteration 7, average log likelihood -1.405043
[ Info: iteration 8, average log likelihood -1.404877
[ Info: iteration 9, average log likelihood -1.404701
[ Info: iteration 10, average log likelihood -1.404524
[ Info: iteration 11, average log likelihood -1.404356
[ Info: iteration 12, average log likelihood -1.404201
[ Info: iteration 13, average log likelihood -1.404063
[ Info: iteration 14, average log likelihood -1.403942
[ Info: iteration 15, average log likelihood -1.403837
[ Info: iteration 16, average log likelihood -1.403747
[ Info: iteration 17, average log likelihood -1.403669
[ Info: iteration 18, average log likelihood -1.403602
[ Info: iteration 19, average log likelihood -1.403543
[ Info: iteration 20, average log likelihood -1.403491
[ Info: iteration 21, average log likelihood -1.403446
[ Info: iteration 22, average log likelihood -1.403404
[ Info: iteration 23, average log likelihood -1.403367
[ Info: iteration 24, average log likelihood -1.403333
[ Info: iteration 25, average log likelihood -1.403302
[ Info: iteration 26, average log likelihood -1.403273
[ Info: iteration 27, average log likelihood -1.403247
[ Info: iteration 28, average log likelihood -1.403221
[ Info: iteration 29, average log likelihood -1.403198
[ Info: iteration 30, average log likelihood -1.403175
[ Info: iteration 31, average log likelihood -1.403154
[ Info: iteration 32, average log likelihood -1.403134
[ Info: iteration 33, average log likelihood -1.403115
[ Info: iteration 34, average log likelihood -1.403096
[ Info: iteration 35, average log likelihood -1.403079
[ Info: iteration 36, average log likelihood -1.403062
[ Info: iteration 37, average log likelihood -1.403045
[ Info: iteration 38, average log likelihood -1.403030
[ Info: iteration 39, average log likelihood -1.403015
[ Info: iteration 40, average log likelihood -1.403001
[ Info: iteration 41, average log likelihood -1.402987
[ Info: iteration 42, average log likelihood -1.402974
[ Info: iteration 43, average log likelihood -1.402961
[ Info: iteration 44, average log likelihood -1.402949
[ Info: iteration 45, average log likelihood -1.402937
[ Info: iteration 46, average log likelihood -1.402925
[ Info: iteration 47, average log likelihood -1.402914
[ Info: iteration 48, average log likelihood -1.402904
[ Info: iteration 49, average log likelihood -1.402893
[ Info: iteration 50, average log likelihood -1.402883
┌ Info: EM with 100000 data points 50 iterations avll -1.402883
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4056275574860848
│     -1.4055564455827296
│      ⋮                 
└     -1.4028834145733382
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4160686486012748
│     -1.4160872265880866
│     -1.4160273642422545
│     -1.415985234133621 
│      ⋮                 
│     -1.402903670065055 
│     -1.402893373288528 
└     -1.4028834145733382
32×26 Array{Float64,2}:
 -0.245441   -0.329419     0.0434807  -0.371634    0.410029     0.116046    -0.134981    -0.728715   -0.433598    0.261922    0.149043    -0.573268   -0.0124265  -0.0414561   -0.00494379   0.473982     0.2706      -0.274894   -0.23257     0.0511525   0.145202   -0.316585   -0.082254     -0.58104      0.800678     0.169002  
  0.054417    0.0524025    0.0453987  -0.209325   -0.0765577   -0.165112    -0.589822     0.0824706  -0.565795    0.0605937   0.0105452   -0.480619   -0.0253173  -0.596411     0.124229     0.344553     0.56039      0.370159    0.172711   -0.117266    0.611913   -0.490952    0.109274     -0.766717     0.366204     0.111116  
  0.356925   -0.317866     0.538906   -0.143093   -0.272519     0.17382     -0.407344    -0.603907   -0.250182   -0.20995     0.431032    -0.318853    0.690418   -0.90866     -0.432633     0.275449     0.285114    -0.628665    0.0108805  -0.0557134   0.217968    0.0243157  -0.0210006     0.837337    -0.118769     0.0821218 
  0.100912   -0.168932     0.102611   -0.699431    0.244332    -0.00535217  -0.00787146  -0.0969172  -0.342738    0.109919    0.361162     0.0955796   0.409692   -0.891769     0.851744     0.205018     0.036661    -0.524037   -0.835144   -0.0360031  -0.33697    -0.0201833   0.0725451     0.743303     0.171489     0.579264  
  0.0381069  -0.193083     0.222449   -0.655723   -0.126968     0.328962    -0.0472075   -0.260117   -0.226825   -0.27888    -0.624253    -0.175646    0.549077    0.0840293    0.0772708    0.437843    -0.0558981    0.338102    0.368111   -0.149952   -0.372566   -0.0577776   0.0524395    -0.088071    -0.493647    -0.296937  
 -0.0539902   0.490461    -0.0410163  -0.32191     0.457931    -0.3246      -0.405329    -0.407112    0.301632    0.145327   -0.463016    -0.200536    0.173553   -0.49542     -0.136423     0.0652474   -0.32387     -0.203801    0.0424746  -0.045136    0.299477   -0.376109    0.168377      0.190695    -0.167697    -0.401386  
 -0.105037    0.528235     0.157675    0.101482   -0.769473     0.187659    -0.93567      0.252669   -0.227848    0.277039   -0.00658132  -0.296214    0.242393    0.386306    -0.622651     0.26038     -0.010012     0.489121   -0.430296   -0.0987585   0.151124   -0.225515    0.198713      0.276848    -0.327494    -0.16581   
  0.403532    0.384902    -0.0212469   0.538147   -0.0124066   -0.0529563    0.0465501    0.408742   -0.143402   -0.116717   -0.560962    -0.20409     0.10661     0.854267    -0.607004     0.542267    -0.323698     0.494368    0.524487    0.401599   -0.28582     0.0355593   0.0050698    -0.0528929    0.261476    -0.0284368 
  0.0246205  -0.0296863    0.0775513   0.0239248   0.00913773  -0.0519098    0.0461884   -0.101154   -0.155957   -0.0372129  -0.132398    -0.118356    0.167881    0.0468854   -0.262313     0.167773     0.0358779   -0.0731705   0.0132834   0.160148   -0.118722    0.0648     -0.105988     -0.0649286    0.114116    -0.124393  
  0.069784   -0.163716    -0.0858287  -0.156193   -0.0387437    0.191337    -0.00394952   0.202801    0.0926346  -0.0923801   0.021128     0.0597499  -0.079297    0.00894451   0.392765    -0.0717828   -0.00985228   0.0951074  -0.024995   -0.131252    0.12669    -0.0629044   0.0463184    -0.0387477   -0.108816     0.0660142 
 -0.082572   -0.269173    -0.0840428   0.337991   -0.0748707    0.38462      0.232543    -0.131996    0.556424   -0.225378    0.123476     0.260828   -0.21037     0.350448    -0.0249587   -0.00140786  -0.317513    -0.284091   -0.161077    0.578725   -0.46177     0.0761048  -0.436842      0.402129    -0.347735    -0.470659  
  0.0537569   0.432491    -0.147011    0.428786    0.109089    -0.144562     0.115586     0.146934    0.473763   -0.130798   -0.25885      0.671541   -0.0338076   0.400425     0.00993825  -0.515177     0.177326     0.11543    -0.126941   -0.0630555  -0.546899   -0.129314   -0.357051     -0.371125    -0.148805    -0.141913  
  0.304764    0.408829     0.0506683   0.5531     -0.249052    -0.0322128    0.267736     0.330714    0.0292232   0.362687    0.00974619   0.080777   -0.433037    0.152054     0.102344    -0.345506    -0.417999    -0.660313   -0.227745    0.318596    0.706698   -0.0794332  -0.205985     -0.0251354    0.503576     0.0541259 
  0.0351643  -0.0716003   -0.192842    0.316876    0.689261    -0.587343     0.136304     0.0893924   0.0504168   0.250806   -0.145168     0.393247   -0.805451    0.131155     0.568389    -0.308872    -0.273791     0.0719726   0.711333   -0.134268    0.534668    0.116792    0.0244606    -0.333397     0.027121    -0.109571  
 -0.269466   -0.342235    -0.140249    0.270765   -0.0399372   -0.534613     0.088558    -0.157072    0.174945    0.286032    0.610678    -0.0603303  -0.478807   -0.220005    -0.0433082   -0.101567     0.277652    -0.162245   -0.0826306   0.25103     0.482297    0.175306    0.163846      0.161065     0.251077     0.28118   
 -0.0636153   0.595601     0.220567    0.156442   -0.0291682   -0.40313     -0.0553144    0.120162    0.0836395  -0.368381    0.274582     0.135283    0.0666679  -0.258063    -0.158563    -0.246824     0.00404843  -0.156409   -0.0398161  -0.156582   -0.0369564   0.335617    0.330179      0.195245    -0.00669318   0.409762  
 -0.0977369  -0.165287    -0.235425   -0.42954    -0.174897     0.189944     0.161849    -0.135437   -0.292888   -0.480295   -0.401196    -0.12514    -0.200886    0.0891729    0.174552     0.0403738   -0.141283    -0.0846062  -0.327718    0.874814    0.498334   -0.892628    0.335022     -0.55693     -0.672316    -0.422529  
 -0.230992   -0.658002    -0.201344    0.223035   -0.28132      0.204597     0.136771     0.189652   -0.0158437   0.480878   -0.197171    -0.700044    0.181629   -0.19684      0.0301488    0.329684    -0.658136     0.163153    0.164933    0.574894    0.528521   -0.261025   -0.00991713    0.605879     0.29211     -0.488719  
 -0.0698804  -0.0524064    0.0860922  -0.0237393  -0.0992565    0.263191    -0.0962203    0.029667   -0.145578   -0.14589     0.180378    -0.193006   -0.0665982  -0.188528     0.229034     0.0990291    0.0827442   -0.0882413   0.0585916  -0.0513426   0.214202    0.017183   -0.0518396    -0.0717056    0.00887246  -0.0176675 
  0.130998    0.669684    -0.162826    0.0459575   0.262972    -0.823504    -0.319429    -0.302011    0.252916    0.219652   -0.188999     0.0584842   0.2619     -0.0325467   -0.405121    -0.00465856   0.0368125   -0.0633734  -0.177796    0.254258   -0.0713901  -0.367762    0.000605439  -0.0237153    0.442861     0.00988915
 -0.227592    0.00356846  -0.154174   -0.10934     0.269644     0.0580245    0.37105     -0.0977052   0.233269    0.161893   -0.42956     -0.551279    0.494715   -0.248017    -0.822965     0.345317    -0.393283    -0.484245   -0.271282   -0.692189    0.561234    1.0577     -0.153828     -0.264611     0.377864    -0.362545  
 -0.277204   -0.537818    -0.324454    0.413179   -0.328403     0.456383     0.714386     0.0486335   0.147899   -0.489661   -0.0967059   -0.367802    0.0462621  -0.108265    -0.339826     0.149778     0.224691    -0.385307   -0.707979    0.495966   -0.748077    0.338731   -0.679873     -0.00335821   0.0411569   -0.177102  
  0.325078   -0.206374     0.135876    0.230673    0.180728     0.212143     0.240865     0.148605    0.138172   -0.466023   -0.00288408   0.0580168  -0.0585657  -0.430294     0.908639     0.278241     0.150063    -0.551224    0.646947   -0.0594693  -0.301       0.0303745  -0.657318      0.401909     0.418455     0.00767843
  0.151623   -0.515593    -0.194084    0.338303    0.510234     0.126622     0.0535603   -0.12565    -0.0600779   0.275806    0.367379     0.298536    0.331284    0.65566      0.196165     0.318795     0.098116    -0.207967    0.0854025   0.421412   -0.547614   -0.255656   -0.130591      0.226047     0.709787     0.0633823 
 -0.119097    0.0680938    0.274458   -0.47114     0.151655    -0.244598     0.207351    -0.313863    0.0670264  -0.637049    0.229051     0.395203   -0.389588    0.00446097  -0.0741738   -0.301772     0.446519    -0.521495   -0.194045   -0.190495   -0.293616    0.0872056   0.131187     -0.939833     0.0645999    0.327776  
  0.156403    0.354643     0.211311   -0.29692     0.155233     0.302499    -0.511673    -0.432488   -0.241006   -0.437198    0.173352     0.432311    0.945111   -0.134177    -0.265452     0.0939555    0.370479     0.289761   -0.447753   -0.252564   -0.652067   -0.107847   -0.153118     -0.304       -0.299842     0.0836275 
 -0.139989   -0.260545     0.279811    0.151504   -0.409291     0.643975     0.410675     0.614906   -0.455563    0.0799951   0.332449     0.200666   -0.0926522   0.192232     0.237552    -0.244156     0.419525     0.331386   -0.173773   -0.301025    0.145531    0.754135   -0.0402665     0.0383253   -0.196227     0.242764  
  0.475932    0.509251    -0.144621   -0.364736    0.0331592    0.0588454    0.121472     0.894817   -0.041576   -0.19536     0.00779504  -0.147406    0.314067   -0.477972     0.168518    -0.33879     -0.344742     0.206616    0.0354676  -0.573161    0.0751351   0.311196    0.309711     -0.0349209    0.151353     0.422419  
 -0.152649    0.227772     0.0185631   0.182447   -0.13499     -0.0311532   -0.127796     0.440979    0.651158   -0.363977   -0.407727    -0.186104   -0.384353    0.625931    -0.414061    -0.358714    -0.458764    -0.0780178   0.574132    0.306386    0.25678     0.397128    0.196103      0.329888    -1.13691     -0.368214  
  0.087427   -0.0969008    0.295914    0.141391    0.225423    -0.153421     0.464447    -0.0567862   0.683618    0.239309   -0.0226684    0.868741    0.0446942   0.573603    -0.209794    -0.691169    -0.286802    -0.0344037  -0.0762226  -0.358058   -0.720797    0.653352    0.0307045     0.844907    -0.394291     0.136604  
 -0.953205   -0.255599    -0.299835    0.189592    0.106456    -0.0608086    0.197297    -0.358277    0.18662     0.295634   -0.504414     0.726946   -0.28709     0.315791     0.039061    -0.130593     0.496875    -0.0728659  -0.586227    0.118358   -0.569811   -0.163391   -0.116609     -0.373719    -0.418937    -0.478212  
  0.317155    0.0455852    0.0521069   0.117469   -0.670793    -0.0847503   -0.202824     0.311183   -0.0359908  -0.494999    0.478325     0.564585   -0.386383    0.464525     0.640508    -0.0425989    0.407346     0.400729    0.551604    0.658071   -0.43624    -0.339082    0.138641      0.312137    -0.293657     0.46531   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.402874
[ Info: iteration 2, average log likelihood -1.402864
[ Info: iteration 3, average log likelihood -1.402855
[ Info: iteration 4, average log likelihood -1.402847
[ Info: iteration 5, average log likelihood -1.402838
[ Info: iteration 6, average log likelihood -1.402830
[ Info: iteration 7, average log likelihood -1.402822
[ Info: iteration 8, average log likelihood -1.402814
[ Info: iteration 9, average log likelihood -1.402807
[ Info: iteration 10, average log likelihood -1.402799
┌ Info: EM with 100000 data points 10 iterations avll -1.402799
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.122349e+05
      1       6.961355e+05      -2.160994e+05 |       32
      2       6.812874e+05      -1.484810e+04 |       32
      3       6.762371e+05      -5.050288e+03 |       32
      4       6.735677e+05      -2.669478e+03 |       32
      5       6.718206e+05      -1.747105e+03 |       32
      6       6.706091e+05      -1.211449e+03 |       32
      7       6.697423e+05      -8.667821e+02 |       32
      8       6.691027e+05      -6.396125e+02 |       32
      9       6.685826e+05      -5.201032e+02 |       32
     10       6.681461e+05      -4.365455e+02 |       32
     11       6.678052e+05      -3.408217e+02 |       32
     12       6.675312e+05      -2.740715e+02 |       32
     13       6.672746e+05      -2.565994e+02 |       32
     14       6.670186e+05      -2.560234e+02 |       32
     15       6.667715e+05      -2.470017e+02 |       32
     16       6.665463e+05      -2.252433e+02 |       32
     17       6.663413e+05      -2.050349e+02 |       32
     18       6.661440e+05      -1.972857e+02 |       32
     19       6.659780e+05      -1.659439e+02 |       32
     20       6.658232e+05      -1.548220e+02 |       32
     21       6.656774e+05      -1.458034e+02 |       32
     22       6.655488e+05      -1.286428e+02 |       32
     23       6.654323e+05      -1.165093e+02 |       32
     24       6.653340e+05      -9.822927e+01 |       32
     25       6.652446e+05      -8.948194e+01 |       32
     26       6.651650e+05      -7.956432e+01 |       32
     27       6.650909e+05      -7.412533e+01 |       32
     28       6.650198e+05      -7.105278e+01 |       32
     29       6.649445e+05      -7.529817e+01 |       32
     30       6.648842e+05      -6.026526e+01 |       32
     31       6.648334e+05      -5.089173e+01 |       32
     32       6.647859e+05      -4.749309e+01 |       32
     33       6.647302e+05      -5.562840e+01 |       32
     34       6.646815e+05      -4.876143e+01 |       32
     35       6.646365e+05      -4.501014e+01 |       32
     36       6.646000e+05      -3.645112e+01 |       32
     37       6.645640e+05      -3.598505e+01 |       32
     38       6.645302e+05      -3.384698e+01 |       32
     39       6.644959e+05      -3.424299e+01 |       32
     40       6.644640e+05      -3.191745e+01 |       32
     41       6.644310e+05      -3.301195e+01 |       32
     42       6.643934e+05      -3.757673e+01 |       32
     43       6.643610e+05      -3.246769e+01 |       32
     44       6.643306e+05      -3.037530e+01 |       32
     45       6.642961e+05      -3.445989e+01 |       32
     46       6.642631e+05      -3.299313e+01 |       32
     47       6.642360e+05      -2.709846e+01 |       32
     48       6.642111e+05      -2.489977e+01 |       32
     49       6.641877e+05      -2.344110e+01 |       32
     50       6.641651e+05      -2.257983e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 664165.1139139216)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415146
[ Info: iteration 2, average log likelihood -1.410007
[ Info: iteration 3, average log likelihood -1.408644
[ Info: iteration 4, average log likelihood -1.407650
[ Info: iteration 5, average log likelihood -1.406598
[ Info: iteration 6, average log likelihood -1.405590
[ Info: iteration 7, average log likelihood -1.404854
[ Info: iteration 8, average log likelihood -1.404413
[ Info: iteration 9, average log likelihood -1.404154
[ Info: iteration 10, average log likelihood -1.403985
[ Info: iteration 11, average log likelihood -1.403863
[ Info: iteration 12, average log likelihood -1.403767
[ Info: iteration 13, average log likelihood -1.403688
[ Info: iteration 14, average log likelihood -1.403621
[ Info: iteration 15, average log likelihood -1.403562
[ Info: iteration 16, average log likelihood -1.403510
[ Info: iteration 17, average log likelihood -1.403464
[ Info: iteration 18, average log likelihood -1.403422
[ Info: iteration 19, average log likelihood -1.403384
[ Info: iteration 20, average log likelihood -1.403349
[ Info: iteration 21, average log likelihood -1.403317
[ Info: iteration 22, average log likelihood -1.403287
[ Info: iteration 23, average log likelihood -1.403260
[ Info: iteration 24, average log likelihood -1.403234
[ Info: iteration 25, average log likelihood -1.403211
[ Info: iteration 26, average log likelihood -1.403188
[ Info: iteration 27, average log likelihood -1.403167
[ Info: iteration 28, average log likelihood -1.403147
[ Info: iteration 29, average log likelihood -1.403128
[ Info: iteration 30, average log likelihood -1.403110
[ Info: iteration 31, average log likelihood -1.403092
[ Info: iteration 32, average log likelihood -1.403075
[ Info: iteration 33, average log likelihood -1.403059
[ Info: iteration 34, average log likelihood -1.403044
[ Info: iteration 35, average log likelihood -1.403029
[ Info: iteration 36, average log likelihood -1.403015
[ Info: iteration 37, average log likelihood -1.403001
[ Info: iteration 38, average log likelihood -1.402988
[ Info: iteration 39, average log likelihood -1.402975
[ Info: iteration 40, average log likelihood -1.402963
[ Info: iteration 41, average log likelihood -1.402951
[ Info: iteration 42, average log likelihood -1.402940
[ Info: iteration 43, average log likelihood -1.402928
[ Info: iteration 44, average log likelihood -1.402918
[ Info: iteration 45, average log likelihood -1.402907
[ Info: iteration 46, average log likelihood -1.402897
[ Info: iteration 47, average log likelihood -1.402888
[ Info: iteration 48, average log likelihood -1.402878
[ Info: iteration 49, average log likelihood -1.402869
[ Info: iteration 50, average log likelihood -1.402860
┌ Info: EM with 100000 data points 50 iterations avll -1.402860
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.141033    0.482318     0.0568005     0.149629    0.186454     0.136876   -0.129033     0.0867224   0.255173   -0.276497   -0.197715    0.841805    0.217164     0.330263    -0.200719   -0.332004    0.142825    0.332016   -0.324882    -0.251664    -0.566201    0.0278328  -0.0432997   -0.324611    -0.760728   -0.274941  
  0.202189    0.0682381    0.44771      -0.376907   -0.259065     0.219932   -0.624567    -0.496453   -0.190583   -0.132522    0.420229   -0.0994931   0.919635    -0.554252    -0.363532    0.370334    0.368125    0.104501   -0.4805      -0.36467     -0.264524    0.0728215   0.105126     0.382789    -0.188158    0.118751  
  0.36417     0.58391      0.261336      0.170384   -0.70836      0.266885   -0.10418      1.00258     0.247642    0.155908   -0.356933   -0.282019    0.169069     0.543099    -0.182996    0.0935639  -0.599514    0.139012    0.0866178    0.469238     0.122469    0.108839    0.110697     0.541242    -0.515806   -0.177432  
 -0.191882   -0.233164    -0.0573576     0.0285319  -0.0605203   -0.261289    0.156617     0.139       0.117867    0.0900302   0.363757   -0.220501   -0.425294    -0.3573       0.0977469  -0.178594   -0.145446   -0.298896   -0.0257278    0.0683316    0.849873    0.130191    0.272268     0.14882      0.17983     0.310255  
  0.219321   -0.398145    -0.159         0.131212    0.111087     0.200103    0.25319     -0.0127955   0.0929394   0.0872489  -0.243274   -0.110341    0.175572     0.242445     0.0833603   0.375396   -0.310598   -0.0992514   0.245655     0.339699    -0.166721   -0.0518428  -0.382321     0.264577     0.138484   -0.372728  
  0.156022   -0.8599      -0.234602     -0.64883     0.502917     0.394624   -0.385114    -0.683915   -0.563548    0.70266    -0.13802    -0.224956    0.370596    -0.164323     0.250571    0.410979   -0.112427   -0.550694   -0.446179     0.0406819    0.0538567  -0.641081    0.0626839    0.0591256    0.465425    0.19367   
  0.0524543   0.384584     0.0275663     0.459124   -0.57316     -0.355423    0.122325     0.436494    0.0901313  -0.754627    0.197267    0.277437   -0.0113765   -0.205189     0.0655633  -0.226892    0.423151    0.229258    0.43524     -0.161129    -0.341336    0.628503    0.064763     0.276001    -0.175691    0.548329  
 -0.0759635  -0.144074    -0.0882574    -0.154475    0.0940501    0.0365057  -0.0486807   -0.0202695  -0.209089    0.179299   -0.0890389  -0.593562    0.201244    -0.374959     0.0170797   0.271465   -0.130363   -0.0283824  -0.0706279    0.0861619    0.395234   -0.0926608   0.132453    -0.0641389    0.373506   -0.161846  
 -0.190399   -0.561515    -0.310772      0.433604   -0.124289     0.753917    0.555881    -0.0856105   0.52354    -0.425844    0.160619    0.191302   -0.315148     0.272297     0.0857534   0.0453115  -0.237735   -0.302279   -0.39032      0.612313    -0.650229    0.336064   -0.697166     0.359586    -0.282558   -0.410626  
  0.0217706   0.0693518    0.0277113    -0.0150465   0.00482398  -0.0160501  -0.0139114    0.0234348   0.105865   -0.140184    0.0273073   0.086236    0.0441362   -0.0231441    0.0302444  -0.0710194   0.0339386  -0.0797664  -0.0664812   -0.0405739   -0.0716428   0.0288376  -0.028524     0.00472937  -0.0276187   0.0104798 
  0.10547     0.29869     -0.038328     -0.0600796   0.566812    -0.320238   -0.545048    -0.232186   -0.211013    0.549577   -0.172183    0.183761   -0.369661    -0.47947      0.426405   -0.137709    0.105422    0.267283    0.309684    -0.484267     0.735115   -0.386035   -0.130381    -0.358194     0.117596   -0.22993   
  0.129963   -0.551711     0.255165      0.129832    0.103663     0.115742   -0.0741579   -0.101855    0.10089    -0.0384625   0.423801    0.0145887  -0.0324544   -0.332455     0.64042     0.817676    0.399765   -0.137731    0.602977    -0.0800519   -0.242854    0.600868   -0.465304     0.696535     0.722982    0.273087  
 -0.130546    0.213119    -0.062284      0.297246   -0.0391525   -0.481499    0.28645     -0.415832    0.506706    0.530771   -0.374822   -0.136238   -0.0281353    0.178771    -0.624544   -0.171332   -0.187102   -0.280553   -0.419997     0.5445       0.228168   -0.285138    0.0389708   -0.130941     0.157477   -0.622282  
  0.468086    0.442402     0.0278658     0.673092    0.154293    -0.10105    -0.215367     0.371374   -0.288556   -0.106032   -0.534208    0.0427254  -0.00668521   0.855097    -0.506441    0.540623   -0.34969     0.405361    0.508706     0.275462    -0.180993   -0.161935   -0.221932     0.0479347    0.635449    0.134409  
  0.0196587   0.0558724    0.266921     -0.0642099  -0.376562     0.637878    0.30951      0.719607   -0.314553    0.0126555   0.227816    0.131909    0.019894    -0.0072196    0.313566   -0.605777    0.124216    0.20357    -0.221613    -0.534118     0.197969    0.489574    0.071745     0.137785    -0.33975     0.319126  
 -0.190475    0.372452     0.0188538     0.0275039  -0.330959     0.189255   -0.732073    -0.346275    0.105574    0.365764   -0.492482   -0.381384    0.258254     0.126143    -0.362876    0.199254    0.0108529   0.542576   -0.281078     0.214058     0.11133    -0.579542   -0.404131     0.192029    -0.375091   -0.986973  
 -0.187116    0.00184074  -0.040328     -0.38511     0.392568    -0.336445   -0.00883577  -0.503155   -0.266844   -0.394992    0.71604     0.345451    0.0315486   -0.37899     -0.130048   -0.261262    0.505568   -0.428813   -0.237961    -0.0941501   -0.0377858  -0.056176    0.00503477  -0.617918     0.338337    0.731998  
 -0.123319    0.0206676   -0.0775821     0.031776   -0.545505     0.0553084   0.0594798    0.168847   -0.0947628  -0.386435    0.136634    0.308758   -0.343955     0.330972     0.205151   -0.166854    0.252814    0.178524   -0.0118073    0.442868    -0.0773431  -0.132927    0.200463    -0.245664    -0.546325    0.165534  
 -0.0627064  -0.191562     0.0664916     0.439898   -0.0196352    0.286338    0.386103     0.0602568  -0.460767    0.211924    0.186426    0.0602717  -0.0539654    0.285948     0.0575265   0.0278771   0.391202   -0.0937074  -0.399842     0.132242    -0.339045    0.171607   -0.175975    -0.562982     0.575007    0.274631  
  0.0366324   0.00354229  -0.0407377     0.223072   -0.0727958   -0.446953   -0.232082    -0.156643   -0.099153   -0.147247    0.304901    0.431817   -0.0536562    0.0698411    0.446859   -0.322886    0.557981    0.0503519   0.190977     0.835479    -0.594849   -0.732868   -0.137285     0.453955    -0.114565    0.0385124 
 -0.0669309  -0.0722116    0.125267     -0.179278   -0.201144    -0.0787963  -0.468509     0.103839   -0.492096    0.259512   -0.165115   -0.293146    0.0478017    0.0945339   -0.291316    0.413691    0.159222    0.53313     0.0229744   -0.0321344    0.279922    0.0788364   0.436662    -0.223637    -0.0241237   0.0872994 
  0.0512741  -0.0280434   -0.226417      0.435618    0.456569    -0.413689    0.823947     0.30317     0.172119    0.118982   -0.221346    0.294583   -0.640173     0.239925     0.651423   -0.465098   -0.396472   -0.269873    0.508949     0.131242     0.223515    0.315924   -0.00896229  -0.394907     0.200412   -0.084985  
 -0.0347809   0.835391    -0.000845443  -0.452483    0.50462     -0.717835   -0.230175    -0.151274    0.128499   -0.125156   -0.256137   -0.364013    0.394537    -0.461365    -0.173361    0.225592   -0.308393   -0.291476   -0.00261439   0.111855    -0.0669763  -0.134992    0.437881     0.145968     0.323746    0.356914  
  0.187888    0.327335     0.0357704     0.337679    0.212503    -0.324199    0.04142      0.257007    0.590999    0.474559    0.681683    0.58964    -0.187927     0.393379    -0.190866   -0.47725    -0.394438   -0.179814   -0.185089    -0.107738    -0.274336    0.44958     0.106745     0.60949      0.241033    0.53482   
 -0.299952   -0.163274     0.0132376     0.0161375  -0.354791     0.197946   -0.342282     0.0462384  -0.28364    -0.0720918   0.418781   -0.813825   -0.162186    -0.104783     0.123387    0.464228    0.0252644  -0.133347   -0.0152637    0.583634     0.506872   -0.57058     0.0776384   -0.319985     0.551303    0.00338764
 -0.198376   -0.0180451   -0.200739      0.40616     0.254554    -0.201414   -0.597907     0.0291606   0.631556   -0.621894   -0.0995089  -0.0861796  -0.806618     0.829139    -0.407929   -0.293336   -0.326521   -0.0804389   0.81824      0.035463     0.525557    0.19228     0.108603    -0.0887914   -0.651522   -0.3743    
 -0.618283   -0.240094     0.218973     -0.119425    0.418092    -0.419472    0.3325      -0.592643    0.414306   -0.0310643  -0.635       0.772246   -0.158976     0.510968    -0.0861243  -0.191186    0.382832   -0.360779   -0.17114     -0.172652    -0.844332    0.0317986  -0.2276      -0.333151    -0.328157   -0.422962  
 -0.0296055  -0.0933057    0.123744     -0.595993   -0.166677     0.454806    0.00230996  -0.313874   -0.341567   -0.681403   -0.493742   -0.228051    0.362757     0.00270003   0.0873737   0.387848    0.0165354   0.200895    0.2823      -0.0329315   -0.274999   -0.20736     0.140533    -0.29094     -0.480093   -0.124105  
  0.0869456  -0.0195177    0.455972      0.0113297  -0.179772     0.141488   -0.168538    -0.267824    0.0206084  -0.412602    0.0797617  -0.069792    0.0538259   -1.01844      0.070601   -0.111256   -0.0129862  -1.25147     0.0231867    0.00412088   0.397226   -0.225472   -0.217893     0.610107    -0.382544   -0.335835  
  0.290556   -0.448214    -0.374019     -0.266221    0.204448    -0.743993    0.290109     0.177579    0.553683    0.342026   -0.602592    0.357933    0.675954    -0.151052    -0.0916232  -0.324304   -0.396567    0.656376    0.787134     0.0415151    0.166634    0.0780323   0.645177     0.808397    -1.10033    -0.313085  
  0.665254    0.417574    -0.00965171   -0.216056    0.329262     0.101951   -0.0661666    0.38056     0.249693   -0.6451     -0.122434    0.195439   -0.142542    -0.221534     0.57184     0.0143069   0.339396   -0.302296   -0.096179    -0.315976    -0.246614   -0.797793   -0.560555    -0.506709     0.641428   -0.127784  
 -0.0697273   0.102097    -0.142318     -0.141371    0.223334     0.128354    0.307296     0.0599237   0.104814   -0.0378023  -0.43552    -0.545095    0.592848    -0.317179    -0.667504    0.25317    -0.253336   -0.337375   -0.20082     -0.7784       0.314521[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
    0.979561   -0.361041    -0.229192     0.45856    -0.236115  [ Info: iteration 1, average log likelihood -1.402852
[ Info: iteration 2, average log likelihood -1.402844
[ Info: iteration 3, average log likelihood -1.402836
[ Info: iteration 4, average log likelihood -1.402828
[ Info: iteration 5, average log likelihood -1.402821
[ Info: iteration 6, average log likelihood -1.402813
[ Info: iteration 7, average log likelihood -1.402806
[ Info: iteration 8, average log likelihood -1.402799
[ Info: iteration 9, average log likelihood -1.402793
[ Info: iteration 10, average log likelihood -1.402786
┌ Info: EM with 100000 data points 10 iterations avll -1.402786
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
