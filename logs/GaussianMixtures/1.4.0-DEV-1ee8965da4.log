 Resolving package versions...
 Installed Missings ─────────── v0.4.3
 Installed GaussianMixtures ─── v0.3.0
 Installed Distances ────────── v0.8.2
 Installed Rmath ────────────── v0.5.1
 Installed NearestNeighbors ─── v0.4.3
 Installed BinDeps ──────────── v0.8.10
 Installed Parameters ───────── v0.12.0
 Installed Clustering ───────── v0.13.3
 Installed SortingAlgorithms ── v0.3.1
 Installed DataAPI ──────────── v1.1.0
 Installed QuadGK ───────────── v2.1.1
 Installed Arpack ───────────── v0.3.1
 Installed CMake ────────────── v1.1.2
 Installed DataStructures ───── v0.17.6
 Installed Distributions ────── v0.21.8
 Installed Blosc ────────────── v0.5.1
 Installed ScikitLearnBase ──── v0.5.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed URIParser ────────── v0.4.0
 Installed StatsFuns ────────── v0.9.0
 Installed StatsBase ────────── v0.32.0
 Installed StaticArrays ─────── v0.12.1
 Installed PDMats ───────────── v0.9.10
 Installed OrderedCollections ─ v1.1.0
 Installed HDF5 ─────────────── v0.12.5
 Installed JLD ──────────────── v0.9.1
 Installed LegacyStrings ────── v0.4.1
 Installed BinaryProvider ───── v0.5.8
 Installed SpecialFunctions ─── v0.8.0
 Installed FileIO ───────────── v1.0.7
 Installed Compat ───────────── v2.2.0
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.3.1
  [9e28174c] + BinDeps v0.8.10
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.8
  [5789e2e9] + FileIO v1.0.7
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.3
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.1.1
  [79098fc4] + Rmath v0.5.1
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.8.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.0
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath ───────────→ `~/.julia/packages/Rmath/4wt82/deps/build.log`
  Building CMake ───────────→ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Arpack ──────────→ `~/.julia/packages/Arpack/cu5By/deps/build.log`
  Building Blosc ───────────→ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 ────────────→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Building SpecialFunctions → `~/.julia/packages/SpecialFunctions/ne2iw/deps/build.log`
   Testing GaussianMixtures
Status `/tmp/jl_AcjKei/Manifest.toml`
  [7d9fca2a] Arpack v0.3.1
  [9e28174c] BinDeps v0.8.10
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.8
  [5789e2e9] FileIO v1.0.7
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.3
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.1.1
  [79098fc4] Rmath v0.5.1
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.8.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.0
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -3.7838470242774133e6, [1329.4949956709622, 98670.50500432904], [634.0274684513498 -749.4601063479147 546.7351180177433; -1218.4987165909245 1201.1253629808066 -1131.5144387116384], [[1868.7700091755735 -891.5683568370846 -311.775384609574; -891.5683568370846 2813.244091080158 1583.1051557882697; -311.775384609574 1583.1051557882697 1742.6048476078834], [97907.9075780534 597.6420767107757 120.30104139097678; 597.6420767107757 97195.88815994447 -1640.4734472712717; 120.30104139097675 -1640.4734472712717 98074.34306951116]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.222820e+03
      1       1.052175e+03      -1.706443e+02 |        4
      2       9.924635e+02      -5.971181e+01 |        2
      3       9.724609e+02      -2.000262e+01 |        0
      4       9.724609e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 972.4609200273935)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.077330
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.739251
[ Info: iteration 2, lowerbound -3.625938
[ Info: iteration 3, lowerbound -3.507457
[ Info: iteration 4, lowerbound -3.361783
[ Info: iteration 5, lowerbound -3.188261
[ Info: iteration 6, lowerbound -2.999489
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.815264
[ Info: iteration 8, lowerbound -2.663356
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.548636
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.462016
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.401205
[ Info: iteration 12, lowerbound -2.357363
[ Info: iteration 13, lowerbound -2.328404
[ Info: iteration 14, lowerbound -2.311182
[ Info: iteration 15, lowerbound -2.307832
[ Info: dropping number of Gaussions to 2
[ Info: iteration 16, lowerbound -2.302918
[ Info: iteration 17, lowerbound -2.299260
[ Info: iteration 18, lowerbound -2.299256
[ Info: iteration 19, lowerbound -2.299254
[ Info: iteration 20, lowerbound -2.299254
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sun Nov 24 00:27:00 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Sun Nov 24 00:27:09 2019: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Sun Nov 24 00:27:11 2019: EM with 272 data points 0 iterations avll -2.077330
5.8 data points per parameter
, Sun Nov 24 00:27:13 2019: GMM converted to Variational GMM
, Sun Nov 24 00:27:22 2019: iteration 1, lowerbound -3.739251
, Sun Nov 24 00:27:22 2019: iteration 2, lowerbound -3.625938
, Sun Nov 24 00:27:22 2019: iteration 3, lowerbound -3.507457
, Sun Nov 24 00:27:22 2019: iteration 4, lowerbound -3.361783
, Sun Nov 24 00:27:22 2019: iteration 5, lowerbound -3.188261
, Sun Nov 24 00:27:22 2019: iteration 6, lowerbound -2.999489
, Sun Nov 24 00:27:22 2019: dropping number of Gaussions to 7
, Sun Nov 24 00:27:22 2019: iteration 7, lowerbound -2.815264
, Sun Nov 24 00:27:22 2019: iteration 8, lowerbound -2.663356
, Sun Nov 24 00:27:22 2019: dropping number of Gaussions to 5
, Sun Nov 24 00:27:22 2019: iteration 9, lowerbound -2.548636
, Sun Nov 24 00:27:22 2019: dropping number of Gaussions to 4
, Sun Nov 24 00:27:22 2019: iteration 10, lowerbound -2.462016
, Sun Nov 24 00:27:22 2019: dropping number of Gaussions to 3
, Sun Nov 24 00:27:22 2019: iteration 11, lowerbound -2.401205
, Sun Nov 24 00:27:22 2019: iteration 12, lowerbound -2.357363
, Sun Nov 24 00:27:22 2019: iteration 13, lowerbound -2.328404
, Sun Nov 24 00:27:22 2019: iteration 14, lowerbound -2.311182
, Sun Nov 24 00:27:22 2019: iteration 15, lowerbound -2.307832
, Sun Nov 24 00:27:22 2019: dropping number of Gaussions to 2
, Sun Nov 24 00:27:22 2019: iteration 16, lowerbound -2.302918
, Sun Nov 24 00:27:22 2019: iteration 17, lowerbound -2.299260
, Sun Nov 24 00:27:22 2019: iteration 18, lowerbound -2.299256
, Sun Nov 24 00:27:22 2019: iteration 19, lowerbound -2.299254
, Sun Nov 24 00:27:22 2019: iteration 20, lowerbound -2.299254
, Sun Nov 24 00:27:22 2019: iteration 21, lowerbound -2.299253
, Sun Nov 24 00:27:22 2019: iteration 22, lowerbound -2.299253
, Sun Nov 24 00:27:22 2019: iteration 23, lowerbound -2.299253
, Sun Nov 24 00:27:22 2019: iteration 24, lowerbound -2.299253
, Sun Nov 24 00:27:22 2019: iteration 25, lowerbound -2.299253
, Sun Nov 24 00:27:22 2019: iteration 26, lowerbound -2.299253
, Sun Nov 24 00:27:22 2019: iteration 27, lowerbound -2.299253
, Sun Nov 24 00:27:22 2019: iteration 28, lowerbound -2.299253
, Sun Nov 24 00:27:22 2019: iteration 29, lowerbound -2.299253
, Sun Nov 24 00:27:22 2019: iteration 30, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 31, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 32, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 33, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 34, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 35, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 36, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 37, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 38, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 39, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 40, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 41, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 42, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 43, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 44, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 45, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 46, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 47, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 48, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 49, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: iteration 50, lowerbound -2.299253
, Sun Nov 24 00:27:23 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601382, 95.95490777398619]
β = [178.04509222601382, 95.95490777398619]
m = [4.250300733269911 79.28686694436185; 2.0002292577753704 53.85198717246129]
ν = [180.04509222601382, 97.95490777398619]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484857 -0.007644049042327489; 0.0 0.00858170516633361], [0.37587636119483825 -0.008953123827346048; 0.0 0.012748664777409427]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9917334430641419
avll from llpg:  -0.9917334430641421
avll direct:     -0.991733443064142
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9668203145015637
avll from llpg:  -0.9668203145015637
avll direct:     -0.9668203145015638
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.053151     0.102472    -0.0115641   -0.0250116    0.0311347   -0.243604     0.126064    -0.118812    -0.15927      -0.12659     -0.162288     -0.0137872    0.0483703    -0.0296866   -0.0509979  -0.0763929   -0.195965     0.0881582    0.178872     0.0080594   -0.0616289    0.000356159   0.0899168   -0.0868207   -0.150284     0.239708
  0.0233471   -0.0730259    0.00396455   0.0532896    0.0362064    0.0136743   -0.0239506   -0.0192556    0.28003       0.0939404    0.0623611    -0.0542718   -0.064678     -0.0505131   -0.022082    0.0323679   -0.0342418   -0.059223     0.0724456   -0.0294492    0.082198    -0.101791      0.0272285   -0.0872019   -0.145847    -0.0890498
  0.0757333    0.00107476  -0.248153     0.0775306   -0.16373      0.129095    -0.0822964    0.0637377   -0.0489903     0.261018     0.127562     -0.133441     0.0210089     0.156924    -0.204954   -0.11603     -0.0159309   -0.00278711   0.0600559   -0.128851    -0.112024     0.0638544    -0.0476924   -0.198914    -0.055989     0.00481369
  0.0405048    0.028693    -0.0479933    0.0544796    0.108615    -0.0903664    0.0804274   -0.144061     0.0594954     0.0297974    0.109986     -0.101448     0.121913      0.0833917   -0.165252    0.0428529   -0.0604424    0.188703    -0.119065     0.0916776   -0.068284    -0.0791995    -0.141321    -0.147707    -0.00425506   0.0709233
 -0.119502    -1.88672e-5   0.0105512    0.0229354   -0.099905     0.030191    -0.272422    -0.0704764    0.0420169    -0.0135604    0.00359072    0.166337    -0.0268357     0.00233084   0.0588901  -0.0608303    0.204       -0.0778854    0.102973    -0.102801     0.289542    -0.0228858    -0.038069    -0.0722114   -0.103704    -0.130828
  0.107873     0.13156     -0.120314     0.107216    -0.0460339   -0.126606    -0.0617373    0.0693455   -0.000829044  -0.141534    -0.0648848    -0.0571202    0.143709     -0.00909412  -0.0897769   0.0401289   -0.0945355    0.0341961   -0.0886721   -0.034481    -0.168797    -0.0799071     0.0906282   -0.098049    -0.0398604    0.0988529
  0.0846979    0.116196    -0.0207402    0.1606       0.130492    -0.186843     0.0681114   -0.0502278   -0.275469      0.0682275   -0.0357694    -0.0818175   -0.0794743    -0.0299641   -0.0102755  -0.152173    -0.151134     0.0339747   -0.123813     0.0983331    0.184729    -0.0821232    -0.0728781    0.0457617   -0.0510522   -0.0799694
  0.070843    -0.043633     0.0608339   -0.0613378    0.139274    -0.0420482    0.0559946   -0.025505     0.0248976     0.163274    -0.00649103   -0.146883    -0.112854      0.164256    -0.0499719  -0.135302    -0.0801712    0.0954658   -0.253595     0.0274511    0.0649625   -0.105278     -0.21342      0.0339642    0.0247698   -0.13607
  0.0302957   -0.0289579   -0.0300124   -0.0481521   -0.106116    -0.00640742   0.109722     0.0468186    0.102155      0.206492     0.108684      0.0906675   -0.194372     -0.216632     0.0695116  -0.0581115    0.104555    -0.0291511    0.0920956    0.0387692    0.108591     0.112622     -0.0474451    0.0802767   -0.0383529    0.0473033
 -0.0445031    0.0382289   -0.0219325   -0.200767     0.0729466    0.0933016   -0.144025    -0.0254958   -0.104706      0.0765733    0.0283881     0.184674     0.0123306     0.0224969    0.041838   -0.179874    -0.0613234    0.0727403   -0.0622955   -0.0270926   -0.0185932    0.104507     -0.00267012   0.0115722    0.191896    -0.117499
 -0.107765    -0.0933755   -0.105889     0.145437    -0.0682851    0.0275568    0.077316     0.0765743   -0.211951      0.139027    -0.0933014    -0.00325555   0.070727     -0.0409544   -0.17131     0.119673    -0.0927616   -0.0583324   -0.0589859   -0.010921    -0.225003    -0.0509915     0.136956    -0.178312     0.177361     0.157522
  0.116268     0.0285935    0.0180247    0.00637617   0.0240707    0.16483      0.033376    -0.0977192   -0.0664036     0.126874    -0.0406206     0.0451504   -0.17309       0.0856099    0.02194    -0.104996    -0.00410498   0.111038    -0.0205816    0.065242    -0.0924355   -0.0545853    -0.0602242    0.168016     0.0488522   -0.0791635
  0.174128     0.0597815    0.0153647    0.0423495    0.0272404    0.0751076   -0.00575192   0.140389     0.0157362     0.051222     0.0562298     0.0317021   -0.013943      0.0242672   -0.0185818  -0.0268798   -0.0188671   -0.124907     0.021457    -0.00875269  -0.0636733    0.0344005    -0.135547    -0.058237     0.116747     0.154452
 -0.0297057   -0.0315068   -0.0822261   -0.0323581   -0.0338824    0.0356029    0.0584649    0.0190528    0.138368      0.0483946   -0.0117352    -0.186799     0.103791     -0.00433599  -0.0883947   0.04768      0.00302606  -0.0559535    0.0291354    0.138009    -0.0277432   -0.0472552     0.148157     0.0140802   -0.103355    -0.114651
 -0.0802069    0.0812633    0.114865     0.0939319   -0.25564     -0.072386    -0.122966    -0.113548     0.0800703     0.0431792    0.0442172     0.030816     0.0442527    -0.0741511   -0.106296   -0.19306     -0.0853829   -0.0636014   -0.108007     0.186272    -0.224092    -0.053815      0.169445    -0.223573    -0.0161332    0.0103435
  0.0401579    0.0909836   -0.0672817   -0.0258208   -0.11368     -0.165725    -0.163595    -0.0817298    0.0134235     0.027363    -0.0065178     0.0158399   -0.0224441     0.0789202   -0.18706    -0.117107    -0.187123     0.0184195    0.128458     0.132372     0.0380547   -0.173106      0.0797874    0.139503    -0.0705332    0.0162009
 -0.00810266  -0.0400915   -0.0768368   -0.11784     -0.0820377    0.0355318   -0.0188284    0.0019343   -0.0883106    -0.157119     0.130282      0.0585783   -0.132091     -0.0522172    0.0700097   0.169131    -0.0473463   -0.169739     0.143021    -0.0180904   -0.109168     0.0396942     0.0220374    0.00354831  -0.0283608    0.0271535
  0.0409186    0.0527208   -0.0361792   -0.0940386    0.111183     0.0926391   -0.0236173    0.0683264    0.112493     -0.128772    -0.100657     -0.05249      0.118164     -0.0608492    0.0188875  -0.00420308   0.00558425  -0.210424     0.0860799    0.0109967   -0.0652219    0.107085     -0.0649688   -0.0288476    0.0542921   -0.0743656
 -0.096319    -0.0341896   -0.0125899   -0.00351249   0.0864771    0.0901105    0.192562    -0.0265445    0.0501315    -0.00606077  -0.199527      0.054277     0.107339     -0.243644     0.0393286  -0.141409     0.0198887   -0.222743    -0.126302    -0.0339789   -0.0268694    0.0361002     0.0148308   -0.00172861   0.094772    -0.0978117
  0.12253      0.0415512    0.0730616    0.0213588    0.201806    -0.029795    -0.0347392   -0.0123693   -0.0378276    -0.0415501   -0.0447899    -0.00610378   0.230944      0.0223985   -0.17836     0.0225531   -0.0688882    0.0968654   -0.0768653    0.0104313    0.0285903    0.00709348   -0.150571    -0.156734     0.131516     0.0878431
 -0.0385624   -0.0638333    0.0129498   -0.0338887   -0.148885     0.0595281   -0.0468493    0.041778    -0.05039      -0.115852     0.0243707     0.0338688    0.0436252    -0.0239226    0.118477    0.0735811   -0.00133678   0.0601307    0.0769318    0.121584     0.0295958    0.147486     -0.0420363    0.0211042   -0.0159801   -0.0973606
 -0.0432826   -0.0486336   -0.0884243    0.0275323    0.0168493   -0.100406    -0.00627803  -0.0248329    0.0419525     0.226804    -0.01199      -0.0860406    0.0359051     0.0741413   -0.184489   -0.0522154   -0.0714091    0.0564924    0.174038     0.0497797    0.0593441    0.137878     -0.00501584  -0.0391832   -0.0522138    0.053917
 -0.0199176    0.178917    -0.00728893   0.00198314   0.0952919    0.207787     0.0380518   -0.0668858   -0.0292529     0.15254     -0.0391625     0.106492     0.0202215     0.0527359    0.175168    0.013152     0.0576651   -0.114869     0.149914    -0.178677     0.0281243    0.107413      0.00632526  -0.119757    -0.244149    -0.0934015
 -0.180639     0.030037     0.099084    -0.105558     0.0795998   -0.0584748    0.0866475   -0.119665     0.044691     -0.24745     -0.0920803    -0.0631799   -0.103373     -0.146917     0.0736177   0.00143814   0.145402     0.0353816    0.139346    -0.00281988   0.0824515   -0.0396615     0.0949347    0.137813    -0.115585    -0.199155
  0.117414     0.0527527    0.0457948    0.193914     0.140408     0.12801     -0.0435209    0.0565611   -0.218777     -0.0275197    0.0457486     0.0323382   -0.0216189    -0.132688    -0.143275   -0.0930178   -0.0273377    0.058339     0.0165507    0.0225299    0.10628      0.103733     -0.0402472    0.00567488  -0.0581039    0.0992975
  0.0840373   -0.178036    -0.0101574   -0.0810895   -0.0157668    0.21654      0.00144645   0.00161869  -0.136504     -0.10058      0.000285239  -0.0900485   -0.252814     -0.104709    -0.0641185   0.0964327   -0.0991765   -0.0818504   -0.0848801    0.00130975   0.0251975    0.00903349    0.0566084   -0.0218526    0.173036     0.111827
 -0.169434    -0.0649441    0.0338722    0.0692713    0.00359828  -0.124108    -0.110636     0.245603    -0.0845376     0.0188478   -0.159423      0.049311     0.0184463     0.118975     0.193292    0.0898972    0.105417     0.0621516   -0.018786     0.0737004   -0.0979342   -0.0395644     0.00385991   0.154321     0.00387417  -0.0488894
 -0.0833315   -0.0187053   -0.100571     0.0100937   -0.0905195   -0.0658406    0.031807    -0.0238121   -0.274869     -0.0581083   -0.060913     -0.0671016   -0.000996687  -0.0710642   -0.163733   -0.0109965    0.0134945    0.0744958    0.050839     0.0808783    0.0167148   -0.0511125    -0.0691867    0.0312227    0.0685753   -0.12418
  0.10008     -0.0534756   -0.0387579   -0.12347     -0.0409521    0.00696748  -0.0307266    0.0338188   -0.00900154   -0.0115474    0.135472     -0.0212163    0.0613988     0.0499709   -0.0512221   0.139658    -0.120053    -0.0385441    0.0166001   -0.202798    -0.00894762   0.103186     -0.00981969   0.0553196   -0.117304     0.096961
  0.00172874   0.234524     0.178443     0.0309084    0.0387281    0.154098     0.104489    -0.11595     -0.00333835    0.0746099    0.00436068   -0.0020801    0.0741834     0.0959304   -0.0612698  -0.00345772   0.0866039   -0.093648     0.00282672   0.0856095   -0.0467683    0.0197182     0.0480634    0.0488391    0.106728    -0.0755159
  0.0567014    0.0229256    0.0385111    0.032047    -0.141057     0.112402    -0.0277539    0.0361127   -0.00234855    0.0309691    0.132531      0.113271     0.100462      0.1049       0.0852182  -0.0652127    0.0354043   -0.0246788   -0.0880347    0.216603     0.00162037   0.0148376     0.0687022    0.16392      0.142848     0.0963768
  0.223387     0.129975    -0.140244    -0.206002    -0.0519374   -0.0215966   -0.0402893    0.18464     -0.0501994     0.014031     0.057398     -0.00639941   0.221148     -0.0876404    0.0486748   0.0342726   -0.0120715    0.239275     0.0152197    0.134992    -0.0837393    0.0100883    -0.103192    -0.089152    -0.0230378    0.0702545kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3948859753756992
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.394970
[ Info: iteration 2, average log likelihood -1.394876
[ Info: iteration 3, average log likelihood -1.393956
[ Info: iteration 4, average log likelihood -1.383373
[ Info: iteration 5, average log likelihood -1.362129
[ Info: iteration 6, average log likelihood -1.356025
[ Info: iteration 7, average log likelihood -1.354757
[ Info: iteration 8, average log likelihood -1.354262
[ Info: iteration 9, average log likelihood -1.354042
[ Info: iteration 10, average log likelihood -1.353930
[ Info: iteration 11, average log likelihood -1.353862
[ Info: iteration 12, average log likelihood -1.353815
[ Info: iteration 13, average log likelihood -1.353780
[ Info: iteration 14, average log likelihood -1.353752
[ Info: iteration 15, average log likelihood -1.353730
[ Info: iteration 16, average log likelihood -1.353712
[ Info: iteration 17, average log likelihood -1.353697
[ Info: iteration 18, average log likelihood -1.353685
[ Info: iteration 19, average log likelihood -1.353674
[ Info: iteration 20, average log likelihood -1.353665
[ Info: iteration 21, average log likelihood -1.353657
[ Info: iteration 22, average log likelihood -1.353651
[ Info: iteration 23, average log likelihood -1.353645
[ Info: iteration 24, average log likelihood -1.353640
[ Info: iteration 25, average log likelihood -1.353636
[ Info: iteration 26, average log likelihood -1.353632
[ Info: iteration 27, average log likelihood -1.353629
[ Info: iteration 28, average log likelihood -1.353626
[ Info: iteration 29, average log likelihood -1.353623
[ Info: iteration 30, average log likelihood -1.353620
[ Info: iteration 31, average log likelihood -1.353617
[ Info: iteration 32, average log likelihood -1.353615
[ Info: iteration 33, average log likelihood -1.353612
[ Info: iteration 34, average log likelihood -1.353610
[ Info: iteration 35, average log likelihood -1.353608
[ Info: iteration 36, average log likelihood -1.353606
[ Info: iteration 37, average log likelihood -1.353604
[ Info: iteration 38, average log likelihood -1.353602
[ Info: iteration 39, average log likelihood -1.353600
[ Info: iteration 40, average log likelihood -1.353598
[ Info: iteration 41, average log likelihood -1.353596
[ Info: iteration 42, average log likelihood -1.353594
[ Info: iteration 43, average log likelihood -1.353592
[ Info: iteration 44, average log likelihood -1.353590
[ Info: iteration 45, average log likelihood -1.353587
[ Info: iteration 46, average log likelihood -1.353585
[ Info: iteration 47, average log likelihood -1.353582
[ Info: iteration 48, average log likelihood -1.353579
[ Info: iteration 49, average log likelihood -1.353577
[ Info: iteration 50, average log likelihood -1.353574
┌ Info: EM with 100000 data points 50 iterations avll -1.353574
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.394969880887286
│     -1.3948762192765158
│      ⋮
└     -1.3535735836551324
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.353676
[ Info: iteration 2, average log likelihood -1.353561
[ Info: iteration 3, average log likelihood -1.352855
[ Info: iteration 4, average log likelihood -1.346029
[ Info: iteration 5, average log likelihood -1.328880
[ Info: iteration 6, average log likelihood -1.318705
[ Info: iteration 7, average log likelihood -1.315760
[ Info: iteration 8, average log likelihood -1.314511
[ Info: iteration 9, average log likelihood -1.313741
[ Info: iteration 10, average log likelihood -1.313191
[ Info: iteration 11, average log likelihood -1.312791
[ Info: iteration 12, average log likelihood -1.312502
[ Info: iteration 13, average log likelihood -1.312285
[ Info: iteration 14, average log likelihood -1.312116
[ Info: iteration 15, average log likelihood -1.311979
[ Info: iteration 16, average log likelihood -1.311862
[ Info: iteration 17, average log likelihood -1.311759
[ Info: iteration 18, average log likelihood -1.311665
[ Info: iteration 19, average log likelihood -1.311577
[ Info: iteration 20, average log likelihood -1.311493
[ Info: iteration 21, average log likelihood -1.311411
[ Info: iteration 22, average log likelihood -1.311331
[ Info: iteration 23, average log likelihood -1.311255
[ Info: iteration 24, average log likelihood -1.311182
[ Info: iteration 25, average log likelihood -1.311114
[ Info: iteration 26, average log likelihood -1.311048
[ Info: iteration 27, average log likelihood -1.310983
[ Info: iteration 28, average log likelihood -1.310917
[ Info: iteration 29, average log likelihood -1.310846
[ Info: iteration 30, average log likelihood -1.310768
[ Info: iteration 31, average log likelihood -1.310680
[ Info: iteration 32, average log likelihood -1.310580
[ Info: iteration 33, average log likelihood -1.310467
[ Info: iteration 34, average log likelihood -1.310345
[ Info: iteration 35, average log likelihood -1.310217
[ Info: iteration 36, average log likelihood -1.310085
[ Info: iteration 37, average log likelihood -1.309957
[ Info: iteration 38, average log likelihood -1.309842
[ Info: iteration 39, average log likelihood -1.309743
[ Info: iteration 40, average log likelihood -1.309655
[ Info: iteration 41, average log likelihood -1.309578
[ Info: iteration 42, average log likelihood -1.309512
[ Info: iteration 43, average log likelihood -1.309459
[ Info: iteration 44, average log likelihood -1.309415
[ Info: iteration 45, average log likelihood -1.309376
[ Info: iteration 46, average log likelihood -1.309339
[ Info: iteration 47, average log likelihood -1.309304
[ Info: iteration 48, average log likelihood -1.309268
[ Info: iteration 49, average log likelihood -1.309232
[ Info: iteration 50, average log likelihood -1.309197
┌ Info: EM with 100000 data points 50 iterations avll -1.309197
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3536758243603535
│     -1.3535609123974839
│      ⋮
└     -1.309196548026931
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.309317
[ Info: iteration 2, average log likelihood -1.309119
[ Info: iteration 3, average log likelihood -1.308147
[ Info: iteration 4, average log likelihood -1.299658
[ Info: iteration 5, average log likelihood -1.281403
[ Info: iteration 6, average log likelihood -1.268055
[ Info: iteration 7, average log likelihood -1.262740
[ Info: iteration 8, average log likelihood -1.260057
[ Info: iteration 9, average log likelihood -1.258520
[ Info: iteration 10, average log likelihood -1.257650
[ Info: iteration 11, average log likelihood -1.257113
[ Info: iteration 12, average log likelihood -1.256734
[ Info: iteration 13, average log likelihood -1.256447
[ Info: iteration 14, average log likelihood -1.256222
[ Info: iteration 15, average log likelihood -1.256013
[ Info: iteration 16, average log likelihood -1.255781
[ Info: iteration 17, average log likelihood -1.255468
[ Info: iteration 18, average log likelihood -1.254947
[ Info: iteration 19, average log likelihood -1.253954
[ Info: iteration 20, average log likelihood -1.252104
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.249391
[ Info: iteration 22, average log likelihood -1.267103
[ Info: iteration 23, average log likelihood -1.258505
[ Info: iteration 24, average log likelihood -1.256205
[ Info: iteration 25, average log likelihood -1.255722
[ Info: iteration 26, average log likelihood -1.255554
[ Info: iteration 27, average log likelihood -1.255437
[ Info: iteration 28, average log likelihood -1.255322
[ Info: iteration 29, average log likelihood -1.255178
[ Info: iteration 30, average log likelihood -1.254949
[ Info: iteration 31, average log likelihood -1.254533
[ Info: iteration 32, average log likelihood -1.253711
[ Info: iteration 33, average log likelihood -1.251979
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.249017
[ Info: iteration 35, average log likelihood -1.266651
[ Info: iteration 36, average log likelihood -1.257952
[ Info: iteration 37, average log likelihood -1.255704
[ Info: iteration 38, average log likelihood -1.255255
[ Info: iteration 39, average log likelihood -1.255071
[ Info: iteration 40, average log likelihood -1.254892
[ Info: iteration 41, average log likelihood -1.254667
[ Info: iteration 42, average log likelihood -1.254362
[ Info: iteration 43, average log likelihood -1.253930
[ Info: iteration 44, average log likelihood -1.253291
[ Info: iteration 45, average log likelihood -1.252236
[ Info: iteration 46, average log likelihood -1.250219
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.246655
[ Info: iteration 48, average log likelihood -1.262942
[ Info: iteration 49, average log likelihood -1.253601
[ Info: iteration 50, average log likelihood -1.251193
┌ Info: EM with 100000 data points 50 iterations avll -1.251193
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.309317111523987
│     -1.3091188962187212
│      ⋮
└     -1.251192780597709
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.250878
[ Info: iteration 2, average log likelihood -1.250327
[ Info: iteration 3, average log likelihood -1.246553
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.218115
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.197506
[ Info: iteration 6, average log likelihood -1.199258
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.174384
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.190890
[ Info: iteration 9, average log likelihood -1.196509
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.165193
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     13
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.160259
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.184949
[ Info: iteration 13, average log likelihood -1.178366
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.143571
[ Info: iteration 15, average log likelihood -1.194716
[ Info: iteration 16, average log likelihood -1.177169
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.141615
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.166118
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.177200
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.164830
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.153873
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.179511
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.164146
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.153420
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.162339
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.165694
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.166406
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.156321
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.171876
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.165342
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.155893
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.155311
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.167394
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.169102
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.149781
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.173930
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.168108
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.149379
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.157248
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.169877
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.162407
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.151952
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.176369
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.161903
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.152128
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.160171
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.164304
[ Info: iteration 48, average log likelihood -1.165141
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.143650
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.176130
┌ Info: EM with 100000 data points 50 iterations avll -1.176130
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2508775576921158
│     -1.2503266623406484
│      ⋮
└     -1.1761298865453165
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.175573
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.148617
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│     25
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.139767
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     26
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.123398
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     14
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.102023
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.077603
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     27
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.090989
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.060701
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     14
│     26
│     27
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.051778
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      7
│      8
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.078360
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     14
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.057912
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      7
│      8
│     27
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.056449
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     14
│     19
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.066587
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.064481
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      6
│     14
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.040127
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.079929
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.058861
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      7
│      8
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.049212
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     14
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.075061
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      7
│      8
│     20
│      ⋮
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.055950
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     14
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.064064
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.063261
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     14
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.063991
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     26
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.051440
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     14
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.061050
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│      8
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.056324
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     14
│     27
│     28
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.056340
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     19
│     26
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.061131
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│     14
│     26
│     27
│     28
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.052108
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      7
│      8
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.059778
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     14
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.066589
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│      8
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.055149
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     14
│     26
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.052232
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      6
│      7
│      8
│     26
│     27
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.058790
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     14
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.065894
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     26
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.057366
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│     14
│     26
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.052324
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│      8
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.062466
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     14
│     19
│     26
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.050761
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│      8
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.068712
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     14
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.057333
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      7
│      8
│     26
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.046758
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      5
│     14
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.067221
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│      8
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.067036
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│     14
│     26
│     27
│     28
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.047435
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      6
│      7
│      8
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.059985
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     14
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.064557
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     27
│     28
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.052392
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      5
│     14
│     26
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.055363
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     26
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.054898
┌ Info: EM with 100000 data points 50 iterations avll -1.054898
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1755729922102722
│     -1.1486166940395324
│      ⋮
└     -1.0548977397010422
32×26 Array{Float64,2}:
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3948859753756992
│     -1.394969880887286
│     -1.3948762192765158
│     -1.3939559375471895
│      ⋮
│     -1.0523915473756673
│     -1.0553630556603901
└     -1.0548977397010422
 -0.0607926   -0.0194154   -0.0967277   -0.00197842  -0.157023    -0.0644199   0.0290449    -0.014054    -0.237094     -0.0696361   -0.0574766   -0.0588824   -0.0142283   -0.0852688   -0.167995    0.0115521    0.0241332    0.0737536    0.0486206   0.0832138    0.0394168    -0.0528636   -0.0697266    0.0310633     0.0957199   -0.152354
 -0.034957    -0.0257877   -0.0869964   -0.0353479   -0.0124252    0.0126694   0.0668444     0.00951634   0.158191      0.0442657   -0.0168343   -0.181964     0.0968779   -0.00826409  -0.0869977   0.0462213    0.0192819   -0.0599909    0.0303734   0.139262    -0.00745514   -0.0465418    0.146827     0.0258813    -0.0984468   -0.10331
 -0.167648    -0.0851724   -0.0365155    0.110522    -0.0446444   -0.0437273  -0.0165889     0.167767    -0.136408      0.0807845   -0.150786     0.0329573    0.0612838    0.0289649    0.0146187   0.115694     0.010024     0.00185661  -0.0406336   0.0542668   -0.181302     -0.0445529    0.0689904   -0.0173105     0.103819     0.0657762
  0.222023     0.138853    -0.139451    -0.210535    -0.0463813   -0.0232298  -0.0490679     0.184697    -0.050931      0.0146779    0.0482415   -0.00757288   0.228145    -0.0815095    0.04128     0.0407638   -0.0146958    0.236022     0.0174385   0.0929187   -0.0832854    -0.0434402   -0.104994    -0.0881288     0.00869153   0.0348561
  0.0353053    0.0793795   -0.0336186   -0.092899     0.107961     0.115511   -0.0364018     0.0617378    0.103319     -0.139154    -0.0963328   -0.120675     0.1238      -0.045923     0.0167813  -0.00257329   0.0054085   -0.209483     0.0770926   0.00464308  -0.0992162     0.0874675   -0.0618031   -0.0246746     0.0679479   -0.102693
 -0.0374849    0.0384282   -0.0268379   -0.213757     0.0386844    0.0922494  -0.130282     -0.0229576   -0.137067      0.08596      0.0405459    0.185086     0.00734183   0.0283667    0.0416351  -0.197843    -0.0664128    0.0722827   -0.0566147  -0.0319298    0.000838696   0.0943137    0.0477582    0.0212359     0.188406    -0.115233
 -0.165259     0.0293977    0.0917498   -0.0824363    0.0830881   -0.0551938   0.0871916    -0.254019     0.0456016    -0.227611    -0.0896008    0.0534618   -0.106226    -0.185465    -0.0236514   0.107501     0.269839     0.00576593   0.118542   -0.0137453   -1.48551      -0.039531     0.0163458    0.140855     -0.102057    -0.201941
 -0.175494     0.0296656    0.103403    -0.118171     0.0791274   -0.0551206   0.0867352     0.0315959    0.0458587    -0.253815    -0.0914856   -0.11777     -0.105485    -0.135581     0.14152    -0.133947     0.0659444   -0.00875627   0.154382    0.00157465   1.21609      -0.0408025    0.183201     0.135634     -0.116698    -0.197888
 -0.0965693   -0.0208808   -0.0447464   -0.00576287   0.0447933    0.119313    0.199715     -0.0249995    0.0541691    -0.00171864  -0.1785       0.0534869    0.105914    -0.243449     0.0389817  -0.166912     0.0430954   -0.207264    -0.117416   -0.0375204   -0.0392257     0.0106956   -0.00852104   0.00278143    0.0961416   -0.106799
  0.0541217    0.127997    -0.0434937   -0.0153497    0.0179985   -0.254672    0.095948     -0.12366     -0.154714     -0.124263    -0.144788    -0.0163272    0.0360582   -0.0347222   -0.0472402  -0.0754845   -0.179948     0.0863745    0.177147    0.00418626  -0.0489214     0.00336758   0.111711    -0.0850184    -0.14284      0.204433
 -0.0582529    0.0963816    0.106656     0.0258332   -0.0830616    0.0479046  -0.104876     -0.0960377    0.028048      0.0400031    0.0297179    0.070394     0.0478754    0.0019275   -0.0467823  -0.065753     0.0581816   -0.0664745   -0.0073511   0.0546045    0.00637752   -0.0104805    0.0617514   -0.0815665     0.0107952   -0.0689237
  0.138096     0.0101518   -0.0320263   -0.0354531    0.00639395   0.0359187  -0.0335468     0.0876657   -0.00298966    0.0198265    0.109653     0.0266271    0.0388558    0.0391623   -0.0397731   0.0541482   -0.0747595   -0.0712409    0.0052818  -0.092027    -0.0248163     0.0754173   -0.0631946   -0.00277086   -0.0062114    0.12799
  0.0861323    0.127452    -0.0291493    0.169583     0.133821    -0.187551    0.0676346    -0.0606863   -0.289101      0.103667    -0.0640312   -0.0845987   -0.0751347   -0.012802    -0.017121   -0.154687    -0.144545     0.0287859   -0.125128    0.112903     0.188323     -0.0659066   -0.0790685    0.0458841    -0.0711995   -0.0461578
 -0.0192609    0.177479    -0.00886503  -0.00285752   0.0886868    0.21611     0.0358557    -0.0646162   -0.00838152    0.150409    -0.0414686    0.11154      0.022809     0.0958615    0.175395    0.029248     0.0458357   -0.12927      0.145515   -0.157222     0.0299467     0.0983105    0.00825902  -0.0978868    -0.222762    -0.0875172
 -0.00445646  -0.0352446   -0.0658433   -0.132736    -0.103403     0.0339403  -0.0262265     0.0220533   -0.0603433    -0.167053     0.131359     0.060126    -0.122674    -0.0534543    0.0508164   0.143287    -0.078925    -0.189264     0.185962   -0.0198718   -0.113385      0.0362468    0.0242789   -0.00654586   -0.0434617    0.0389493
  0.0517902    0.0245863    0.0569007    0.0229632   -0.133234     0.0998628  -0.0384269     0.0340187   -0.00247916    0.0338609    0.132056     0.113343     0.101035     0.110371     0.0850745  -0.0634416    0.0906082   -0.0253737   -0.0930393   0.193463    -0.0250349     0.0270215    0.076483     0.160667      0.146865     0.116375
  0.0854411   -0.193495    -0.0108216   -0.0835307   -0.0168146    0.217351   -0.00159755    0.00607027  -0.144213     -0.0896165   -0.00958617  -0.0897648   -0.246542    -0.106459    -0.0703302   0.0998074   -0.102165    -0.112162    -0.115882   -0.00684441   0.0247118     0.00937276   0.0558282   -0.0210775     0.189707     0.118853
  0.131791     0.0814344   -0.0813736    0.070437     0.0449268   -0.105295    0.0104215    -0.0363835    0.0277166    -0.0793491    0.00337251  -0.0757325    0.143719     0.0260611   -0.119222    0.0453725   -0.0794606    0.125189    -0.0994715   0.00536662  -0.114186     -0.0806515   -0.0195101   -0.130838     -0.0312712    0.0865183
  0.113694     0.0603221    0.0485481    0.191527     0.138629     0.124176   -0.016         0.0578591   -0.209735     -0.0157292    0.00845315   0.0225625   -0.013548    -0.131086    -0.129791   -0.0886892   -0.0277703    0.065167     0.0161588   0.00509566   0.106472      0.114019    -0.0388994   -0.000342474  -0.0557731    0.0854458
  0.0875746   -0.0115436    0.0704265   -0.0276395    0.165177    -0.0445791   0.0386666    -0.0228647   -0.000253478   0.0681941   -0.0547858   -0.0759169    0.020592     0.175894    -0.109635   -0.0877819   -0.0749192    0.0988162   -0.197773    0.0374163    0.0514071    -0.0610341   -0.193593    -0.0285883     0.0504495   -0.0530422
 -0.567157     0.0246542    0.0439086    0.00684944   0.0222841    0.090393   -0.0126549    -0.108445    -0.0689987     0.375406    -0.136915     0.0536696   -0.256006     0.0888581   -0.106271   -0.0966837   -0.0371936    0.0468225   -0.0521189   0.0356528   -0.209973     -0.091705     0.0800751    0.154995      0.0275871   -0.0905791
  0.777648     0.0353538   -0.00359313   0.0131084    0.0298957    0.155064    0.115975     -0.0630319   -0.0681371    -0.157843    -0.0472406    0.0425747   -0.023641     0.0696308    0.229451   -0.109877    -0.0233135    0.131386     0.0319024   0.113237     0.0333308    -0.0349904   -0.2445       0.175608      0.0594269   -0.0609588
  0.0329441   -0.0890753    0.0209581    0.0490727   -0.00197828  -0.0864139   0.00807342   -0.0282333    0.151841      0.0842659   -0.113298    -0.0396032   -0.0645845   -0.0278478   -0.0148335   0.0611481   -0.762028    -0.092616     0.0988641  -0.0950573    0.082469     -0.0761526    0.0246201    0.00260635   -0.161797    -0.0900342
  0.0142542   -0.0519961   -0.0309252    0.0447587    0.00755344   0.0677747  -0.0822967    -0.0168315    0.424504      0.1327       0.115196    -0.0594793   -0.0426517   -0.0750637    0.0804318   0.0669454    0.732209    -0.0381582    0.0186199   0.0933222    0.0742192    -0.113888     0.0283491   -0.118025     -0.168689    -0.0886061
 -0.0259769   -0.046958    -0.0909437    0.0285791    0.0204115   -0.11196    -0.0262865    -0.0242525    0.0102402     0.218719    -0.00344513  -0.0828782    0.0666411    0.0758462   -0.153674   -0.0467024   -0.0300777    0.0570882    0.154235    0.0634772    0.0584363     0.137726     0.00894328  -0.0362065    -0.0604634    0.0555759
  0.0337742    0.0666093   -0.0738583   -0.0186871   -0.107856    -0.128167   -0.166801     -0.109458     0.0361677     0.0307337    0.0130504    0.0161145   -0.045153     0.109754    -0.21226    -0.121356    -0.182619     0.0149376    0.128563    0.131778     0.0374753    -0.166137     0.13074      0.146399     -0.0714495    0.0130976
  0.0616484   -0.093448     0.0135018    0.00795326  -0.216389     0.35325    -0.0468246     0.0571162   -0.0569203    -0.307098     0.0619771    0.028934     0.0138727   -0.0242789    0.105521    0.0869177   -0.00327705   0.4846       0.0727314   0.138866     0.029731      0.119121    -0.0787716    0.0201699    -0.0437633   -0.0798246
 -0.295913    -0.0755728    0.00800399  -0.0196093   -0.0827308   -0.275621   -0.046578      0.0503931   -0.0480104     0.0482418    0.0311181    0.0414435    0.112406    -0.0246386    0.131964    0.085119    -0.00271158  -0.488384     0.0902424   0.0951141    0.102904      0.236163    -0.00602636   0.0147838     0.0181798   -0.131976
  0.0516258    0.172524    -0.259386     0.06183     -0.157632     0.105058   -0.0815769     0.057617    -0.047839      0.259738     0.128874    -0.26975      0.0220491    0.15634     -0.215727   -0.395107    -0.0175336   -0.071361    -0.0212866  -0.131766    -0.0924109     0.362367    -0.127389    -0.490461      0.152321     0.149699
  0.0915913   -0.0161129   -0.245431     0.0744927   -0.159893     0.167922   -0.0813078     0.0631601   -0.0511694     0.263179     0.139828    -0.105783     0.021293     0.157315    -0.19835    -0.0289675    0.00364802   0.0410045    0.114357   -0.11974     -0.13551      -0.161084     0.0433116    0.0376224    -0.11524     -0.0906668
  0.0285183   -0.00554808  -0.0372806   -0.120258    -0.0815867   -0.0467974  -0.000815126   0.0450609    0.108706      0.191411     0.0967832    0.0849404   -0.213106    -0.230297     0.0615039  -0.0528022    0.106612    -0.0425088    0.0851452   0.0472075    0.180789      0.0983585   -0.0459218    0.0912316    -0.0483284    0.0393494
  0.0313203   -0.0127255   -0.0325268   -0.0803127   -0.0719988   -0.0565557   0.120702      0.0468186    0.11405       0.170564     0.0732793    0.0730578   -0.225178    -0.222645     0.0678078  -0.0677031    0.105116    -0.0341132    0.0781748   0.0208916    0.173135      0.108664    -0.0509238    0.0905312    -0.0342288    0.0459783[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│     14
│     19
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.039075
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.024996
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     14
│     19
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.031677
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.029094
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│     14
│     19
│     26
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.032855
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.019482
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│      6
│     14
│     19
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.028941
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.015470
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│     14
│     19
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.022087
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.019821
┌ Info: EM with 100000 data points 10 iterations avll -1.019821
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.185524e+05
      1       6.622082e+05      -1.563443e+05 |       32
      2       6.397091e+05      -2.249910e+04 |       32
      3       6.268530e+05      -1.285604e+04 |       32
      4       6.166230e+05      -1.022999e+04 |       32
      5       6.074342e+05      -9.188833e+03 |       32
      6       6.007371e+05      -6.697084e+03 |       32
      7       5.960765e+05      -4.660590e+03 |       32
      8       5.933210e+05      -2.755542e+03 |       32
      9       5.914654e+05      -1.855557e+03 |       32
     10       5.898619e+05      -1.603478e+03 |       32
     11       5.883528e+05      -1.509196e+03 |       32
     12       5.872194e+05      -1.133389e+03 |       32
     13       5.865628e+05      -6.565321e+02 |       32
     14       5.862318e+05      -3.310157e+02 |       32
     15       5.860477e+05      -1.840840e+02 |       32
     16       5.858702e+05      -1.775044e+02 |       32
     17       5.857100e+05      -1.602037e+02 |       32
     18       5.855347e+05      -1.753347e+02 |       32
     19       5.853247e+05      -2.100365e+02 |       32
     20       5.851195e+05      -2.051252e+02 |       32
     21       5.849408e+05      -1.787100e+02 |       32
     22       5.848228e+05      -1.179964e+02 |       31
     23       5.847396e+05      -8.318979e+01 |       32
     24       5.846789e+05      -6.074001e+01 |       32
     25       5.846203e+05      -5.855151e+01 |       32
     26       5.845592e+05      -6.115987e+01 |       32
     27       5.844996e+05      -5.955195e+01 |       32
     28       5.844518e+05      -4.785613e+01 |       32
     29       5.844094e+05      -4.242056e+01 |       32
     30       5.843738e+05      -3.551627e+01 |       31
     31       5.843439e+05      -2.990579e+01 |       31
     32       5.843129e+05      -3.099430e+01 |       31
     33       5.842864e+05      -2.649713e+01 |       31
     34       5.842635e+05      -2.295053e+01 |       32
     35       5.842411e+05      -2.237292e+01 |       27
     36       5.842202e+05      -2.086582e+01 |       32
     37       5.841924e+05      -2.785202e+01 |       31
     38       5.841354e+05      -5.702451e+01 |       32
     39       5.840280e+05      -1.073837e+02 |       32
     40       5.838598e+05      -1.682004e+02 |       32
     41       5.836994e+05      -1.603381e+02 |       32
     42       5.835899e+05      -1.095454e+02 |       32
     43       5.835258e+05      -6.413073e+01 |       32
     44       5.834724e+05      -5.341908e+01 |       32
     45       5.834072e+05      -6.513886e+01 |       32
     46       5.833357e+05      -7.154711e+01 |       31
     47       5.832774e+05      -5.830652e+01 |       32
     48       5.832267e+05      -5.070194e+01 |       31
     49       5.831834e+05      -4.325433e+01 |       32
     50       5.831377e+05      -4.570082e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 583137.7048065283)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.302787
[ Info: iteration 2, average log likelihood -1.272938
[ Info: iteration 3, average log likelihood -1.240998
[ Info: iteration 4, average log likelihood -1.200901
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.148910
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.122894
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.120570
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.084173
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     13
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.048087
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      6
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.077490
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.077622
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.031784
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      6
│     13
│     17
│     22
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.013766
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.079533
[ Info: iteration 15, average log likelihood -1.059053
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     17
│     20
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.001656
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│     12
│     13
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.039284
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.068893
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.037097
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│     12
│     13
│     17
│     20
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -0.994200
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.059635
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     22
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.029555
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.029055
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.044210
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.032135
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      6
│     12
│     13
│     22
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -0.995967
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.073822
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.045583
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      6
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.013260
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     22
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.021608
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.058838
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      6
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.027739
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.042469
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     17
│     22
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.021740
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      6
│     12
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.027765
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     20
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.047349
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.051912
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      6
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.033131
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.020346
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     13
│     20
│     24
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.000373
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.069042
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.044684
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.040494
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      6
│     20
│     24
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.003129
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.063601
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     17
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.045242
[ Info: iteration 47, average log likelihood -1.045811
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      6
│     12
│     20
│     24
│     25
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -0.988700
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.074805
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.065615
┌ Info: EM with 100000 data points 50 iterations avll -1.065615
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0526877    0.125504    -0.0521533    -0.0193282     0.00823655  -0.245798     0.0817827   -0.124055    -0.148856     -0.117128     -0.136909    -0.0139242    0.0352644    -0.0266834   -0.0506109  -0.0756894   -0.17769      0.0817241     0.175127     0.0104253   -0.043217     -0.00425623   0.105016    -0.0816891    -0.140788     0.192824
  0.0798499   -0.0458022    0.0597977    -0.044632      0.140405    -0.0409216    0.101029    -0.0187116   -0.00204651    0.139966     -0.0548371   -0.148802    -0.114154      0.184058    -0.0796396  -0.148575    -0.080682     0.0870767    -0.266062     0.0471688    0.0701354    -0.109612    -0.200706     0.0490306    -0.00169369  -0.146533
  0.112118     0.0472333    0.0324071     0.187719      0.145721     0.141495    -0.0364513    0.0576446   -0.213928     -0.019457      0.00438375   0.0651104   -0.0115592    -0.190739    -0.0515389  -0.0636992   -0.0400653    0.0356653     0.016508    -0.0183717    0.108616      0.0791291   -0.0261098    0.0153525    -0.0525974    0.11224
  0.0194414    0.231347     0.188215      0.0302783     0.0476181    0.176405     0.100489    -0.118563    -0.0303703     0.0709757     0.0806346    2.35061e-6   0.0885092     0.099411    -0.0912418   0.0178685    0.0849529   -0.0658094     0.00572155   0.0813154   -0.0440458     0.0164782    0.0475857    0.0454292     0.101191    -0.106219
 -0.0253323   -0.0471542   -0.0910688     0.0272323     0.0151891   -0.112828    -0.0327069   -0.023852     0.00680472    0.215754     -0.00517108  -0.080232     0.0634804     0.0763396   -0.152802   -0.0434169   -0.0375119    0.0565013     0.153943     0.0648957    0.0587273     0.135728     0.00669497  -0.0305271    -0.0605963    0.0537628
 -0.160687     0.0286441    0.097473     -0.105466      0.0802556   -0.0477107    0.0791155   -0.0902373    0.0459051    -0.24878      -0.0857748   -0.0690447   -0.0985889    -0.161052     0.084025   -0.0376788    0.148654    -0.00389724    0.140697    -0.00447527   0.138324     -0.0369231    0.117557     0.135095     -0.109294    -0.194095
 -0.0649302   -0.0187214   -0.0963625    -0.0026117    -0.155673    -0.0637404    0.026741    -0.0151199   -0.233155     -0.0676959    -0.0555835   -0.0589041   -0.0165323    -0.0849103   -0.168248    0.00937617   0.021717     0.0736826     0.0487762    0.0831388    0.0361264    -0.0538219   -0.0692582    0.0309561     0.0944018   -0.152664
  0.171186     0.0666645   -0.00396062    0.0198895     0.0355565    0.079908    -0.0212768    0.142352     0.0154957     0.0651455     0.0573571    0.0787669   -0.000989555   0.00858855  -0.018653   -0.02618     -0.0179701   -0.127873      0.0175856   -0.0138584   -0.0433679     0.0421711   -0.125044    -0.0372152     0.124799     0.147932
 -0.162552    -0.0806888   -0.0344882     0.102095     -0.0388946   -0.0436532   -0.0173179    0.167375    -0.134878      0.0778194    -0.148025     0.0372928    0.0581565     0.0299399    0.0163322   0.114627     0.0126711    0.00249887   -0.0390823    0.0505824   -0.172145     -0.0438754    0.0675403   -0.0110998     0.10197      0.057102
 -0.0939631   -0.00391906   0.0117787     0.000928774  -0.074523     0.0318768   -0.272816    -0.0647525    0.0230202     0.00838355   -0.0138261    0.160382    -0.0206425    -0.00774464   0.0646811  -0.0388654    0.184553    -0.0783836     0.0903334   -0.0925897    0.299422     -0.0185598   -0.0282653   -0.0547535    -0.0827712   -0.130751
  0.0709941    0.0284748    0.0228637     0.0109521     0.0245763    0.127156     0.0475631   -0.0837464   -0.068579      0.121056     -0.0929328    0.0475107   -0.145426      0.0785501    0.0581411  -0.101832    -0.0278991    0.0872535    -0.0106379    0.0727707   -0.0978321    -0.0612037   -0.0735367    0.166653      0.0412081   -0.0758008
 -0.0189922    0.166913    -0.0160219    -0.00737874    0.103161     0.228278     0.0339587   -0.0621418   -0.00388164    0.168624     -0.0414304    0.123116     0.0198255     0.0971506    0.174802    0.104875     0.0448314   -0.139109      0.139678    -0.169231     0.0298169     0.106763     0.00683205  -0.0926176    -0.204815    -0.0857649
  0.0802981    0.0657464   -0.281135      0.0606303    -0.163437     0.151405    -0.0821694    0.058768    -0.0503358     0.249659      0.129981    -0.167212     0.0171811     0.130866    -0.193554   -0.192131    -0.00195997   0.000382616   0.0606013   -0.124409    -0.119356      0.0437139   -0.0244057   -0.21978      -0.0244506    0.00842009
 -0.00562354  -0.0502754   -0.0582599    -0.137505     -0.11045      0.0345123   -0.032098     0.0288035   -0.0644044    -0.162249      0.128072     0.0627907   -0.12079      -0.0478961    0.0535105   0.146751    -0.0732492   -0.18415       0.191366    -0.0278889   -0.11413       0.0392756    0.0197066    0.00439148   -0.0479493    0.0362405
  0.051535     0.0245435    0.0553986     0.0223983    -0.1329       0.100336    -0.039062     0.0337699   -0.00177426    0.0327349     0.130599     0.113773     0.100505      0.110327     0.0856397  -0.0643146    0.0923659   -0.0251633    -0.0935221    0.191677    -0.0248411     0.0259119    0.0766888    0.161503      0.146165     0.114701
  0.0840054    0.123332    -0.0318586     0.168025      0.131665    -0.185914     0.0678285   -0.0578304   -0.289515      0.0961553    -0.0477207   -0.0813799   -0.0775784    -0.00968727  -0.0130341  -0.163251    -0.141958     0.0257922    -0.119783     0.110667     0.189942     -0.0611082   -0.0772215    0.051124     -0.0796189   -0.0531639
  0.0304281    0.084465    -0.0295459    -0.0957522     0.112274     0.12014     -0.0435938    0.0601862    0.100584     -0.149062     -0.0975724   -0.075434     0.114384     -0.0556414    0.0232135  -0.00740507   0.0153347   -0.207114      0.106082    -0.0113741   -0.104081      0.0987553   -0.0629086   -0.0289093     0.0639212   -0.130664
  0.220002     0.140388    -0.138883     -0.208446     -0.0477929   -0.0233935   -0.0497048    0.182664    -0.0523296     0.0146947     0.0485011   -0.00701642   0.226224     -0.0806011    0.0399378   0.0396249   -0.0163543    0.233531      0.0187531    0.0939294   -0.0833772    -0.0469277   -0.107738    -0.0840058     0.0081983    0.0333801
  0.102897     0.0450561   -0.0486731     0.0566559     0.106095    -0.0889844    0.0760193   -0.144004     0.0545965     0.0286855     0.0844119   -0.100329     0.130741      0.0583272   -0.16215     0.0412914   -0.0616556    0.216623     -0.115676     0.0517099   -0.0633372    -0.0762845   -0.139873    -0.149715     -0.00960348   0.0686429
  0.0172902    0.0636097   -0.0525909    -0.0422491    -0.0942362   -0.134018    -0.155594    -0.0928313    0.0446205     0.0382979     0.0104103    0.0265418   -0.0372222     0.0892335   -0.215422   -0.127516    -0.188983     0.0278453     0.0976997    0.108578     0.0351743    -0.182757     0.201186     0.130276     -0.0293876    0.013386
  0.117566     0.0660978    0.0760398     0.0195692     0.201418    -0.0418523   -0.042951    -0.0122634   -0.0324657    -0.0346764    -0.0434645    0.0229057    0.233443      0.115002    -0.17677     0.0206215   -0.0630166    0.0979482    -0.0717889    0.0164469    0.0293808     0.0169725   -0.145957    -0.15362       0.131458     0.123478
 -0.0260057   -0.0293995   -0.0873133    -0.0379064    -0.0107418    0.0132234    0.0708205    0.00832457   0.167632      0.045312     -0.0130682   -0.184523     0.104263     -0.00898729  -0.0869207   0.0477262    0.0214729   -0.0612206     0.0298577    0.144309    -0.000792586  -0.0463097    0.147393     0.0227075    -0.100287    -0.115117
  0.106023    -0.061062    -0.0541731    -0.101682     -0.0341308    0.0139908   -0.0602199    0.0474038   -0.0187333    -0.0146171     0.145532    -0.00831248   0.0457807     0.0843131   -0.0552544   0.139632    -0.119984    -0.0501976     0.00762499  -0.190303    -0.0109628     0.105562    -0.00126565   0.0544692    -0.144921     0.0938343
 -0.0363045    0.0471836   -0.0347512    -0.207621      0.0393474    0.122819    -0.126098    -0.0196155   -0.188482      0.0840309     0.0365651    0.252016     0.0322168     0.0290424    0.0741965  -0.416369    -0.0684007    0.0652069    -0.0522202   -0.0333142    0.0236722     0.151496     0.0466766    0.0162815     0.144667    -0.153998
  0.0871786    0.0156635    0.0274315     0.0922563     0.0547178    0.120304    -0.0250144    0.0568392   -0.149899     -0.00246417    0.0110763    0.0473775   -0.0422157    -0.062122    -0.227908   -0.0262688   -0.0107305    0.0456549     0.0288779    0.038902     0.101648      0.174891    -0.0561457    0.0155548    -0.00569626   0.0305641
  0.0235348   -0.0691502   -0.00735176    0.0489082     0.00331682  -0.00330702  -0.0389712   -0.0196964    0.296748      0.10814       0.00667908  -0.0501498   -0.0591939    -0.0540493    0.0381288   0.0593158    0.0319322   -0.06119       0.0567781    0.00696822   0.0788782    -0.0967537    0.0263504   -0.0585981    -0.165168    -0.0892384
 -0.132596    -0.0914665   -0.000858464  -0.0487236    -0.205258     0.109017    -0.063744     0.0370081   -0.0388212    -0.168375      0.0891328    0.0403945    0.054311     -0.0426249    0.226522    0.07976      0.00800781   0.0845845     0.0789583    0.11637      0.0385557     0.189918    -0.0678097    0.01421      -0.00747083  -0.0900204
 -0.0955463    0.0594977    0.0848789     0.0382719    -0.209706    -0.0457031   -0.121369    -0.102473     0.0895744     0.0305286     0.0481891   -0.0222715    0.0449413    -0.0690316   -0.090105   -0.170853    -0.084216    -0.0424293    -0.112583     0.17039     -0.209317     -0.0198934    0.152005    -0.200134      0.0211251    0.00646004
  0.0277527    0.00325571  -0.0249662    -0.109048     -0.0602705   -0.0900286    0.111275     0.0401772    0.124203      0.213088      0.0635813    0.0817103   -0.248501     -0.204407     0.0639522  -0.0672578    0.101254    -0.0329108     0.0871951    0.0272674    0.186342      0.104202    -0.0645345    0.137441     -0.041305     0.0366266
 -0.0964446   -0.0202321   -0.0434117    -0.0086935     0.0411474    0.116753     0.196858    -0.0235938    0.0535323     0.000303899  -0.177939     0.0532105    0.106293     -0.243595     0.0390387  -0.173377     0.0420513   -0.205701     -0.118377    -0.0378189   -0.0382894     0.013992    -0.00626679   0.000672101   0.0974248   -0.10766
  0.0853218   -0.193378    -0.0108564    -0.0833486    -0.0165822    0.217576  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
  -0.00140739   0.00597777  -0.144732     -0.0901129    -0.00913127  -0.0895185   -0.247242     -0.106401    -0.070237    0.0997696   -0.102445    -0.111961     -0.115974    -0.00605463   0.0248578     0.00937991   0.0559268   -0.0212192     0.189931     0.118901
  0.148831     0.115319    -0.117005      0.0957166    -0.0237638   -0.124514    -0.0565631    0.0801483    0.000418031  -0.171078     -0.066256    -0.057623     0.151841     -0.0132545   -0.0724654   0.0441772   -0.0969012    0.039414     -0.0860605   -0.0416327   -0.166897     -0.0822879    0.0988983   -0.110115     -0.0606385    0.101324┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.017358
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      6
│     12
│      ⋮
│     24
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.968995
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│      6
│     12
│     20
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.993094
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      6
│     12
│     13
│     17
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.992475
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│      6
│     12
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.996555
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      6
│     12
│      ⋮
│     24
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.975637
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      6
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.011461
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      6
│     12
│      ⋮
│     24
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.979885
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│      6
│     12
│     20
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.994818
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      6
│     12
│     13
│     17
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.992468
┌ Info: EM with 100000 data points 10 iterations avll -0.992468
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0995648  -0.0233344   -0.0152691    0.176527      0.0571389   -0.138142     0.0969268   -0.0563023   -0.040924    0.00782896   0.126454    -0.025949    -0.0936465    0.250552    -0.00382137   0.126688    -0.167454     -0.0432961   -0.110254     0.0971323   -0.0855169   -0.0673727    0.0179046    0.0966748  -0.0297591    -0.0852012
 -0.0390779   0.0918638    0.0935853    0.0747378     0.145781     0.0959455   -0.0230803   -0.0283134    0.0542479   0.0124753    0.0999038   -0.112897    -0.0735524    0.187854     0.0707492   -0.00901749   0.0336608    -0.12179      0.0366217    0.135908    -0.00736681   0.0695746    0.0445289    0.0547545   0.0787316     0.0515729
  0.0231384  -0.11105      0.0225895    0.0726399     0.0241031   -0.0271379    0.207137     0.289561     0.0450888   0.182646     0.104292     0.0997052    0.107833    -0.149046    -0.145347    -0.0742822   -0.0656099     0.0177246   -0.145015    -0.024987    -0.199026    -0.0678201    0.141958     0.213148    0.033516      0.124658
  0.166467   -0.0549146   -0.192519    -0.0452808     0.0646509    0.0292336   -0.0990635    0.0503723   -0.0392078  -0.0167408    0.0828443   -0.0156147   -0.0955236   -0.0559208    0.0442473    0.00700761   0.0333347     0.152449     0.0341917   -0.0675528   -0.0499472   -0.135242     0.0344335    0.0422483  -0.131983      0.13661
  0.0281391  -0.0282813   -0.0410537    0.0362561    -0.144539     0.106064    -0.154482    -0.0730827   -0.0979956  -0.0940924   -0.0402421   -0.0327027   -0.0385165    0.179831    -0.219004    -0.238311    -0.0653029     0.0994277    0.0795809   -0.11865      0.0150661    0.0204573   -0.0660248   -0.116911    0.123596     -0.00599591
 -0.0722197   0.0906366   -0.13303     -0.0520107     0.0604756    0.0417016    0.106155    -0.103235     0.0666782   0.0498878    0.0774446   -0.0695749   -0.266175    -0.00408734  -0.0372447    0.0595642   -0.0943835     0.110472    -0.0208276    0.0729376   -0.016582     0.21843      0.0201492    0.159936    0.101737     -0.0430812
 -0.115858    0.0648396   -0.117291    -0.0661735    -0.0614817    0.24499     -0.0277381    0.208044     0.0900937   0.0964246   -0.0846391    0.116649     0.0731808   -0.063223    -0.0154736    0.0118884    0.000604623  -0.0635636   -0.0682513   -0.0016793    0.0307288    0.0173527   -0.0257635   -0.0874145  -0.166417     -0.0145699
  0.0509469  -0.259015     0.0187093    0.0220522    -0.100234    -0.00593038   0.0389092    0.00676919   0.229314   -0.0210098   -0.165059    -0.0330089    0.172495    -0.0392901    0.00817836   0.0356785   -0.0303441    -0.0263915    0.00184485   0.0408072    0.0884083   -0.0525813   -0.0111821   -0.0638777   0.124535     -0.139252
 -0.106064   -0.0973128    0.01833      0.00610082   -0.0710902    0.150537     0.120829    -0.00343327  -0.0720076  -0.137929    -0.107426    -0.192791     0.178578     0.100365     0.134052     0.119699    -3.98365e-5   -0.103367    -0.0390318    0.133834     0.0447985    0.0460363    0.0779414    0.035989    0.0544368    -0.0543079
 -0.0221908   0.0170123   -0.0167847    0.0897877    -0.0205516   -0.175383    -0.0752389   -0.0555025    0.125711   -0.0540204   -0.102619    -0.114886    -0.0710591    0.0153938   -0.0105698   -0.0443176    0.11797       0.0671647   -0.0716715   -0.16763      0.0637063    0.0592642   -0.126662     0.0980598   0.0212915    -0.0596383
  0.284809   -0.0552938    0.0168392   -0.0398254    -0.0897578   -0.254532     0.0401485    0.0460968   -0.0343692  -0.0668701   -0.0237035    0.128378    -0.025417    -0.126008     0.271494    -0.0778174   -0.0143751    -0.0167399   -0.194455    -0.0840456   -0.0807554    0.0306752   -0.0190569    0.0901714  -0.118876      0.0511023
  0.209742   -0.0451849    0.244969    -0.0905888     0.122994    -0.0410976    0.0739742    0.00641679   0.0917195  -0.0830351    0.0978657   -0.0198788   -0.0800066   -0.0392511   -0.0435588   -0.0131002    0.0241752     0.029671     0.0252961   -0.150942     0.200604    -0.0891671   -0.0304307    0.108536    0.0532678    -0.089663
 -0.260523    0.030484    -0.268414    -0.0921726    -0.21212      0.0378935   -0.0739155    0.0496718   -0.160136   -0.0737422    0.106486    -0.012223     0.0520719    0.170844     0.141994    -0.00994828  -0.136729      0.0587347   -0.100036     0.123009    -0.0994645   -0.0143637   -0.049184    -0.0811763   0.117137      0.0245847
 -0.0743517  -0.0192865   -0.03563      0.119831      0.0332013    0.0101936   -0.106064     0.12577     -0.0663505  -0.0520269    0.015004    -0.0413743   -0.0407581   -0.0166156    0.105369    -0.0647274    0.0323499    -0.0258658    0.0042625   -0.0891025    0.0413212   -0.0643229   -0.0676991    0.167238   -0.0743311    -0.0412542
 -0.0745686  -0.157913    -0.124153    -0.109438      0.0132165   -0.0934054   -0.118176    -0.052672    -0.129878   -0.0946351    0.0321658    0.0705178    0.0874159    0.0197758    0.145109     0.0538846   -0.0876241    -0.0933707    0.0503322   -0.0619027   -0.0640968   -0.0629296    0.0623623   -0.168135    0.151527     -0.00371977
 -0.149761    0.0317549    0.0421807    0.100766      0.0148645    0.0356136   -0.130327     0.0243886    0.163012   -0.0445433   -0.0429587   -0.0381292   -0.109184    -0.183654    -0.0313694    0.170823    -0.179278     -0.0395248   -0.111392     0.0503781   -0.0717163   -0.10772     -0.107674     0.144974    0.0763433    -0.129376
 -0.182415   -0.0622113   -0.0576952    0.0274305     0.0223018    0.143244    -0.0359772   -0.141495    -0.150676    0.0728137   -0.0751046    0.0292198   -0.0970791   -0.128354    -0.0458536    0.0184327   -0.0478382    -0.00536601   0.0992524   -0.0532274    0.17024      0.107181     0.0929672    0.0326506   0.000184794  -0.191878
 -0.207574   -0.0488293    0.0043873   -0.066607      0.00501048   0.0746908   -0.0964603    0.0485948    0.0404736   0.0422072    0.139862     0.0502726    0.0501108   -0.124536     0.03374     -0.0400296    0.0548262    -0.0305655   -0.0979556    0.0176836   -0.0373213   -0.0182309    0.0343193    0.0223368  -0.139618      0.0130963
  0.0889262  -0.0397302   -0.00146672  -0.114418     -0.0636014    0.0416022    0.0824341    0.104978    -0.0772469  -0.07536     -0.0854614   -0.143116     0.0996914    0.01588      0.224971    -0.0486464   -0.106057     -0.0449527    0.137764     0.0161463    0.13971      0.155929     0.125674     0.100765    0.0181591    -0.0325041
 -0.0858439   0.0741559   -0.0906625   -0.0284455    -0.0542217   -0.00556893   0.0179344   -0.127856     0.0146596   0.0486802   -0.103338    -0.0159072    0.0656259    0.244966     0.0113797   -0.0205837    0.0613894     0.0985682   -0.107169    -0.129836     0.0393697    0.150747    -0.0892414    0.0794688   0.0738023     0.0175246
  0.0745027   0.120109     0.0493914   -0.0668252     0.209197     0.00880225  -0.00870361  -0.00455767  -0.225002   -0.0361797   -0.0932855   -0.0321576    0.106687     0.147003     0.0341111    0.0323443    0.1594       -0.0984217    0.221913     0.122388     0.0184973    0.0933473   -0.00547729   0.0737842   0.136532     -0.114874
  0.0290891   0.0683655    0.203575     0.0378202    -0.133657     0.146883     0.0136595   -0.0105704   -0.0995618  -0.0328396    0.0616578   -0.0486314    0.169644    -0.0303643   -0.161592    -0.0850121    0.0789748     0.140363    -0.12008     -0.0289131    0.0273559    0.376596     0.094622     0.018894   -0.148616     -0.171716
 -0.107871    0.0365074   -0.0765736   -0.013705     -0.0264338   -0.0729695    0.0504141   -0.036663     0.0831247   0.1097       0.169438     0.0953783    0.013661    -0.0165004   -0.157045     0.257678     0.0129702    -0.157551    -0.00739077  -0.0572864    0.130534     0.126705    -0.0451677    0.0154196  -0.0857983    -0.0508453
 -0.0801967  -0.0168537    0.120031     0.00144246   -0.206479    -0.11611     -0.0044217    0.0928196   -0.109572    0.175471     0.0828307    0.0441847   -0.147067     0.112601    -0.0945642    0.148273    -0.0770486    -0.0484414    0.0370768    0.0407931    0.1245      -0.0147489   -0.00466051  -0.0587246  -0.0249235    -0.108038
  0.0789111  -0.00830648   0.199115     0.0667547     0.0179933   -0.0248724    0.0996374   -0.0227244    0.0820742  -0.0311004    0.019631     0.169015     0.173823    -0.0845694   -0.00861799   0.0902348    0.00305757   -0.0935808   -0.0163081   -0.170685    -0.262919     0.0083993   -0.135655     0.0541854   0.1757       -0.0123653
  0.147322    0.0246062   -0.0758847   -0.11359       0.0780223   -0.0117868   -0.0136263   -0.0561124   -0.0212898   0.21726      0.0716369    0.0734044    0.00661298   0.0150372   -0.117428     0.0611634    0.0440158     0.018293    -0.0396413   -0.0335036   -0.0015444    0.0471448   -0.145421    -0.193293    0.0492444    -0.0509866
 -0.0653191   0.00303906   0.211149     0.0495966     0.0569938   -0.0811117    0.229816     0.169031     0.0524872   0.133447     0.0454583    0.0649477    0.0788578   -0.0226653   -0.00508411   0.0383391    0.0623191    -0.12618      0.0171873   -0.0332555   -0.132904    -0.0484786    0.199861     0.0805144   0.0707572     0.139134
  0.140921    0.0777727   -0.0743698   -0.000772639   0.031942     0.059317    -0.0127028    0.109509     0.0443474  -0.164368     0.156296    -0.06669      0.183946    -0.0691288    0.0261063    0.0912595    0.0102482     0.108615     0.233949    -0.00775071  -0.00441981   0.0399021    0.0409674   -0.0743897  -0.161403      0.0530402
 -0.068464    0.108929    -0.0452558    0.0198065     0.112552    -0.06313      0.1458       0.0108682    0.15087    -0.00818508   0.0206432   -0.00919856   0.174092    -0.141976     0.059263     0.239906    -0.0144037     0.0544107   -0.0623375   -0.00984561   0.283727     0.233645     0.0871216   -0.0870632   0.156572      0.0470689
  0.0853438  -0.138826    -0.013428    -0.18027      -0.0638188    0.0594442    0.063778     0.146889     0.0340418   0.0359299   -0.182818    -0.00373852   0.06575     -0.0303746    0.135047     0.0050072   -0.109625     -0.0890233   -0.0204622   -0.0315448   -0.0229951    0.00629691   0.00447185   0.0129103  -0.0479122     0.0439085
  0.0331615   0.0516817   -0.0597817   -0.00800603    0.0524435   -0.297939     0.0766139   -0.0830299    0.145421    0.0704646    0.086668    -0.100199     0.0536219   -0.0169049   -0.103903     0.0336345    0.017893      0.177484     0.107957    -0.0941148    0.0455897    0.186139     0.0117584   -0.0405713  -0.149871     -0.259164
  0.194133   -0.0577084   -0.0306188    0.021471     -0.0558886   -0.0616566   -0.0348525    0.0670318    0.0724328  -0.104696    -0.00874252   0.234068     0.0382545   -0.0529531   -0.012882     0.0141409    0.0239279     0.0722004    0.0677148    0.0481071   -0.20778     -0.0272674    0.126233    -0.0170808   0.00983393    0.0774773kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4143215802565607
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414340
[ Info: iteration 2, average log likelihood -1.414248
[ Info: iteration 3, average log likelihood -1.414169
[ Info: iteration 4, average log likelihood -1.414075
[ Info: iteration 5, average log likelihood -1.413956
[ Info: iteration 6, average log likelihood -1.413796
[ Info: iteration 7, average log likelihood -1.413550
[ Info: iteration 8, average log likelihood -1.413139
[ Info: iteration 9, average log likelihood -1.412462
[ Info: iteration 10, average log likelihood -1.411511
[ Info: iteration 11, average log likelihood -1.410491
[ Info: iteration 12, average log likelihood -1.409704
[ Info: iteration 13, average log likelihood -1.409259
[ Info: iteration 14, average log likelihood -1.409054
[ Info: iteration 15, average log likelihood -1.408968
[ Info: iteration 16, average log likelihood -1.408933
[ Info: iteration 17, average log likelihood -1.408918
[ Info: iteration 18, average log likelihood -1.408912
[ Info: iteration 19, average log likelihood -1.408910
[ Info: iteration 20, average log likelihood -1.408908
[ Info: iteration 21, average log likelihood -1.408908
[ Info: iteration 22, average log likelihood -1.408907
[ Info: iteration 23, average log likelihood -1.408907
[ Info: iteration 24, average log likelihood -1.408907
[ Info: iteration 25, average log likelihood -1.408907
[ Info: iteration 26, average log likelihood -1.408907
[ Info: iteration 27, average log likelihood -1.408906
[ Info: iteration 28, average log likelihood -1.408906
[ Info: iteration 29, average log likelihood -1.408906
[ Info: iteration 30, average log likelihood -1.408906
[ Info: iteration 31, average log likelihood -1.408906
[ Info: iteration 32, average log likelihood -1.408906
[ Info: iteration 33, average log likelihood -1.408906
[ Info: iteration 34, average log likelihood -1.408906
[ Info: iteration 35, average log likelihood -1.408906
[ Info: iteration 36, average log likelihood -1.408906
[ Info: iteration 37, average log likelihood -1.408906
[ Info: iteration 38, average log likelihood -1.408906
[ Info: iteration 39, average log likelihood -1.408906
[ Info: iteration 40, average log likelihood -1.408906
[ Info: iteration 41, average log likelihood -1.408905
[ Info: iteration 42, average log likelihood -1.408905
[ Info: iteration 43, average log likelihood -1.408905
[ Info: iteration 44, average log likelihood -1.408905
[ Info: iteration 45, average log likelihood -1.408905
[ Info: iteration 46, average log likelihood -1.408905
[ Info: iteration 47, average log likelihood -1.408905
[ Info: iteration 48, average log likelihood -1.408905
[ Info: iteration 49, average log likelihood -1.408905
[ Info: iteration 50, average log likelihood -1.408905
┌ Info: EM with 100000 data points 50 iterations avll -1.408905
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4143397016163148
│     -1.414247681198198
│      ⋮
└     -1.408905309812306
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408923
[ Info: iteration 2, average log likelihood -1.408829
[ Info: iteration 3, average log likelihood -1.408749
[ Info: iteration 4, average log likelihood -1.408658
[ Info: iteration 5, average log likelihood -1.408556
[ Info: iteration 6, average log likelihood -1.408450
[ Info: iteration 7, average log likelihood -1.408353
[ Info: iteration 8, average log likelihood -1.408273
[ Info: iteration 9, average log likelihood -1.408212
[ Info: iteration 10, average log likelihood -1.408167
[ Info: iteration 11, average log likelihood -1.408135
[ Info: iteration 12, average log likelihood -1.408110
[ Info: iteration 13, average log likelihood -1.408091
[ Info: iteration 14, average log likelihood -1.408076
[ Info: iteration 15, average log likelihood -1.408064
[ Info: iteration 16, average log likelihood -1.408054
[ Info: iteration 17, average log likelihood -1.408044
[ Info: iteration 18, average log likelihood -1.408035
[ Info: iteration 19, average log likelihood -1.408027
[ Info: iteration 20, average log likelihood -1.408017
[ Info: iteration 21, average log likelihood -1.408008
[ Info: iteration 22, average log likelihood -1.407997
[ Info: iteration 23, average log likelihood -1.407985
[ Info: iteration 24, average log likelihood -1.407972
[ Info: iteration 25, average log likelihood -1.407957
[ Info: iteration 26, average log likelihood -1.407941
[ Info: iteration 27, average log likelihood -1.407924
[ Info: iteration 28, average log likelihood -1.407906
[ Info: iteration 29, average log likelihood -1.407888
[ Info: iteration 30, average log likelihood -1.407869
[ Info: iteration 31, average log likelihood -1.407850
[ Info: iteration 32, average log likelihood -1.407833
[ Info: iteration 33, average log likelihood -1.407816
[ Info: iteration 34, average log likelihood -1.407801
[ Info: iteration 35, average log likelihood -1.407788
[ Info: iteration 36, average log likelihood -1.407776
[ Info: iteration 37, average log likelihood -1.407765
[ Info: iteration 38, average log likelihood -1.407756
[ Info: iteration 39, average log likelihood -1.407748
[ Info: iteration 40, average log likelihood -1.407740
[ Info: iteration 41, average log likelihood -1.407734
[ Info: iteration 42, average log likelihood -1.407729
[ Info: iteration 43, average log likelihood -1.407724
[ Info: iteration 44, average log likelihood -1.407720
[ Info: iteration 45, average log likelihood -1.407716
[ Info: iteration 46, average log likelihood -1.407713
[ Info: iteration 47, average log likelihood -1.407710
[ Info: iteration 48, average log likelihood -1.407707
[ Info: iteration 49, average log likelihood -1.407705
[ Info: iteration 50, average log likelihood -1.407703
┌ Info: EM with 100000 data points 50 iterations avll -1.407703
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4089231994618636
│     -1.4088290083442725
│      ⋮
└     -1.407702632869098
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407712
[ Info: iteration 2, average log likelihood -1.407646
[ Info: iteration 3, average log likelihood -1.407589
[ Info: iteration 4, average log likelihood -1.407521
[ Info: iteration 5, average log likelihood -1.407439
[ Info: iteration 6, average log likelihood -1.407341
[ Info: iteration 7, average log likelihood -1.407231
[ Info: iteration 8, average log likelihood -1.407115
[ Info: iteration 9, average log likelihood -1.407001
[ Info: iteration 10, average log likelihood -1.406897
[ Info: iteration 11, average log likelihood -1.406805
[ Info: iteration 12, average log likelihood -1.406727
[ Info: iteration 13, average log likelihood -1.406661
[ Info: iteration 14, average log likelihood -1.406606
[ Info: iteration 15, average log likelihood -1.406561
[ Info: iteration 16, average log likelihood -1.406523
[ Info: iteration 17, average log likelihood -1.406490
[ Info: iteration 18, average log likelihood -1.406462
[ Info: iteration 19, average log likelihood -1.406437
[ Info: iteration 20, average log likelihood -1.406415
[ Info: iteration 21, average log likelihood -1.406395
[ Info: iteration 22, average log likelihood -1.406377
[ Info: iteration 23, average log likelihood -1.406360
[ Info: iteration 24, average log likelihood -1.406346
[ Info: iteration 25, average log likelihood -1.406332
[ Info: iteration 26, average log likelihood -1.406320
[ Info: iteration 27, average log likelihood -1.406309
[ Info: iteration 28, average log likelihood -1.406300
[ Info: iteration 29, average log likelihood -1.406291
[ Info: iteration 30, average log likelihood -1.406283
[ Info: iteration 31, average log likelihood -1.406276
[ Info: iteration 32, average log likelihood -1.406269
[ Info: iteration 33, average log likelihood -1.406263
[ Info: iteration 34, average log likelihood -1.406257
[ Info: iteration 35, average log likelihood -1.406252
[ Info: iteration 36, average log likelihood -1.406247
[ Info: iteration 37, average log likelihood -1.406242
[ Info: iteration 38, average log likelihood -1.406237
[ Info: iteration 39, average log likelihood -1.406233
[ Info: iteration 40, average log likelihood -1.406228
[ Info: iteration 41, average log likelihood -1.406224
[ Info: iteration 42, average log likelihood -1.406220
[ Info: iteration 43, average log likelihood -1.406216
[ Info: iteration 44, average log likelihood -1.406212
[ Info: iteration 45, average log likelihood -1.406207
[ Info: iteration 46, average log likelihood -1.406203
[ Info: iteration 47, average log likelihood -1.406199
[ Info: iteration 48, average log likelihood -1.406195
[ Info: iteration 49, average log likelihood -1.406190
[ Info: iteration 50, average log likelihood -1.406186
┌ Info: EM with 100000 data points 50 iterations avll -1.406186
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4077118983891592
│     -1.4076464747754758
│      ⋮
└     -1.4061860126210948
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406190
[ Info: iteration 2, average log likelihood -1.406125
[ Info: iteration 3, average log likelihood -1.406061
[ Info: iteration 4, average log likelihood -1.405984
[ Info: iteration 5, average log likelihood -1.405887
[ Info: iteration 6, average log likelihood -1.405767
[ Info: iteration 7, average log likelihood -1.405627
[ Info: iteration 8, average log likelihood -1.405476
[ Info: iteration 9, average log likelihood -1.405322
[ Info: iteration 10, average log likelihood -1.405175
[ Info: iteration 11, average log likelihood -1.405038
[ Info: iteration 12, average log likelihood -1.404914
[ Info: iteration 13, average log likelihood -1.404804
[ Info: iteration 14, average log likelihood -1.404706
[ Info: iteration 15, average log likelihood -1.404621
[ Info: iteration 16, average log likelihood -1.404547
[ Info: iteration 17, average log likelihood -1.404483
[ Info: iteration 18, average log likelihood -1.404428
[ Info: iteration 19, average log likelihood -1.404379
[ Info: iteration 20, average log likelihood -1.404337
[ Info: iteration 21, average log likelihood -1.404300
[ Info: iteration 22, average log likelihood -1.404267
[ Info: iteration 23, average log likelihood -1.404236
[ Info: iteration 24, average log likelihood -1.404208
[ Info: iteration 25, average log likelihood -1.404182
[ Info: iteration 26, average log likelihood -1.404158
[ Info: iteration 27, average log likelihood -1.404135
[ Info: iteration 28, average log likelihood -1.404114
[ Info: iteration 29, average log likelihood -1.404093
[ Info: iteration 30, average log likelihood -1.404073
[ Info: iteration 31, average log likelihood -1.404053
[ Info: iteration 32, average log likelihood -1.404034
[ Info: iteration 33, average log likelihood -1.404016
[ Info: iteration 34, average log likelihood -1.403998
[ Info: iteration 35, average log likelihood -1.403980
[ Info: iteration 36, average log likelihood -1.403963
[ Info: iteration 37, average log likelihood -1.403947
[ Info: iteration 38, average log likelihood -1.403931
[ Info: iteration 39, average log likelihood -1.403915
[ Info: iteration 40, average log likelihood -1.403899
[ Info: iteration 41, average log likelihood -1.403885
[ Info: iteration 42, average log likelihood -1.403870
[ Info: iteration 43, average log likelihood -1.403856
[ Info: iteration 44, average log likelihood -1.403843
[ Info: iteration 45, average log likelihood -1.403830
[ Info: iteration 46, average log likelihood -1.403817
[ Info: iteration 47, average log likelihood -1.403805
[ Info: iteration 48, average log likelihood -1.403793
[ Info: iteration 49, average log likelihood -1.403782
[ Info: iteration 50, average log likelihood -1.403771
┌ Info: EM with 100000 data points 50 iterations avll -1.403771
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4061897493191455
│     -1.4061246069743576
│      ⋮
└     -1.4037706731376336
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.403769
[ Info: iteration 2, average log likelihood -1.403702
[ Info: iteration 3, average log likelihood -1.403636
[ Info: iteration 4, average log likelihood -1.403557
[ Info: iteration 5, average log likelihood -1.403457
[ Info: iteration 6, average log likelihood -1.403331
[ Info: iteration 7, average log likelihood -1.403180
[ Info: iteration 8, average log likelihood -1.403010
[ Info: iteration 9, average log likelihood -1.402833
[ Info: iteration 10, average log likelihood -1.402659
[ Info: iteration 11, average log likelihood -1.402496
[ Info: iteration 12, average log likelihood -1.402348
[ Info: iteration 13, average log likelihood -1.402215
[ Info: iteration 14, average log likelihood -1.402096
[ Info: iteration 15, average log likelihood -1.401991
[ Info: iteration 16, average log likelihood -1.401898
[ Info: iteration 17, average log likelihood -1.401816
[ Info: iteration 18, average log likelihood -1.401743
[ Info: iteration 19, average log likelihood -1.401678
[ Info: iteration 20, average log likelihood -1.401620
[ Info: iteration 21, average log likelihood -1.401567
[ Info: iteration 22, average log likelihood -1.401519
[ Info: iteration 23, average log likelihood -1.401475
[ Info: iteration 24, average log likelihood -1.401435
[ Info: iteration 25, average log likelihood -1.401397
[ Info: iteration 26, average log likelihood -1.401362
[ Info: iteration 27, average log likelihood -1.401329
[ Info: iteration 28, average log likelihood -1.401297
[ Info: iteration 29, average log likelihood -1.401267
[ Info: iteration 30, average log likelihood -1.401239
[ Info: iteration 31, average log likelihood -1.401212
[ Info: iteration 32, average log likelihood -1.401186
[ Info: iteration 33, average log likelihood -1.401161
[ Info: iteration 34, average log likelihood -1.401137
[ Info: iteration 35, average log likelihood -1.401115
[ Info: iteration 36, average log likelihood -1.401093
[ Info: iteration 37, average log likelihood -1.401072
[ Info: iteration 38, average log likelihood -1.401052
[ Info: iteration 39, average log likelihood -1.401033
[ Info: iteration 40, average log likelihood -1.401014
[ Info: iteration 41, average log likelihood -1.400996
[ Info: iteration 42, average log likelihood -1.400979
[ Info: iteration 43, average log likelihood -1.400963
[ Info: iteration 44, average log likelihood -1.400947
[ Info: iteration 45, average log likelihood -1.400932
[ Info: iteration 46, average log likelihood -1.400917
[ Info: iteration 47, average log likelihood -1.400902
[ Info: iteration 48, average log likelihood -1.400889
[ Info: iteration 49, average log likelihood -1.400875
[ Info: iteration 50, average log likelihood -1.400862
┌ Info: EM with 100000 data points 50 iterations avll -1.400862
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.44295     -0.386386   -0.548111   -0.447707    0.0720675   0.308751    -0.333811    0.484804   -0.194341     0.309912   -0.269741    0.0748886   0.0876006   -0.129924    -0.535189    ┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4037687746496603
│     -1.4037016885970888
│      ⋮
└     -1.4008618842430398
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4143215802565607
│     -1.4143397016163148
│     -1.414247681198198
│     -1.4141690079699842
│      ⋮
│     -1.400888534442179
│     -1.4008750137577681
└     -1.4008618842430398
0.128326   -0.563803   -0.0854028     0.0596044   -0.00211437   0.184581   -0.173669    0.00174609   0.0752916   0.0142817    0.278585
  0.46454     -0.226042   -0.326353    0.0627079   0.361832    0.0226169   -0.415618   -0.0874131  -0.211408     0.654737    0.816349    0.154114   -0.119863     0.348926    -0.219983    0.268612   -0.456904   -0.216354     -0.431391     0.322252     0.0526761  -0.436703    0.0825634   -0.425457    0.326508     0.123545
  0.364805    -0.0295962  -0.0791796  -0.168766    0.163536    0.0935353   -0.160742    0.339628    0.0384845   -0.537953    0.154865   -0.0698554  -0.345303    -0.205464    -1.11172     0.17154     0.617952    0.217317     -0.159337    -0.126266     0.171781   -0.210722   -0.1505       0.527752    0.386311    -0.255969
  0.59194     -0.437092   -0.204827    0.0187713   0.0978109  -0.150367    -0.297416    0.301659   -0.117304    -0.109799   -0.376201    0.557215    0.0533173    0.0145375    0.235665   -0.299019    0.578551    0.17954      -0.541268    -0.245662    -0.205944   -0.481771   -0.487027     0.325471   -0.159374     0.338733
 -0.0239263   -0.123931   -0.340348   -0.163799   -0.35734    -0.682124     0.175621   -0.305015    0.178839     0.316907   -0.289062    0.281514   -0.603639     0.185804     0.121408    0.518512   -0.173345   -0.409845     -0.908652    -0.523742     0.550814    0.110604   -0.268585    -0.0387857   0.140841    -0.10037
 -0.24041      0.577436    0.100504    0.314856   -0.461859   -0.161151     0.0637579   0.758889    0.0731932    0.0475233  -0.831897    0.440723   -0.553104    -0.486136    -0.0631723   0.471439    0.589246   -0.0733523    -0.468267     0.104311     0.0083058   0.0749308  -0.666414     0.429273   -0.315976     0.11708
  0.0319656   -0.176334   -0.186781    0.233483    0.191088   -0.356187    -0.0782991   0.58912     0.27014     -0.323208    0.171509    0.271194    0.514566    -0.0764765   -0.112373    0.182976   -0.0559292  -0.165143     -0.394674    -0.174843    -0.631852    0.214418    0.146396    -0.206022    0.672002     0.484075
 -0.511224     0.124066   -0.170572    0.218846   -0.115046    0.0455387    0.836174    0.571404    0.203666     0.231514    0.253118    0.342935   -0.200042     0.496511    -0.131771    0.196614   -0.0630631   0.273435     -0.125385     0.151745    -0.482356   -0.315896    0.551838     0.165836    0.141334    -0.338909
 -0.201293     0.260068   -0.168224    0.26419     0.487656   -0.263856    -0.170311   -0.538654   -0.18012     -0.174733    0.334006   -0.416012    0.189576     0.00952471  -0.236644    0.349191   -0.0189182   0.0492687     0.11653     -0.247356     0.0861116   0.277999   -0.163657     0.182522    0.553048    -0.573195
 -0.113735     0.301221    0.0453613  -0.0175488   0.374446   -0.315663     0.218613    0.217701   -0.24377      0.0326046   0.264215   -0.377566   -0.19632     -0.0574732   -0.566855    0.588685    0.20455    -0.397381     -0.102376    -0.098749     0.111623    0.235093    0.196695     0.202494    0.354616     0.287108
 -0.381158     0.57042    -0.163925    0.0296438  -0.164053    0.368915    -0.146085   -0.500438    0.456045    -0.342645   -0.0482669  -0.524465    0.340622    -0.355991     0.579854    0.287104   -0.881393    0.000912945   0.196232     0.11         0.126266    0.465263   -0.195057    -0.350124   -0.00940616  -0.239315
 -0.697411     0.268695    0.574929    0.0420182  -0.337192    0.0612627    0.649923   -0.0226591  -0.00996428   0.301847    0.119066   -0.455906    0.00415905  -0.282753     0.338224    0.0999245  -0.0359399  -0.201094      0.2394       0.360499     0.0458333   0.463874    0.643565    -0.328983    0.026351     0.0102564
  0.00815961  -0.0253853   0.0984223  -0.195341   -0.169642   -0.0288013    0.0616712  -0.031139    0.0111532   -0.0782848  -0.472654   -0.242187    0.0892872    0.0139761    0.159978   -0.0503288   0.114271   -0.0314052     0.153686    -0.0493375    0.0169556   0.146638   -0.135041     0.370247   -0.226186    -0.0397851
  0.0394211   -0.16782     0.0465238  -0.0848181  -0.185405    0.0119681    0.0229795   0.0236813   0.0178662    0.0654428   0.164203   -0.082035   -0.0261283    0.0217765    0.0270083  -0.011132   -0.180153    0.056549     -0.0603946    0.0986242   -0.0049876  -0.0721092   0.0477748   -0.130423    0.12882     -0.104484
  0.126567     0.180368   -0.080468    0.0363677   0.444711    0.181672    -0.150713   -0.0901969   0.144481    -0.0540978   0.0750692   0.645968    0.0718584    0.588551     0.0624599  -0.275607    0.186368    0.104472      0.359315     0.0683243   -0.0429636   0.049394    0.181461     0.0202399  -0.236958    -0.284476
 -0.148127     0.318019   -0.105815    0.52254     0.103134    0.118855    -0.149471    0.0704901   0.0679814   -0.0561676   0.213919    0.475808   -0.180632    -0.28762      0.118048   -0.0559069   0.0555818  -0.0483898    -0.174767    -0.0943441    0.377748   -0.149982   -0.231566    -0.403456   -0.240813     0.306103
 -0.106856    -0.303134    0.233882   -0.080912   -0.820742   -0.202788     0.0241188   0.187503    0.00175119   0.23143    -0.254527   -0.73243     0.00772564  -0.750641    -0.122135    0.17841    -0.355913   -0.0107316    -0.5336       0.300927     0.0755524  -0.177617   -0.34898     -0.144346    0.396486    -0.263411
  0.172101    -0.205441   -0.110763    0.0726207  -0.279249   -0.407028     0.0153774  -0.50385    -0.539153    -0.309897    0.396821   -0.600484   -0.178677    -0.852879     0.0599585   0.14499    -0.427687    0.224609      0.00425397  -0.322168     0.416475   -0.124513   -0.292567     0.0245811  -0.0426638    0.411969
 -0.0459121    0.009812    0.0238744  -0.10386     0.042579    0.00729155   0.112361   -0.0845487  -0.0662748    0.0857643   0.0220739  -0.117459   -0.0744184   -0.0180957   -0.0345036   0.0606525  -0.0212343   0.0425915     0.00216191   0.0028469    0.104773   -0.0306167   0.111064     0.161528    0.00353169  -0.175192
 -0.258247    -0.047719   -0.41911     0.696368   -0.0254245  -0.306049     0.111595    0.896498   -0.295184    -0.215569    0.368933    0.0173045   0.758733    -0.369447    -0.0790307   0.214846   -0.0699648  -0.403051     -0.348579    -0.0488998   -0.187149   -0.0810038  -0.0737538   -0.209665    0.158051     0.840502
  0.303818    -0.305087   -0.0434111  -0.573341   -0.159076    0.166705     0.26748    -0.493112    0.037414     0.301231   -0.321482   -0.416367   -0.533288     0.401534    -0.181489   -0.208246   -0.101291    0.521014      0.497773    -0.117533    -0.335435    0.220368    0.301485     0.523697   -0.065655    -0.520595
 -0.160828     0.411672   -0.303393   -0.311682    0.650946    0.154332     0.31983    -0.0638508  -0.412998     0.440239   -0.208054   -0.416851    0.15727      0.123712    -0.133659   -0.600434    0.125115   -0.081198      0.176115     0.23774      0.436739   -0.546768    0.198412     0.661568   -0.256552    -0.380993
 -0.117601     0.135958    0.211251   -0.32015    -0.048685    0.492001    -0.165422    0.527154    0.215188    -0.123056    0.0251579  -0.161855   -0.0127326   -0.156023    -0.600124    0.310756    0.361362    0.107315      0.146353    -0.0136682    0.0120775   1.20186     0.356888    -0.492874    0.121654     0.0828888
 -0.100134    -0.14815     0.238675    0.062529   -0.0547728   0.114261    -0.41368     0.219373    0.0105338    0.502589   -0.43641    -0.0562645  -0.0627945    1.0266      -0.323512    0.472252    0.435718   -0.490782      0.0111567    0.172047    -0.0599281   0.680312    0.0116496    0.220016    0.225568    -0.589744
 -0.282507    -0.615344   -0.155032   -0.0371454  -0.451781   -0.552582     0.267382   -0.10557    -0.120504    -0.0705113  -0.0723475  -0.26443     0.421165     0.425181     0.875502   -0.216887   -0.281282    0.143385     -0.0773559   -0.620441    -0.65262     0.373673    0.319484    -0.196126   -0.234344     0.25842
 -0.290727     0.352957    0.365209    0.14049     0.356191   -0.396669     0.220106   -0.214133    0.139435     0.0796619  -0.477332    0.11981     0.741907     0.0206678    0.812674   -0.310089    0.248401   -0.546111     -0.0202735   -0.530625     0.3015      0.282132   -0.282898    -0.0816079  -0.412122    -0.124477
 -0.125979    -0.409893    0.171392   -0.183236    0.313184    0.268402    -0.591905   -0.803771    0.0107427   -0.139031    0.718292   -0.266374    0.058891    -0.210817     0.0170854  -0.774645   -0.146929    0.430041      0.487142     0.490547    -0.214716    0.25442     0.493431    -0.115342    0.59        -0.448125
  0.129485    -0.172276    0.0512729  -0.108321    0.566698   -0.443574     0.309313   -0.415147    0.286315    -0.662651    0.195686   -0.39478     0.678939     0.24993      0.432436    0.514561   -0.378741   -0.0243754     0.321752    -0.169176    -0.908577   -0.0127552   0.334057     0.580128    0.416709     0.191429
  0.436662     0.0472833   0.297019    0.254796   -0.520355    0.0697646    0.295788   -0.68259    -0.043801    -0.0832164   0.0985378   0.24686    -0.213415    -0.00709505   0.710225   -0.666945    0.106011    0.715507      0.388671    -0.0895413    0.103014   -0.36226    -0.194427     0.0206222  -0.558856    -0.492398
  0.0598099   -0.0241613   1.08577     0.343981   -0.436223   -0.188768    -0.288457   -0.833486    0.987209    -0.511299    0.130005    0.457423   -0.621478     0.488465     0.461022    0.4546      0.245491    0.346901      0.257016     0.169792     0.10129    -0.242552   -0.50047      0.0624144   0.0886939   -0.0561062
  0.297756     0.16212    -0.171467    0.0511122   0.260088    0.426742    -0.454659    0.35869     0.0682552    0.027345   -0.278857    1.27668     0.0969519    0.428347     0.129388   -0.317493    0.255184    0.0521465     0.329867     0.117815    -0.106094    0.0457365  -0.0636327   -0.342702   -0.507658     0.125387
 -0.227659     0.0696642   0.367562   -0.26339    -0.26144     0.936613     0.300745    0.337378    0.20917     -0.269118    0.740867    0.208798    0.212094    -0.280329    -0.0661738  -0.301917   -0.321099   -0.154332      0.371093     0.552274     0.338694   -0.198494    0.409364    -0.514104   -0.421955     0.151174[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.400849
[ Info: iteration 2, average log likelihood -1.400837
[ Info: iteration 3, average log likelihood -1.400825
[ Info: iteration 4, average log likelihood -1.400813
[ Info: iteration 5, average log likelihood -1.400802
[ Info: iteration 6, average log likelihood -1.400790
[ Info: iteration 7, average log likelihood -1.400780
[ Info: iteration 8, average log likelihood -1.400769
[ Info: iteration 9, average log likelihood -1.400759
[ Info: iteration 10, average log likelihood -1.400749
┌ Info: EM with 100000 data points 10 iterations avll -1.400749
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind full, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.084291e+05
      1       6.916182e+05      -2.168110e+05 |       32
      2       6.789843e+05      -1.263384e+04 |       32
      3       6.741444e+05      -4.839935e+03 |       32
      4       6.716665e+05      -2.477848e+03 |       32
      5       6.700722e+05      -1.594300e+03 |       32
      6       6.688667e+05      -1.205571e+03 |       32
      7       6.679651e+05      -9.015790e+02 |       32
      8       6.672241e+05      -7.409943e+02 |       32
      9       6.665810e+05      -6.430647e+02 |       32
     10       6.659975e+05      -5.835143e+02 |       32
     11       6.654760e+05      -5.215412e+02 |       32
     12       6.649798e+05      -4.961353e+02 |       32
     13       6.645353e+05      -4.445838e+02 |       32
     14       6.641400e+05      -3.952520e+02 |       32
     15       6.637937e+05      -3.463069e+02 |       32
     16       6.635000e+05      -2.936530e+02 |       32
     17       6.632305e+05      -2.695414e+02 |       32
     18       6.630072e+05      -2.232665e+02 |       32
     19       6.628340e+05      -1.732434e+02 |       32
     20       6.626906e+05      -1.434221e+02 |       32
     21       6.625499e+05      -1.406470e+02 |       32
     22       6.624291e+05      -1.208005e+02 |       32
     23       6.623309e+05      -9.821836e+01 |       32
     24       6.622476e+05      -8.330959e+01 |       32
     25       6.621652e+05      -8.237636e+01 |       32
     26       6.620919e+05      -7.334157e+01 |       32
     27       6.620193e+05      -7.262078e+01 |       32
     28       6.619487e+05      -7.052709e+01 |       32
     29       6.618774e+05      -7.137113e+01 |       32
     30       6.618183e+05      -5.902137e+01 |       32
     31       6.617688e+05      -4.952367e+01 |       32
     32       6.617264e+05      -4.243669e+01 |       32
     33       6.616832e+05      -4.312867e+01 |       32
     34       6.616482e+05      -3.499520e+01 |       32
     35       6.616177e+05      -3.055140e+01 |       32
     36       6.615866e+05      -3.107393e+01 |       32
     37       6.615572e+05      -2.937369e+01 |       32
     38       6.615258e+05      -3.145493e+01 |       32
     39       6.614939e+05      -3.186220e+01 |       32
     40       6.614626e+05      -3.130247e+01 |       32
     41       6.614318e+05      -3.083988e+01 |       32
     42       6.614033e+05      -2.846391e+01 |       32
     43       6.613800e+05      -2.336159e+01 |       32
     44       6.613570e+05      -2.300986e+01 |       32
     45       6.613333e+05      -2.363358e+01 |       32
     46       6.613088e+05      -2.447612e+01 |       32
     47       6.612866e+05      -2.227061e+01 |       32
     48       6.612634e+05      -2.318408e+01 |       32
     49       6.612404e+05      -2.299773e+01 |       32
     50       6.612177e+05      -2.272551e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 661217.6655061485)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412433
[ Info: iteration 2, average log likelihood -1.407587
[ Info: iteration 3, average log likelihood -1.406310
[ Info: iteration 4, average log likelihood -1.405386
[ Info: iteration 5, average log likelihood -1.404378
[ Info: iteration 6, average log likelihood -1.403362
[ Info: iteration 7, average log likelihood -1.402600
[ Info: iteration 8, average log likelihood -1.402158
[ Info: iteration 9, average log likelihood -1.401916
[ Info: iteration 10, average log likelihood -1.401769
[ Info: iteration 11, average log likelihood -1.401664
[ Info: iteration 12, average log likelihood -1.401583
[ Info: iteration 13, average log likelihood -1.401514
[ Info: iteration 14, average log likelihood -1.401454
[ Info: iteration 15, average log likelihood -1.401400
[ Info: iteration 16, average log likelihood -1.401351
[ Info: iteration 17, average log likelihood -1.401304
[ Info: iteration 18, average log likelihood -1.401260
[ Info: iteration 19, average log likelihood -1.401219
[ Info: iteration 20, average log likelihood -1.401179
[ Info: iteration 21, average log likelihood -1.401141
[ Info: iteration 22, average log likelihood -1.401104
[ Info: iteration 23, average log likelihood -1.401070
[ Info: iteration 24, average log likelihood -1.401037
[ Info: iteration 25, average log likelihood -1.401007
[ Info: iteration 26, average log likelihood -1.400978
[ Info: iteration 27, average log likelihood -1.400951
[ Info: iteration 28, average log likelihood -1.400925
[ Info: iteration 29, average log likelihood -1.400902
[ Info: iteration 30, average log likelihood -1.400879
[ Info: iteration 31, average log likelihood -1.400859
[ Info: iteration 32, average log likelihood -1.400839
[ Info: iteration 33, average log likelihood -1.400821
[ Info: iteration 34, average log likelihood -1.400804
[ Info: iteration 35, average log likelihood -1.400788
[ Info: iteration 36, average log likelihood -1.400773
[ Info: iteration 37, average log likelihood -1.400759
[ Info: iteration 38, average log likelihood -1.400746
[ Info: iteration 39, average log likelihood -1.400733
[ Info: iteration 40, average log likelihood -1.400721
[ Info: iteration 41, average log likelihood -1.400710
[ Info: iteration 42, average log likelihood -1.400699
[ Info: iteration 43, average log likelihood -1.400689
[ Info: iteration 44, average log likelihood -1.400679
[ Info: iteration 45, average log likelihood -1.400669
[ Info: iteration 46, average log likelihood -1.400660
[ Info: iteration 47, average log likelihood -1.400652
[ Info: iteration 48, average log likelihood -1.400643
[ Info: iteration 49, average log likelihood -1.400635
[ Info: iteration 50, average log likelihood -1.400627
┌ Info: EM with 100000 data points 50 iterations avll -1.400627
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0814261    0.141003   -0.104498     0.20501    -0.191756    -0.77484      -0.106927    0.443895    -0.232917    0.346987    -0.870138    0.129878   -0.695881    -0.129078   -0.11332     0.661719     0.672495    -0.124262    -0.58261     -0.288109    -0.387127     0.321082    -0.549749     0.632639    0.168641    0.158151
 -0.00480447  -0.198864   -0.277888     0.581537    0.0200892   -0.407359      0.120021    0.629688     0.260469   -0.716337     0.319461    0.0253752   0.741109    -0.264862   -0.0866143   0.228597    -0.121211     0.0322536   -0.133543    -0.222033    -0.794989    -0.0039811   -0.0659342   -0.0293364   0.486932    0.690133
  0.0507019    0.0878626   0.326692    -0.242459   -0.0125944   -0.053389      0.274759    0.363275    -0.0335945  -0.443683     0.15439    -0.348245   -0.365576    -0.289436   -0.848849    0.0548976    0.781964    -0.0246649   -0.354789    -0.117032     0.093067     0.00342597   0.0900673    0.518794    0.364656   -0.13824
 -0.015638    -0.350054   -0.177975    -0.480185   -0.147108    -0.146484      0.428106   -0.173835    -0.0744688   0.0536874   -0.139008   -0.619591   -0.140294     0.496359   -0.0918291  -0.126501    -0.106721     0.388276     0.398437    -0.397281    -0.642568     0.584875     0.739841     0.305677   -0.0893141  -0.301343
 -0.498802     0.444029    0.069994    -0.0782922  -0.204655     0.184692      0.0588715  -0.37505      0.267849   -0.194121    -0.0790285  -0.904887    0.320067    -0.387234    0.521451    0.275634    -0.505247    -0.0527083    0.161014     0.118379    -0.00110764   0.703287    -0.00651261  -0.221801    0.178385   -0.258984
  0.161976    -0.0456138   0.718415     0.180213   -0.801058     0.038575      0.185867   -0.733519     0.827577   -0.702195    -0.132893    0.264429   -0.663329     0.264778    0.375426   -0.0671664    0.478986     0.753333     0.507048    -0.290567     0.0111938   -0.0875838   -0.503465     0.231106   -0.223321   -0.313744
 -0.174607     0.482034    0.581799     0.012535    0.779327    -0.525124     -0.25403    -0.241499     0.367957   -0.105218    -0.395546    0.428785    0.435229     0.0467556   0.403613    0.0953927    0.413305    -0.442367     0.00391653  -0.545421     0.66352      0.295237    -0.362156    -0.248851   -0.230104   -0.322533
  0.578542     0.342546    0.0424064    0.596397   -0.0900837    0.40392      -0.0820551  -0.0339973   -0.210434    0.201601     0.407544    0.587143   -0.397321     0.0658881   0.235168    0.177071     0.296053    -0.134876    -0.179923     0.13794      0.582643    -0.696731    -0.477307     0.332614   -0.609933    0.125769
  0.627157    -0.727859   -0.46483     -0.222328    0.259861    -0.00332382   -0.430262    0.145007    -0.295063   -0.0801183   -0.0910038   0.380806    0.110143    -0.0846161  -0.155667   -0.0781553    0.109835     0.157679    -0.188705    -0.318239     0.110823    -0.562061    -0.254131     0.2101     -0.115252    0.26259
 -0.0560822    0.281466   -0.0673996   -0.15814     0.226958    -0.256267      0.545444   -0.30664     -0.297468    0.103867    -0.525182   -0.436115    0.326618     0.195137    0.380967   -0.572516     0.102588    -0.0105987    0.0904868   -0.0369468    0.200842    -0.56307      0.0219515    0.942162   -0.379284   -0.376541
  0.0170589    0.0494091   0.161971    -0.165243    0.0407639    0.458836     -0.556159    0.468106     0.216907    0.10567     -0.0163943  -0.0486824  -0.101381     0.470296   -0.703296    0.763792     0.251887    -0.231045     0.016385     0.190809     0.0454261    0.890416     0.105878    -0.261434    0.31226    -0.0458704
 -0.278353    -0.267923    0.439105    -0.209446    0.0206916    0.321957     -0.0326927  -0.123268     0.12468     0.947398    -0.34801     0.483378   -0.564079     0.5141      0.0403354  -0.177209     0.380337    -0.07244     -0.376035     0.231773     0.0996128   -0.0661861    0.247483     0.153378   -0.0352229  -1.10034
 -0.0642443    0.0370207   0.0545476    0.0611976   0.00502405  -0.0679923     0.0546853   0.00531212   0.217935   -0.181559    -0.132396    0.258809    0.0984965    0.099029    0.383921   -0.205532     0.158671     0.100174    -0.00683523  -0.160329    -0.142713     0.123884     0.0140171   -0.089732   -0.17504     0.0600549
  0.123353    -0.0425753  -0.183954     0.0368206   0.225547    -0.120151     -0.249138    0.103971    -0.0446399  -0.0155436    0.239681   -0.0112988   0.0316189   -0.0813413  -0.268223    0.16547     -0.191199    -0.0422053   -0.193342    -0.0450288    0.00537536   0.00327014  -0.0257899   -0.127048    0.348682    0.0473524
 -0.177062    -0.0716008   0.0758573   -0.344143    0.498142     0.768565     -0.0971733  -0.0285911   -0.0167998  -0.432167     0.626235   -0.0154711   0.753798     0.250759   -0.335896   -0.471887    -0.265544    -0.259323     0.623564     0.381102     0.172126    -0.45777      0.607679    -0.387152   -0.40539    -0.18309
 -0.308774     0.33113    -0.00318734   0.577592   -0.262087     0.168425     -0.493615    0.333524     0.248642   -0.0967445    0.0362092   0.543611   -0.124986    -0.659436   -0.280121   -0.0970108    0.0511276    0.0894825   -0.676671     0.33123      0.417786    -0.248982    -0.789197    -0.521724    0.153184    0.145229
  0.0495544   -0.0444788  -0.60568      0.0461054   0.33872     -0.163212     -0.12495     0.440033    -0.433779    0.930601     0.437862    0.271238    0.189575     0.194811   -0.185279    0.0922332   -0.37487     -0.625363    -0.595659     0.365052    -0.247042    -0.179834     0.397881    -0.364987    0.225418    0.531158
 -0.12374      0.453402   -0.191819    -0.0265539  -0.0597483    0.193702      0.0341083   0.711181     0.172255   -0.162539    -0.924721    0.563888   -0.278336    -0.397331    0.226135   -0.234435     0.241741     0.313586     0.182005     0.159617     0.0310558    0.0988491    0.010384     0.0056417  -0.978241    0.439554
 -0.348306     0.069447    0.550683    -0.0931527  -0.592121     0.582319      0.555905    0.629596     0.139885    0.0472955    0.417847    0.123659   -0.0244711   -0.620005   -0.0438551  -0.0196246   -0.00234092  -0.199795     0.21564      0.23973      0.343032     0.423856     0.523511    -0.49323    -0.114208    0.364266
  0.335168     0.0262858   0.387664     0.0927949  -0.19402      0.190164     -0.215431   -0.519558     0.33227     0.189755     0.248177    0.162975    0.145899     0.0578968   0.661508   -0.493514    -0.570776     0.443704     0.409326     0.644472    -0.0426912   -0.135264    -0.0804095   -0.412521   -0.12122    -0.409609
 -0.295282     0.0826376  -0.0547513    0.0683376  -0.0635891    0.0321092     0.636322    0.330969     0.131399    0.308292     0.176078    0.183492   -0.170002     0.477779   -0.15157     0.168087    -0.0699743    0.0714982   -0.00366798   0.163837    -0.247883    -0.164387     0.472548     0.0727708   0.138136   -0.296668
 -0.0213877    0.0634018  -0.0161576    0.0617669   0.0404804   -0.000530309   0.0473042   0.0148969    0.0112791  -0.0336315    0.0381726   0.154404    0.0892742    0.0153644   0.146986    0.0418922   -0.0235461   -0.00335777  -0.00922135   0.0218671    0.0646001   -0.0623016   -0.0209761    0.0434982  -0.109473    0.0203933
 -0.0322258   -0.0838318   0.124585    -0.199347   -0.110455     0.167454     -0.0979135  -0.112502    -0.217405    0.140393    -0.180527   -0.304588   -0.00381763   0.0897073  -0.152526    0.0314651   -0.0178056   -0.0781636    0.333952     0.173208     0.169676     0.115267    -0.0734191    0.292297   -0.0670787  -0.196103
  0.859809     0.353135   -0.173607    -1.01074     0.412675     0.378005     -0.163116   -0.102976    -0.171114    0.393364    -0.199707   -0.129787   -0.457215    -0.0952052  -0.882703   -0.120058    -0.39819      0.309703     0.487648    -0.0302768    0.208904     0.0331137   -0.291976     0.379565    0.0733333  -0.60997
  0.115596    -0.213163    0.0480262    0.149081   -0.493475    -0.603866      0.0475218  -0.58157     -0.346383   -0.0150716    0.315486   -0.19042    -0.457688    -0.358753    0.471871   -0.00186918  -0.480991     0.255298    -0.0878442   -0.306074     0.221912    -0.0474413   -0.10113     -0.240263   -0.0212316   0.104862
 -0.605161     0.810028   -0.51975      0.314595    0.653241    -0.0312818     0.342982   -0.332515    -0.232632   -0.22899      0.459796   -0.152685    0.0322449   -0.278812   -0.153956    0.111836     0.164838    -0.0267779    0.0893108   -0.144423     0.503751     0.105269     0.10054     -0.0169648   0.129906    0.155743
  0.380514     0.166632   -0.331769     0.105943    0.378931     0.3155       -0.338786    0.219422     0.148668   -0.19443     -0.146226    1.11602     0.16069      1.0111      0.129441   -0.470737     0.548243     0.0658098    0.401185    -0.0328055   -0.359778     0.282192     0.0440546   -0.0493627  -0.181287   -0.147713
 -0.121668    -0.516897   -0.0891382   -0.119807   -0.123036     0.678373     -0.365884   -0.516315    -0.128415   -0.0756942    0.59499    -0.41928    -0.288182    -0.458427   -0.421939   -0.738339     0.108577     0.761669     0.428912     0.460856    -0.275679     0.0922124    0.32415      0.21472     0.336975   -0.328561
  0.0816826   -0.336007   -0.162408    -0.112802   -0.584455    -0.212039      0.135082    0.249037     0.408873    0.154006    -0.486097   -0.109312    0.102231     0.0663836   0.211478    0.250394    -0.204649    -0.514416    -0.782235    -0.293229     0.223294     0.0119078   -0.387486    -0.154955   -0.0891374   0.0758489
 -0.435009    -0.29648     0.0976994    0.293672   -0.275898    -0.440839      0.448308    0.0614766   -0.362611    0.153332    -0.249385   -0.0626726   0.912251     0.164764    1.07203    -0.356041     0.0116591   -0.293017     [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
0.140926    -0.63163     -0.289797     0.312291    -0.00630852  -0.2897     -0.424965    0.341853
 -0.125467    -0.372802   -0.101548    -0.0816117  -0.41383     -0.353209      0.116446    0.0275279   -0.286445    0.00557139   0.021693   -1.02956     0.0465017   -0.6469     -0.401696    0.558542    -0.443728    -0.0799875   -0.421331    -0.00633028   0.320021    -0.207664    -0.135513     0.110573    0.536383   -0.0427608
  0.156441    -0.221518    0.221031    -0.0671528   0.758733    -0.433433      0.0837915  -0.6769       0.222239   -0.40454      0.417358   -0.272107    0.477478     0.357868    0.415918    0.509758    -0.252736    -0.0956033    0.25449     -0.0951106   -0.718492     0.0914202    0.537312     0.427382    0.534597   -0.0196502[ Info: iteration 1, average log likelihood -1.400620
[ Info: iteration 2, average log likelihood -1.400612
[ Info: iteration 3, average log likelihood -1.400605
[ Info: iteration 4, average log likelihood -1.400599
[ Info: iteration 5, average log likelihood -1.400592
[ Info: iteration 6, average log likelihood -1.400586
[ Info: iteration 7, average log likelihood -1.400579
[ Info: iteration 8, average log likelihood -1.400573
[ Info: iteration 9, average log likelihood -1.400568
[ Info: iteration 10, average log likelihood -1.400562
┌ Info: EM with 100000 data points 10 iterations avll -1.400562
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
