 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed LegacyStrings ────── v0.4.1
 Installed Blosc ────────────── v0.5.1
 Installed BinDeps ──────────── v0.8.10
 Installed Arpack ───────────── v0.3.1
 Installed SpecialFunctions ─── v0.8.0
 Installed BinaryProvider ───── v0.5.8
 Installed DataStructures ───── v0.17.6
 Installed DataAPI ──────────── v1.1.0
 Installed URIParser ────────── v0.4.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed PDMats ───────────── v0.9.10
 Installed Distances ────────── v0.8.2
 Installed HDF5 ─────────────── v0.12.5
 Installed StaticArrays ─────── v0.12.1
 Installed Distributions ────── v0.21.8
 Installed SortingAlgorithms ── v0.3.1
 Installed JLD ──────────────── v0.9.1
 Installed Missings ─────────── v0.4.3
 Installed StatsBase ────────── v0.32.0
 Installed FileIO ───────────── v1.0.7
 Installed OrderedCollections ─ v1.1.0
 Installed NearestNeighbors ─── v0.4.3
 Installed Rmath ────────────── v0.5.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed CMake ────────────── v1.1.2
 Installed StatsFuns ────────── v0.9.0
 Installed QuadGK ───────────── v2.1.1
 Installed Parameters ───────── v0.12.0
 Installed Clustering ───────── v0.13.3
 Installed Compat ───────────── v2.2.0
  Updating `~/.julia/environments/v1.0/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.0/Manifest.toml`
  [7d9fca2a] + Arpack v0.3.1
  [9e28174c] + BinDeps v0.8.10
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.8
  [5789e2e9] + FileIO v1.0.7
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.3
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.1.1
  [79098fc4] + Rmath v0.5.1
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.8.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.0
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Arpack ──────────→ `~/.julia/packages/Arpack/cu5By/deps/build.log`
  Building CMake ───────────→ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc ───────────→ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building SpecialFunctions → `~/.julia/packages/SpecialFunctions/ne2iw/deps/build.log`
  Building HDF5 ────────────→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Building Rmath ───────────→ `~/.julia/packages/Rmath/4wt82/deps/build.log`
   Testing GaussianMixtures
    Status `/tmp/tmpa0SLbh/Manifest.toml`
  [7d9fca2a] Arpack v0.3.1
  [9e28174c] BinDeps v0.8.10
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.8
  [5789e2e9] FileIO v1.0.7
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.3
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.1.1
  [79098fc4] Rmath v0.5.1
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.8.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.0
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -1.946852905862491e7, [75114.6, 24885.4], [12806.0 -4479.47 28305.1; -13293.5 4373.38 -28623.5], Array{Float64,2}[[71824.8 1278.23 -7992.24; 1278.23 74680.5 2381.81; -7992.24 2381.81 57845.9], [28565.3 -1267.14 8134.49; -1267.14 25197.8 -2591.57; 8134.49 -2591.57 42502.9]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.0/Distributed/src/cluster.jl:932
[ Info: Initializing GMM, 8 Gaussians LinearAlgebra.diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.371584e+03
      1       1.114086e+03      -2.574984e+02 |        7
      2       1.071514e+03      -4.257160e+01 |        4
      3       1.028673e+03      -4.284113e+01 |        4
      4       9.717730e+02      -5.690031e+01 |        0
      5       9.717730e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 971.7730182956766)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.070196
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:582 [inlined]
└ @ Core ./broadcast.jl:582
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:582 [inlined]
└ @ Core ./broadcast.jl:582
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:582 [inlined]
└ @ Core ./broadcast.jl:582
[ Info: iteration 1, lowerbound -3.858629
[ Info: iteration 2, lowerbound -3.758382
[ Info: iteration 3, lowerbound -3.656562
[ Info: iteration 4, lowerbound -3.534972
[ Info: iteration 5, lowerbound -3.402960
[ Info: iteration 6, lowerbound -3.281427
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -3.171704
[ Info: iteration 8, lowerbound -3.065315
[ Info: iteration 9, lowerbound -2.978923
[ Info: iteration 10, lowerbound -2.913565
[ Info: dropping number of Gaussions to 5
[ Info: iteration 11, lowerbound -2.861031
[ Info: dropping number of Gaussions to 4
[ Info: iteration 12, lowerbound -2.817605
[ Info: iteration 13, lowerbound -2.796878
[ Info: dropping number of Gaussions to 3
[ Info: iteration 14, lowerbound -2.788687
[ Info: iteration 15, lowerbound -2.779531
[ Info: iteration 16, lowerbound -2.771293
[ Info: iteration 17, lowerbound -2.758434
[ Info: iteration 18, lowerbound -2.738408
[ Info: iteration 19, lowerbound -2.707956
[ Info: iteration 20, lowerbound -2.663954
[ Info: iteration 21, lowerbound -2.605653
[ Info: iteration 22, lowerbound -2.537735
[ Info: iteration 23, lowerbound -2.470429
[ Info: iteration 24, lowerbound -2.413427
[ Info: iteration 25, lowerbound -2.369692
[ Info: iteration 26, lowerbound -2.337342
[ Info: iteration 27, lowerbound -2.315777
[ Info: iteration 28, lowerbound -2.307451
[ Info: dropping number of Gaussions to 2
[ Info: iteration 29, lowerbound -2.302964
[ Info: iteration 30, lowerbound -2.299262
[ Info: iteration 31, lowerbound -2.299257
[ Info: iteration 32, lowerbound -2.299255
[ Info: iteration 33, lowerbound -2.299254
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Sat Nov 23 19:54:55 2019: Initializing GMM, 8 Gaussians LinearAlgebra.diag covariance 2 dimensions using 272 data points
, Sat Nov 23 19:55:02 2019: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Sat Nov 23 19:55:04 2019: EM with 272 data points 0 iterations avll -2.070196
5.8 data points per parameter
, Sat Nov 23 19:55:06 2019: GMM converted to Variational GMM
, Sat Nov 23 19:55:15 2019: iteration 1, lowerbound -3.858629
, Sat Nov 23 19:55:15 2019: iteration 2, lowerbound -3.758382
, Sat Nov 23 19:55:15 2019: iteration 3, lowerbound -3.656562
, Sat Nov 23 19:55:15 2019: iteration 4, lowerbound -3.534972
, Sat Nov 23 19:55:15 2019: iteration 5, lowerbound -3.402960
, Sat Nov 23 19:55:15 2019: iteration 6, lowerbound -3.281427
, Sat Nov 23 19:55:16 2019: dropping number of Gaussions to 6
, Sat Nov 23 19:55:16 2019: iteration 7, lowerbound -3.171704
, Sat Nov 23 19:55:16 2019: iteration 8, lowerbound -3.065315
, Sat Nov 23 19:55:16 2019: iteration 9, lowerbound -2.978923
, Sat Nov 23 19:55:16 2019: iteration 10, lowerbound -2.913565
, Sat Nov 23 19:55:16 2019: dropping number of Gaussions to 5
, Sat Nov 23 19:55:16 2019: iteration 11, lowerbound -2.861031
, Sat Nov 23 19:55:16 2019: dropping number of Gaussions to 4
, Sat Nov 23 19:55:16 2019: iteration 12, lowerbound -2.817605
, Sat Nov 23 19:55:16 2019: iteration 13, lowerbound -2.796878
, Sat Nov 23 19:55:16 2019: dropping number of Gaussions to 3
, Sat Nov 23 19:55:16 2019: iteration 14, lowerbound -2.788687
, Sat Nov 23 19:55:16 2019: iteration 15, lowerbound -2.779531
, Sat Nov 23 19:55:16 2019: iteration 16, lowerbound -2.771293
, Sat Nov 23 19:55:16 2019: iteration 17, lowerbound -2.758434
, Sat Nov 23 19:55:16 2019: iteration 18, lowerbound -2.738408
, Sat Nov 23 19:55:16 2019: iteration 19, lowerbound -2.707956
, Sat Nov 23 19:55:16 2019: iteration 20, lowerbound -2.663954
, Sat Nov 23 19:55:16 2019: iteration 21, lowerbound -2.605653
, Sat Nov 23 19:55:16 2019: iteration 22, lowerbound -2.537735
, Sat Nov 23 19:55:16 2019: iteration 23, lowerbound -2.470429
, Sat Nov 23 19:55:16 2019: iteration 24, lowerbound -2.413427
, Sat Nov 23 19:55:16 2019: iteration 25, lowerbound -2.369692
, Sat Nov 23 19:55:16 2019: iteration 26, lowerbound -2.337342
, Sat Nov 23 19:55:16 2019: iteration 27, lowerbound -2.315777
, Sat Nov 23 19:55:16 2019: iteration 28, lowerbound -2.307451
, Sat Nov 23 19:55:16 2019: dropping number of Gaussions to 2
, Sat Nov 23 19:55:16 2019: iteration 29, lowerbound -2.302964
, Sat Nov 23 19:55:16 2019: iteration 30, lowerbound -2.299262
, Sat Nov 23 19:55:16 2019: iteration 31, lowerbound -2.299257
, Sat Nov 23 19:55:16 2019: iteration 32, lowerbound -2.299255
, Sat Nov 23 19:55:16 2019: iteration 33, lowerbound -2.299254
, Sat Nov 23 19:55:16 2019: iteration 34, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: iteration 35, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: iteration 36, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: iteration 37, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: iteration 38, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: iteration 39, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: iteration 40, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: iteration 41, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: iteration 42, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: iteration 43, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: iteration 44, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: iteration 45, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: iteration 46, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: iteration 47, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: iteration 48, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: iteration 49, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: iteration 50, lowerbound -2.299253
, Sat Nov 23 19:55:16 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.9549, 178.045]
β = [95.9549, 178.045]
m = [2.00023 53.852; 4.2503 79.2869]
ν = [97.9549, 180.045]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.375876 -0.00895312; 0.0 0.0127487], [0.184042 -0.00764405; 0.0 0.00858171]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9916278690941359
avll from llpg:  -0.9916278690941364
avll direct:     -0.9916278690941364
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9867088309206853
avll from llpg:  -0.9867088309206853
avll direct:     -0.9867088309206853
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.048693     0.186746     0.0988134    0.200585      0.0216456    0.0461786    0.0328706    0.160656     0.0192066    0.0251619    0.0513792     0.108305    -0.093561      0.110163     0.0804151   0.0278864   -0.155489     0.00181861   0.0892984   -0.0104739    0.0793037   -0.0613534    0.0172228   -0.0452041   -0.0668471    0.0602885 
  0.0878262    0.0613516    0.0935727    0.103139      0.0535115   -0.105491     0.00080434   0.0235253    0.125332    -0.101959    -0.0304149    -0.0823408   -0.110695      0.0168105    0.121218   -0.0549859    0.192962    -0.0377879   -0.0486241    0.163849    -0.0866308   -0.0133731    0.0427117    0.088522     0.0206138    0.0479038 
  0.0127178    0.0206538    0.193082    -0.0541816     0.179788    -0.0214977    0.0257732    0.0628038    0.0373012    0.00270238   0.0416249    -0.0752069   -0.26496      -0.0858564    0.0457309  -0.244629     0.108536    -0.0320279    0.0759333    0.0185032   -0.0338462    0.0227196    0.0539096   -0.0992045    0.108674    -0.0610104 
  0.107539    -0.121909    -0.123883     0.183992      0.149081     0.0901466   -0.0964101   -0.0213753    0.12271     -0.0104608   -0.0308564     0.00736474   0.0489577     0.0379605   -0.111723   -0.0514762    0.00570332  -0.0600061    0.0434111    0.049714     0.0450052    0.0560051   -0.0134004    0.0369792   -0.149087     0.0762568 
  0.0965566   -0.0220113    0.0820686   -0.0952926    -0.0482607   -0.0396224   -0.10672     -0.0703866    0.129299     0.0710165    0.0200158     0.0823668    0.0666144    -0.0680391   -0.162127   -0.0527931   -0.00293873   0.030541     0.0494105   -0.126379    -0.0631143   -0.10405     -0.0714655   -0.0239234   -0.0403615   -0.0186756 
  0.099916     0.192444    -0.0868753   -0.0847525     0.126167    -0.0273675    0.0795677   -0.0413885   -0.00806916   0.0579988    0.0340315    -0.0023632    0.0980399    -0.153929    -0.194141   -0.139765    -0.130682     0.135572     0.00380575   0.15613      0.115347     0.014626     0.0582455    0.0654242    0.0143367    0.136676  
  0.100418     0.0087446   -0.155674     0.0664594    -0.0187629   -0.00011118   0.0372944   -0.202752     0.116686    -0.117876     0.0140351    -0.0809387    0.0597165    -0.149198     0.11749    -0.129378    -0.0643587   -0.063109     0.0365426   -0.00127775   0.0794904    0.134578    -0.152415    -0.0213521    0.108365     0.0372755 
  0.0679875    0.145995     0.0534171    0.00911499    0.0962684   -0.109895    -0.0554386    0.0843731   -0.00307629   0.0619708    0.144478      0.0433041   -0.085796      0.124156     0.0124412  -0.116254     0.135747     0.0976739   -0.119851     0.220074    -0.0117631   -0.0317896   -0.194772     0.0203473   -0.176109    -0.129918  
  0.242827    -0.0655977   -0.193313     0.0408512     0.0738864   -0.00936154   0.0822375    0.179616    -0.0736241   -0.0375105   -0.0247313     0.0117582    0.0187774    -0.103842     0.128105   -0.0509751   -0.0679616   -0.259737     0.247449     0.185769     0.19254     -0.0155489   -0.00927386   0.0826546   -0.0892143   -0.134925  
 -0.0955144   -0.234153     0.0907507   -0.301102      0.0222655    0.0884255    0.0895742   -0.00605817   0.243841     0.090311     0.0638714     0.0834766   -0.0229682    -0.031539    -0.0465638  -0.0546356   -0.173363    -0.0254795   -0.160736     0.120576    -0.021484    -0.0294498    0.0467716    0.0192881   -0.0265807    0.0223567 
 -0.0264299   -0.128294    -0.201486    -0.124691     -0.071998    -0.0171522    0.0575338   -0.177966     0.0221706    0.118588    -0.0290245    -0.0261832   -0.0704934     0.137671    -0.0894213   0.0106759    0.0301858    0.0203576   -0.09527      0.103202    -0.00351119   0.0129755    0.0938199   -0.0628466    0.150794    -0.0661523 
  0.0837653   -0.00683584   0.236665     0.00748199    0.0354765    0.0835528    0.0423351   -0.151858     0.00255285  -0.0175707    0.0866621     0.03035      0.178898     -0.0966174    0.0400298  -0.0796592    0.019932     0.209064    -0.0222805    0.0860222    0.105565     0.0301858   -0.0661139    0.13605      0.0401694   -0.0394829 
  0.162922    -0.0010023   -0.037662    -0.0910314    -0.0240015   -0.156261     0.0960466    0.243248     0.00547415   0.0201065    0.0594338    -0.130992     0.104661      0.0456186   -0.142844    0.00338098   0.0440145   -0.0818451   -0.0181128    0.119621    -0.178605     0.0811492    0.150505     0.115377     0.06984     -0.106646  
  0.146456    -0.107037     0.141487     0.000679392   0.193187    -0.0718992    0.0130163    0.0847552    0.0685869   -0.102053     0.0668039    -0.122086    -0.0389274    -0.0024026   -0.183998    0.00185522  -0.0158295   -0.0751747    0.0879075    0.131118     0.113456     0.00125782  -0.190454    -0.0850188    0.0770591    0.0827684 
  0.101917     0.0597322   -0.20524     -0.00650136   -0.100665    -0.157285     0.0307854   -0.122472     0.00864314  -0.0474037   -0.0665147     0.0977601   -0.107071      0.172745     0.107281    0.0231465    0.0667219    0.196103     0.125418     0.00143604   0.113739     0.0742398   -0.00448003   0.0187135   -0.135485    -0.0696866 
 -0.0499259    0.0997497   -0.040864     0.0128762     0.0906912   -0.0202556   -0.0208409    0.0770991   -0.106098    -0.0117231   -0.0804294    -0.0433051   -0.00965736   -0.00946759   0.044008    0.0669656    0.0114332    0.0990318    0.128601    -0.144791     0.0159275   -0.0512263   -0.0594804    0.0519659    0.0277682   -0.136622  
 -0.0808396   -0.017864    -0.0526892   -0.0613854     0.0498533    0.0194058    0.00700274   0.235834     0.107711    -0.200315    -0.0310642     0.00513353  -0.115411      0.0454186    0.102236   -0.0074463   -0.0501503    0.00310689  -0.0140375   -0.0397284   -0.0930522   -0.068218     0.0609472    0.12952     -0.0941705    0.155025  
  0.0356971   -0.0662592    0.044282    -0.0270704    -0.0979272    0.129079     0.00762225  -0.137411     0.0248741    0.00821991  -0.215543     -0.100015    -0.0257432    -0.137909     0.0496249   0.107256     0.173042     0.0922128    0.0390916   -0.0239895    0.164615    -0.0818766    0.148685     0.0760131   -0.0488568   -0.120265  
 -0.0562018   -0.0262775    0.140416     0.134217      0.0530665    0.0923456    0.0151168   -0.0224252    0.0163356    0.16437      0.114599      0.0114989    0.0128335     0.0587477   -0.159242   -0.00636347  -0.114888    -0.0988249    0.106822    -0.0518297    0.0592939   -0.121143    -0.0839652   -0.176352    -0.269871     0.0882975 
 -0.0930346   -0.0666634   -0.058211    -0.0119996    -0.107902     0.0148273   -0.21507      0.00962547  -0.163486    -0.058401    -0.0956678    -0.0230138   -0.0371997     0.158224    -0.122115    0.116503    -0.0648922   -0.0638103   -0.266255    -0.0566135   -0.0872444    0.259392    -0.186409    -0.0152339   -0.00100696  -0.0124093 
 -0.0876047   -0.0409934   -0.169002    -0.0229837     0.0951768    0.0244054   -0.0678496    0.00215001   0.0746942    0.0338847    0.000496746   0.069205    -0.0113653    -0.0451063    0.128907   -0.111419     0.120285     0.0320913    0.132336    -0.236457     0.123802    -0.0393579   -0.0136195   -0.106719     0.263089     0.0297131 
  0.00183002   0.158965    -0.00319227   0.0282549    -0.0487922    0.107419    -0.0913741    0.0503685    0.00522158   0.00591003   0.096693      0.0641843    0.000353991   0.0151297    0.0857568   0.0611403   -0.167134     0.0312118    0.0461671    0.0164238    0.19874      0.0678518    0.0962948   -0.0310543   -0.0481042   -0.0708989 
  0.0766103    0.109115    -0.0341083    0.0520233    -0.0896715    0.0610523   -0.152104    -0.124271     0.126113     0.126        0.0233974     0.0498603   -0.0807364    -0.057851    -0.0139269   0.13076      0.0788188   -0.239891    -0.0137706   -0.0591346   -0.0806416   -0.0333381   -0.136161     0.0274749   -0.0741079    0.00919945
  0.120478     0.149471     0.0362894   -0.0796469    -0.126926     0.0621026   -0.0362275    0.10219      0.032788     0.140416    -0.161331      3.99935e-5   0.0353229     0.05282     -0.103156    0.131118    -0.0676907    0.0233639   -0.0415673    0.0542111    0.0425684    0.0101466    0.170549    -0.0320933    0.0653796   -0.166127  
 -0.117531    -0.0027291    0.0779525    0.115171     -0.0663013    0.100944    -0.10325      0.0110204   -0.0697267    0.0137529   -0.0334934     0.121176    -0.0121764     0.0418027   -0.126607   -0.0302938    0.0551419   -0.0056529   -0.103182    -0.125908    -0.191159     0.0681754    0.0471684    0.0147571    0.0513219    0.128733  
  0.133858    -0.0129189    0.107279     0.0484586    -0.0449086   -0.110109    -0.203434     0.0810419   -0.0146096    0.0304098   -0.108048     -0.0841663   -0.0449172     0.158526    -0.054551   -0.237655     0.0933758    0.0278207   -0.0237578    0.157699     0.0293697   -0.108353    -0.116485     0.091838     0.066932     0.127407  
 -0.155093     0.0148596   -0.0762878   -0.117173      0.0945261    0.0333388    0.170293     0.0264181   -0.150729    -0.0470993    0.103186      0.110917     0.0746201     0.16334     -0.129213   -0.0404192    0.109652    -0.0727405    0.146406    -0.0642087   -0.0922647   -0.0719618   -0.0102185    0.201759    -0.112651     0.0272841 
 -0.110551     0.167219    -0.0408842   -0.0878025    -0.0400573   -0.0762354   -0.0128202    0.0212937   -0.128439    -0.0125812   -0.112617     -0.0182166    0.0613693    -0.02692      0.267      -0.0420107    0.0107603   -0.0674438   -0.0493928    0.110842     0.0693951   -0.00965112   0.0448135   -0.00077227   0.0500803   -0.0494926 
 -0.218987    -0.0313508   -0.013602     0.314743      0.11189      0.205347     0.0176986   -0.0463378    0.0460432    0.126169     0.00550211    0.0683502    0.16255       0.0163575    0.115862   -0.148045    -0.230011    -0.170527     0.0473361   -0.108391     0.178132     0.0955082   -0.0462501   -0.159154     0.00508133   0.0841505 
  0.0198616    0.0300303    0.00101149  -0.0336668    -0.0563821   -0.0899013    0.0726927    0.0413668    0.0347516    0.0237678    0.176659     -0.0447916   -0.0839414    -0.109781    -0.0884866   0.0949322    0.0480725    0.0104314   -0.126024     0.0566811    0.0236233   -0.0275934    0.123116     0.235305    -0.00408422   0.00135197
 -0.0262711    0.0341453   -0.164926     0.0582256     0.0237063   -0.0338694    0.00346878   0.0446157    0.0211939    0.0159922    0.240528     -0.16689      0.121574     -0.00808985   0.121765    0.00363647   0.0946843   -0.0959134   -0.0424399    0.00700644   0.0350449   -0.0523579   -0.0643446    0.106723    -0.0146202   -0.0660931 
  0.244003     0.107278     0.0303762    0.0650433    -0.00175169   0.127515     0.00246889   0.0282045    0.166932     0.0266967   -0.112954      0.246673    -0.0775601     0.0562277   -0.028513    0.0911258   -0.0978698   -0.0416917    0.136508    -0.217658    -0.0826166   -0.0682484    0.185687     0.0484095   -0.00944128   0.0459102 kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3881295283631823
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.388189
[ Info: iteration 2, average log likelihood -1.388127
[ Info: iteration 3, average log likelihood -1.387787
[ Info: iteration 4, average log likelihood -1.384074
[ Info: iteration 5, average log likelihood -1.372222
[ Info: iteration 6, average log likelihood -1.364795
[ Info: iteration 7, average log likelihood -1.362799
[ Info: iteration 8, average log likelihood -1.361656
[ Info: iteration 9, average log likelihood -1.360732
[ Info: iteration 10, average log likelihood -1.359595
[ Info: iteration 11, average log likelihood -1.357432
[ Info: iteration 12, average log likelihood -1.354696
[ Info: iteration 13, average log likelihood -1.353048
[ Info: iteration 14, average log likelihood -1.352110
[ Info: iteration 15, average log likelihood -1.351545
[ Info: iteration 16, average log likelihood -1.351210
[ Info: iteration 17, average log likelihood -1.351004
[ Info: iteration 18, average log likelihood -1.350861
[ Info: iteration 19, average log likelihood -1.350751
[ Info: iteration 20, average log likelihood -1.350661
[ Info: iteration 21, average log likelihood -1.350587
[ Info: iteration 22, average log likelihood -1.350525
[ Info: iteration 23, average log likelihood -1.350471
[ Info: iteration 24, average log likelihood -1.350421
[ Info: iteration 25, average log likelihood -1.350377
[ Info: iteration 26, average log likelihood -1.350339
[ Info: iteration 27, average log likelihood -1.350309
[ Info: iteration 28, average log likelihood -1.350286
[ Info: iteration 29, average log likelihood -1.350272
[ Info: iteration 30, average log likelihood -1.350264
[ Info: iteration 31, average log likelihood -1.350259
[ Info: iteration 32, average log likelihood -1.350256
[ Info: iteration 33, average log likelihood -1.350254
[ Info: iteration 34, average log likelihood -1.350253
[ Info: iteration 35, average log likelihood -1.350252
[ Info: iteration 36, average log likelihood -1.350252
[ Info: iteration 37, average log likelihood -1.350251
[ Info: iteration 38, average log likelihood -1.350251
[ Info: iteration 39, average log likelihood -1.350251
[ Info: iteration 40, average log likelihood -1.350251
[ Info: iteration 41, average log likelihood -1.350251
[ Info: iteration 42, average log likelihood -1.350251
[ Info: iteration 43, average log likelihood -1.350251
[ Info: iteration 44, average log likelihood -1.350251
[ Info: iteration 45, average log likelihood -1.350251
[ Info: iteration 46, average log likelihood -1.350251
[ Info: iteration 47, average log likelihood -1.350251
[ Info: iteration 48, average log likelihood -1.350251
[ Info: iteration 49, average log likelihood -1.350251
[ Info: iteration 50, average log likelihood -1.350251
┌ Info: EM with 100000 data points 50 iterations avll -1.350251
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.388189351381744 
│     -1.3881271429682251
│      ⋮                 
└     -1.350250909507219 
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.350364
[ Info: iteration 2, average log likelihood -1.350262
[ Info: iteration 3, average log likelihood -1.349890
[ Info: iteration 4, average log likelihood -1.346814
[ Info: iteration 5, average log likelihood -1.336471
[ Info: iteration 6, average log likelihood -1.326279
[ Info: iteration 7, average log likelihood -1.321065
[ Info: iteration 8, average log likelihood -1.318012
[ Info: iteration 9, average log likelihood -1.315630
[ Info: iteration 10, average log likelihood -1.313655
[ Info: iteration 11, average log likelihood -1.312074
[ Info: iteration 12, average log likelihood -1.310758
[ Info: iteration 13, average log likelihood -1.309636
[ Info: iteration 14, average log likelihood -1.308731
[ Info: iteration 15, average log likelihood -1.308030
[ Info: iteration 16, average log likelihood -1.307493
[ Info: iteration 17, average log likelihood -1.307111
[ Info: iteration 18, average log likelihood -1.306857
[ Info: iteration 19, average log likelihood -1.306691
[ Info: iteration 20, average log likelihood -1.306579
[ Info: iteration 21, average log likelihood -1.306501
[ Info: iteration 22, average log likelihood -1.306445
[ Info: iteration 23, average log likelihood -1.306403
[ Info: iteration 24, average log likelihood -1.306372
[ Info: iteration 25, average log likelihood -1.306347
[ Info: iteration 26, average log likelihood -1.306326
[ Info: iteration 27, average log likelihood -1.306309
[ Info: iteration 28, average log likelihood -1.306295
[ Info: iteration 29, average log likelihood -1.306282
[ Info: iteration 30, average log likelihood -1.306271
[ Info: iteration 31, average log likelihood -1.306261
[ Info: iteration 32, average log likelihood -1.306252
[ Info: iteration 33, average log likelihood -1.306244
[ Info: iteration 34, average log likelihood -1.306236
[ Info: iteration 35, average log likelihood -1.306229
[ Info: iteration 36, average log likelihood -1.306222
[ Info: iteration 37, average log likelihood -1.306216
[ Info: iteration 38, average log likelihood -1.306210
[ Info: iteration 39, average log likelihood -1.306204
[ Info: iteration 40, average log likelihood -1.306199
[ Info: iteration 41, average log likelihood -1.306194
[ Info: iteration 42, average log likelihood -1.306189
[ Info: iteration 43, average log likelihood -1.306185
[ Info: iteration 44, average log likelihood -1.306180
[ Info: iteration 45, average log likelihood -1.306176
[ Info: iteration 46, average log likelihood -1.306172
[ Info: iteration 47, average log likelihood -1.306169
[ Info: iteration 48, average log likelihood -1.306165
[ Info: iteration 49, average log likelihood -1.306161
[ Info: iteration 50, average log likelihood -1.306157
┌ Info: EM with 100000 data points 50 iterations avll -1.306157
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3503636460811985
│     -1.3502617863964785
│      ⋮                 
└     -1.3061569788895189
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.306308
[ Info: iteration 2, average log likelihood -1.306158
[ Info: iteration 3, average log likelihood -1.305719
[ Info: iteration 4, average log likelihood -1.301731
[ Info: iteration 5, average log likelihood -1.286642
[ Info: iteration 6, average log likelihood -1.270591
[ Info: iteration 7, average log likelihood -1.264604
[ Info: iteration 8, average log likelihood -1.262162
[ Info: iteration 9, average log likelihood -1.260356
[ Info: iteration 10, average log likelihood -1.258701
[ Info: iteration 11, average log likelihood -1.257069
[ Info: iteration 12, average log likelihood -1.255642
[ Info: iteration 13, average log likelihood -1.254725
[ Info: iteration 14, average log likelihood -1.254162
[ Info: iteration 15, average log likelihood -1.253647
[ Info: iteration 16, average log likelihood -1.252955
[ Info: iteration 17, average log likelihood -1.251892
[ Info: iteration 18, average log likelihood -1.250669
[ Info: iteration 19, average log likelihood -1.249766
[ Info: iteration 20, average log likelihood -1.248971
[ Info: iteration 21, average log likelihood -1.248053
[ Info: iteration 22, average log likelihood -1.246987
[ Info: iteration 23, average log likelihood -1.245926
[ Info: iteration 24, average log likelihood -1.245305
[ Info: iteration 25, average log likelihood -1.245047
[ Info: iteration 26, average log likelihood -1.244894
[ Info: iteration 27, average log likelihood -1.244778
[ Info: iteration 28, average log likelihood -1.244686
[ Info: iteration 29, average log likelihood -1.244608
[ Info: iteration 30, average log likelihood -1.244538
[ Info: iteration 31, average log likelihood -1.244473
[ Info: iteration 32, average log likelihood -1.244409
[ Info: iteration 33, average log likelihood -1.244345
[ Info: iteration 34, average log likelihood -1.244278
[ Info: iteration 35, average log likelihood -1.244208
[ Info: iteration 36, average log likelihood -1.244134
[ Info: iteration 37, average log likelihood -1.244054
[ Info: iteration 38, average log likelihood -1.243971
[ Info: iteration 39, average log likelihood -1.243888
[ Info: iteration 40, average log likelihood -1.243816
[ Info: iteration 41, average log likelihood -1.243761
[ Info: iteration 42, average log likelihood -1.243724
[ Info: iteration 43, average log likelihood -1.243699
[ Info: iteration 44, average log likelihood -1.243683
[ Info: iteration 45, average log likelihood -1.243673
[ Info: iteration 46, average log likelihood -1.243667
[ Info: iteration 47, average log likelihood -1.243664
[ Info: iteration 48, average log likelihood -1.243661
[ Info: iteration 49, average log likelihood -1.243660
[ Info: iteration 50, average log likelihood -1.243659
┌ Info: EM with 100000 data points 50 iterations avll -1.243659
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3063075395238937
│     -1.3061581872427823
│      ⋮                 
└     -1.2436587557593826
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.243847
[ Info: iteration 2, average log likelihood -1.243642
[ Info: iteration 3, average log likelihood -1.242888
[ Info: iteration 4, average log likelihood -1.232686
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.194835
[ Info: iteration 6, average log likelihood -1.182557
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.157240
[ Info: iteration 8, average log likelihood -1.181206
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.160179
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.160584
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.162050
[ Info: iteration 12, average log likelihood -1.166660
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.144329
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.170810
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.157816
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.155377
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.156536
[ Info: iteration 18, average log likelihood -1.161396
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.139755
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.167145
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.154961
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.153914
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.155971
[ Info: iteration 24, average log likelihood -1.161139
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.139592
[ Info: iteration 26, average log likelihood -1.166908
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.148860
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.157465
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.157145
[ Info: iteration 30, average log likelihood -1.161958
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.139685
[ Info: iteration 32, average log likelihood -1.166706
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.148601
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      4
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.151238
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.159997
[ Info: iteration 36, average log likelihood -1.161923
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.138657
[ Info: iteration 38, average log likelihood -1.164935
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.146575
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.149282
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.152541
[ Info: iteration 42, average log likelihood -1.158604
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.137174
[ Info: iteration 44, average log likelihood -1.164620
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.146528
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.149254
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.152538
[ Info: iteration 48, average log likelihood -1.158599
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.137166
[ Info: iteration 50, average log likelihood -1.164620
┌ Info: EM with 100000 data points 50 iterations avll -1.164620
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.24384739480293  
│     -1.2436420546311475
│      ⋮                 
└     -1.164619739819566 
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.146776
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.137013
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     21
│     22
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.144636
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     23
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.115111
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     11
│     21
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.085025
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.053361
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.074235
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.070643
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│      8
│     11
│     18
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.061959
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.063139
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.057617
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.063035
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     11
│     21
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.079426
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.048725
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.051361
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.081798
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     11
│     18
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.065554
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.055679
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.062504
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.063594
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│     11
│     21
│     22
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.067174
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│     10
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.054278
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      8
│     11
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.062710
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      7
│     11
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.064305
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      8
│     11
│     18
│     21
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.065827
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      7
│     10
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.052460
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│     11
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.055485
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      8
│     11
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.067382
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│     11
│     21
│     22
│     23
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.070349
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.047115
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.070849
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│     11
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.067944
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      8
│     11
│     18
│     21
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.055272
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.062436
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.056634
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.062253
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     11
│     21
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.079435
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.048599
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.063932
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.073699
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     11
│     18
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.061181
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.055669
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.062421
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.063546
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     11
│     21
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.072494
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.054345
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.065123
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.066807
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     11
│     18
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.066847
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     24
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.056893
┌ Info: EM with 100000 data points 50 iterations avll -1.056893
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1467759446024544
│     -1.1370128564996014
│      ⋮                 
└     -1.056892737787392 
32×26 Array{Float64,2}:
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3881295283631823
│     -1.388189351381744 
│     -1.3881271429682251
│     -1.3877869701913343
│      ⋮                 
│     -1.0668070740481594
│     -1.066847170066357 
└     -1.056892737787392 
  0.164271    -0.00217273  -0.0470836    -0.0875273   -0.0198937   -0.151989     0.0890534    0.205701     0.00176484    0.0236011     0.0606491   -0.127702      0.103047      0.0519955   -0.145655     0.00267426   0.046684   -0.0974009  -0.0284963    0.11993     -0.169751     0.109918     0.151456    0.117805      0.0466175   -0.106229  
  0.0293548    0.0281487    0.192475     -0.0718471    0.16037     -0.0227561    0.0269263    0.0703363    0.0346584     0.0061993     0.046528    -0.0713214    -0.245939     -0.0886919    0.0511628   -0.246649     0.117217   -0.0338022   0.0768632    0.0196098   -0.035502     0.0220404    0.0378458  -0.10039       0.112127    -0.0839882 
 -0.221682    -0.0441564   -0.245942      0.0818001    0.0643442    0.0235111   -0.130789    -0.0979242    0.0900224     0.0223796    -0.0308715    0.0640131    -0.0421585    -0.0327608    0.114441    -0.117101     0.149427   -0.0401973   0.0683691   -0.221629     0.18205     -0.673096    -0.0585357  -0.038132      0.305341     0.0571348 
  0.0198496   -0.0404453   -0.142881     -0.130136     0.0893661    0.023679     0.0199041    0.134793     0.0678725     0.0510673     0.016995     0.073841      0.034278     -0.0552616    0.115659    -0.110724     0.0828793   0.146341    0.193251    -0.248892     0.0554651    0.59742      0.0472035  -0.11587       0.197544    -0.014937  
 -0.00923364   0.168183    -0.00816671   -0.089778    -0.0499092    0.107732    -0.132549     0.0441416   -0.00768133    0.00588448    0.123217     0.0569073    -0.0547229     0.0118391    0.154552     0.11975     -0.224988    0.0261771   0.0735157    0.00689506   0.210618     0.0241936    0.123005   -0.0885666    -0.0916086   -0.077677  
  0.00350999   0.165609    -0.0215082     0.203757    -0.0543409    0.106433    -0.099053     0.0541658   -0.0144909     0.005863      0.00972408   0.0505668     0.13638       0.0156758   -0.0968709   -0.173914     0.0206315   0.0320984  -0.0884954    0.0142523    0.198367    -0.0169726   -0.117878    0.131286      0.0116762   -0.0610595 
  0.109743     0.0796517    0.15025      -0.572502    -0.774243    -0.120813     0.0931068   -0.122177    -0.00413736   -0.0881618    -0.0609498    0.111718     -0.0947901     0.179249     0.104544     0.0229222    0.065235    0.175944    0.129242     0.128834     0.900583     0.0584427    0.0866921   0.012048     -0.107088    -0.0688262 
  0.107351     0.0630209   -0.291069      0.167693     0.0889674   -0.164109     0.00686502  -0.122174     0.0123471    -0.0296877    -0.0631119    0.0913191    -0.10442       0.165982     0.103088     0.0216699    0.0672532   0.189104    0.125488    -0.041784    -0.0263471    0.0746184   -0.0341011   0.0151453    -0.148424    -0.0656847 
 -0.206386    -0.0581994   -0.0318823     0.342554     0.100155     0.21094      0.0191086   -0.0462548    0.0665698     0.127828      0.0258186    0.0518134     0.153167     -0.00565347   0.118086    -0.191255    -0.233354   -0.203167    0.0455344   -0.111803     0.176885     0.0818646   -0.0461895  -0.155102      0.034587     0.0768493 
 -0.0577248   -0.0202277    0.147106      0.147537     0.0375862    0.0668008    0.00466503  -0.0166021    0.00475135    0.158716      0.130112     0.0195745     0.010358      0.0339075   -0.148081    -0.00936164  -0.114822   -0.107143    0.0943238   -0.0382493    0.0575839   -0.117395    -0.0767883  -0.125987     -0.267883     0.0882441 
 -0.102952    -0.226315     0.109412     -0.355666     0.0165518    0.0886357    0.0866638   -0.0109731    0.274608      0.0621841     0.0557136    0.0883636    -0.0215974    -0.0371451   -0.0171205   -0.0468889   -0.186632   -0.004093   -0.164482     0.120385    -0.0458557   -0.0177801    0.0504654   0.0192928    -0.027856     0.0289776 
  0.122632    -0.123487    -0.0853136     0.185454     0.160246     0.0902024   -0.120752    -0.011397     0.121732     -0.0119539    -0.0364737   -0.00706086    0.048694      0.0383469   -0.110702    -0.0446706    0.0102438  -0.130522    0.0430403    0.038076     0.0854097    0.0967334   -0.0132768   0.0376225    -0.145279     0.0766265 
 -0.0265258    0.00796202   0.0341949    -0.0465545    0.0175532   -0.0490932    0.0024156    0.0478033   -0.0798785    -0.010198     -0.0143589    0.0278665     0.0231812     0.169351    -0.0972069   -0.147992     0.0921594  -0.0321742   0.0548935    0.0655097   -0.0380209   -0.119574    -0.0602079   0.149724     -0.0283713    0.0952983 
  0.231124     0.111905     0.00129607    0.0711062    0.0303848    0.162179     0.00173358   0.0202174    0.162686      0.000793785  -0.118723     0.247745     -0.0547203     0.043147    -0.0315029    0.0660787   -0.0958159  -0.0285237   0.14009     -0.21382     -0.0874701   -0.0766208    0.177635    0.0537255     0.0163714    0.0598181 
  0.00418019   0.110173    -0.0669658    -0.0680398    0.0737064   -0.00790518   0.0486407    0.0683401    0.0536978    -0.0404707     0.00122556   0.000669051  -0.00199737   -0.0593235   -0.060058    -0.0621205   -0.0973834   0.0589129  -0.00593364   0.0569808    0.0322111   -0.0217303    0.0513507   0.0959148    -0.0526476    0.130788  
  0.0481874   -0.0429006    0.153843     -0.0127689   -0.0274704    0.116433     0.0334708   -0.156327     0.0328194     0.0263095    -0.0457662   -0.0402755     0.0835068    -0.124065     0.0442745    0.00647213   0.0787184   0.15805     0.0097873    0.0324375    0.129392    -0.024406     0.0316213   0.103901      0.00182608  -0.0738665 
 -0.0922817   -0.0659432   -0.0579884    -0.0175533   -0.105668     0.0143332   -0.194822    -0.0621814   -0.163487     -0.0375275    -0.0945857   -0.055381     -0.0363243     0.153013    -0.173983     0.0901242   -0.0578259  -0.0311994  -0.27667     -0.0548746   -0.073145     0.256177    -0.188333   -0.0144636     0.00491873   0.0164052 
  0.0160103   -0.00334398   0.0010625    -0.046273    -0.0627744   -0.0550228    0.0909152    0.0256054    0.0336679     0.0777544     0.176346    -0.0295349    -0.0981574    -0.130302    -0.0764795    0.0864955    0.0466519   0.0309308  -0.113541     0.0709108    0.0817688   -0.0240619    0.115851    0.229004     -0.0113755    0.00274105
  0.0584112    0.121543     0.0355247    -0.139428    -0.113872    -0.0582343   -0.0302895    0.0951955   -0.0876547    -0.223133     -0.173795    -0.0948981     0.0408818     0.0515924   -0.0888445    0.200605    -0.089507    0.0388864  -0.0854886    0.053876    -0.00770896   0.0357552    0.17206    -0.0261122     0.0110997   -0.167734  
  0.178699     0.152886     0.0320951    -0.0411441   -0.127842     0.0931806   -0.0476245    0.0990942    0.0773621     0.481738     -0.146959     0.0771977     0.143827      0.0749817   -0.172137     0.0846659   -0.0509684   0.0286378  -0.0258873    0.0589381    0.0885982   -0.0614832    0.174574   -0.0358959     0.233245    -0.18309   
  0.0840187   -0.0224596    0.0741349    -0.180393    -0.0514537   -0.0389212   -0.0862624   -0.0758956   -0.0459351     0.146569      0.0192133    0.1225        0.0691571    -0.253328    -0.16271     -0.0831454   -0.027397    0.0189596   0.0466864   -0.573599    -0.10343     -0.160893    -0.0724704   0.0406073    -0.0753341    0.12531   
  0.0691148   -0.0223853    0.0846401    -0.0152791   -0.0478582   -0.0309899   -0.149623    -0.101368     0.310428      0.00360691    0.0195937   -0.026436      0.0702719     0.165142    -0.204555    -0.0145341   -0.0377331   0.021301    0.0514238    0.664555    -0.0747221   -0.0279382   -0.0729787  -0.106899      0.010242    -0.0957782 
 -0.201751     0.167692    -0.040786     -0.0867641    0.140354     0.0374212   -0.0919525    0.312926    -0.113543     -0.0270926    -0.116881    -0.0779307     0.13263      -0.0237706    0.221662     0.0368299   -0.0443757   0.122673   -0.264633     0.11265      0.00426137   0.00748346   0.217121   -0.00123733    0.0463802   -0.112483  
  0.0293496    0.167413    -0.0407505    -0.0861051   -0.198987    -0.184724    -0.0223216   -0.307238    -0.16275      -0.0235803    -0.112026     0.0269864    -0.00370426   -0.0160892    0.278833    -0.102783     0.0359955  -0.230029    0.161107     0.118242     0.0504361   -0.00540437  -0.130832   -0.000488076   0.0285944   -0.0987328 
 -0.0960118    0.011873    -0.0580082     0.0777509   -0.00837949   0.0416508   -0.0450691    0.0260409   -0.00900717    0.00614108    0.0899397   -0.0253129     0.0495423     0.00922213  -0.0217524   -0.0162616    0.0683127  -0.0414651  -0.0671355   -0.083302    -0.0759918    0.0154637    0.0011523   0.0548066     0.0203014    0.0188018 
  0.0125966    0.054201    -0.0369668     0.0268687   -0.0431316    0.0264727    0.0490461   -0.00810406   0.0175095     0.0890788     0.0371956    0.0425655    -0.0943702     0.166371    -0.00896113   0.0359746   -0.0604089   0.0190424   0.00208058   0.0565494    0.0402596    0.00678322   0.0489316  -0.0543075     0.0236551   -0.0014724 
  0.0754432    0.0828004    0.0671396     0.10347     -0.00869053  -0.0385845   -0.0675834   -0.00993244   0.13723      -0.0195254    -0.0121669   -0.0352027    -0.106828     -0.0105169    0.0647945    0.032391     0.147148   -0.124729   -0.0345211    0.074876    -0.0744774   -0.0290599   -0.0381518   0.0619707    -0.02382      0.0353626 
  0.130378    -0.0403578   -0.000642765   0.0302598    0.108228    -0.0296817    0.0472489   -0.0562251    0.0703893    -0.117488      0.0465623   -0.0988869     0.0113126    -0.07786     -0.0557504   -0.0431748   -0.0107067  -0.056012    0.0785066    0.0646444    0.0991916    0.0185356   -0.171066   -0.0493476     0.0729842    0.0634889 
  0.0619282    0.0928827    0.0723072    -0.0472023    0.0491047   -0.100433     0.202966     0.142247     0.0219988    -0.120465      0.0662647    0.0472678    -0.0458009    -0.166513     0.0142839   -0.115121     0.133595    0.110389   -0.0938126    0.372911    -0.0129736   -0.0379586   -0.206817    0.0802907    -0.0513617   -0.152776  
  0.0659339    0.18532      0.0353671     0.0719054    0.0786551   -0.125996    -0.206948     0.0313559    0.000204342   0.315251      0.206873     0.035152     -0.12386       0.501709    -0.0184973   -0.0837979    0.137378    0.0722611  -0.1268       0.0416871   -0.00881679  -0.0209487   -0.177787   -0.142763     -0.212059    -0.097522  
 -0.0544819    0.0772164   -0.0372968     0.00552734   0.0907848   -0.0218636   -0.015934     0.0734333   -0.10511       0.00258613   -0.0575878   -0.0481889     0.0280695    -0.0120652   -0.0415112    0.0741962    0.0117724   0.0329936   0.128361    -0.141412     0.0200978   -0.0526373   -0.0770855   0.143377      0.0263744   -0.139732  
  0.258164    -0.0572239   -0.187103      0.0446937    0.0785613   -0.0094807    0.0936297    0.117715    -0.0665307    -0.0437615    -0.0246958    0.0135845     0.000133954  -0.110441     0.125397    -0.0699104   -0.0848843  -0.241323    0.251051     0.174067     0.191331    -0.0230322   -0.0212125   0.0762769    -0.103457    -0.133454  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.055531
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.041709
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.047879
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.042210
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.055483
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.041624
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.047877
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.042206
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      2
│      7
│      8
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.055482
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.041621
┌ Info: EM with 100000 data points 10 iterations avll -1.041621
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians LinearAlgebra.diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.152460e+05
      1       6.503105e+05      -1.649355e+05 |       32
      2       6.184806e+05      -3.182993e+04 |       32
      3       6.002600e+05      -1.822054e+04 |       32
      4       5.908114e+05      -9.448594e+03 |       32
      5       5.861540e+05      -4.657398e+03 |       32
      6       5.831275e+05      -3.026509e+03 |       32
      7       5.807420e+05      -2.385558e+03 |       32
      8       5.788943e+05      -1.847648e+03 |       32
      9       5.774273e+05      -1.467040e+03 |       32
     10       5.762834e+05      -1.143860e+03 |       32
     11       5.753674e+05      -9.160160e+02 |       32
     12       5.746774e+05      -6.899867e+02 |       32
     13       5.743109e+05      -3.664708e+02 |       32
     14       5.741161e+05      -1.948369e+02 |       32
     15       5.739549e+05      -1.611718e+02 |       32
     16       5.737842e+05      -1.707000e+02 |       32
     17       5.735933e+05      -1.908959e+02 |       32
     18       5.734025e+05      -1.908272e+02 |       32
     19       5.732200e+05      -1.824626e+02 |       32
     20       5.730723e+05      -1.477824e+02 |       32
     21       5.729667e+05      -1.055936e+02 |       32
     22       5.728953e+05      -7.136834e+01 |       30
     23       5.728454e+05      -4.991407e+01 |       32
     24       5.728083e+05      -3.713044e+01 |       31
     25       5.727757e+05      -3.253291e+01 |       30
     26       5.727496e+05      -2.615924e+01 |       30
     27       5.727225e+05      -2.706022e+01 |       31
     28       5.726983e+05      -2.419056e+01 |       29
     29       5.726738e+05      -2.451819e+01 |       28
     30       5.726505e+05      -2.333835e+01 |       30
     31       5.726285e+05      -2.196535e+01 |       30
     32       5.726113e+05      -1.721734e+01 |       31
     33       5.725926e+05      -1.870730e+01 |       29
     34       5.725695e+05      -2.306981e+01 |       31
     35       5.725423e+05      -2.724767e+01 |       31
     36       5.725140e+05      -2.822253e+01 |       31
     37       5.724788e+05      -3.524512e+01 |       31
     38       5.724304e+05      -4.841880e+01 |       31
     39       5.723695e+05      -6.082547e+01 |       32
     40       5.722946e+05      -7.492254e+01 |       32
     41       5.721703e+05      -1.243354e+02 |       32
     42       5.720089e+05      -1.614143e+02 |       32
     43       5.718482e+05      -1.606481e+02 |       32
     44       5.716971e+05      -1.511359e+02 |       32
     45       5.714919e+05      -2.052332e+02 |       32
     46       5.712134e+05      -2.784477e+02 |       32
     47       5.708567e+05      -3.566772e+02 |       32
     48       5.705955e+05      -2.612697e+02 |       32
     49       5.704717e+05      -1.237803e+02 |       32
     50       5.704321e+05      -3.962163e+01 |       30
K-means terminated without convergence after 50 iterations (objv = 570432.0561226343)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.298272
[ Info: iteration 2, average log likelihood -1.266783
[ Info: iteration 3, average log likelihood -1.235425
[ Info: iteration 4, average log likelihood -1.201367
[ Info: iteration 5, average log likelihood -1.168049
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.131907
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.099776
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     20
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.062166
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│      6
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.085198
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.103944
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     12
│     13
│     16
│     20
│     23
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.050608
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.116701
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.078383
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      8
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.067339
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     12
│     16
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.070921
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.068270
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│     18
│     20
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.050238
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     12
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.093802
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.085561
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     16
│     23
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.036989
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      6
│     12
│     18
│     20
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.041725
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.122404
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.084112
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│     12
│     13
│     16
│     18
│     20
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.025833
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      6
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.105262
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.075614
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.059803
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     13
│     16
│     18
│     23
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.048330
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     2
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.094039
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     12
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.076733
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     24
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.073114
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│     13
│     16
│     23
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.053175
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.096106
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.076853
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     18
│     24
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.045037
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     12
│     13
│     16
│     20
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.058976
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.111401
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.064079
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     12
│     18
│     20
│     24
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.032165
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     13
│     16
│     23
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.085646
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.106783
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.065040
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     18
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.059199
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      6
│     13
│     16
│     23
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.040039
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.101843
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.081914
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      5
│     18
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.042325
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     12
│     13
│     16
│     20
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.055896
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.111485
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.069007
┌ Info: EM with 100000 data points 50 iterations avll -1.069007
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.133574    -0.00146676   0.0788996    0.0899353   -0.068661     0.101935    -0.0956413    0.019656   -0.0407713    -0.00471348   -0.0413765    0.120009    -0.0126277    0.0343176    -0.151855    -0.0198137    0.0361694    0.00239827  -0.100359    -0.0969511   -0.183406     0.075871    0.0441839    0.0169698     0.0512643    0.111022   
  0.0337696    0.055236     0.072978    -0.153586     0.0852085   -0.0119191    0.0289661   -0.0273983   0.0521112     0.0212931     0.0185529   -0.0352423   -0.190249    -0.0189035     0.0426488   -0.115427     0.0517723    0.0169022    0.0516267    0.0333663    0.0183852    0.0136362   0.0143966   -0.058228      0.0512231   -0.0497171  
  0.161739     0.0440774   -0.152153     0.0539811    0.00722045  -0.0122275    0.135424    -0.171681    0.0527417    -0.114094     -0.0116437   -0.0597761    0.0951229   -0.157584      0.13451     -0.153377    -0.0540326   -0.102686     0.092456     0.0485736    0.105594     0.138325   -0.129176    -0.0065213     0.102955    -0.0124477  
  0.0679901    0.134914     0.056358     0.00750052   0.0533286   -0.107054    -0.00222407   0.0833685   0.0120998     0.099307      0.130683     0.041386    -0.0867215    0.155985     -0.00317158  -0.0935483    0.134142     0.0812385   -0.106355     0.195911    -0.0111305   -0.0295021  -0.191404    -0.0284317    -0.125506    -0.123678   
  0.210361    -0.162498    -0.13148      0.0132694    0.0691537   -0.0955295    0.177035     0.248505   -0.0310354    -0.0215709     0.00744614  -0.0439124    0.019233    -0.0622849     0.0231329    0.00774077  -0.00861769  -0.27185      0.178692     0.166248     0.0600316   -0.0129039   0.0658508    0.0797152    -0.0579038   -0.083791   
  0.104539     0.0654795   -0.199348     0.00918951  -0.0804274   -0.153074     0.0223695   -0.122852    0.00673718   -0.0427848    -0.0640801    0.0935144   -0.111012     0.170752      0.106879     0.0215953    0.0675528    0.185572     0.125743    -0.0112895    0.162591     0.070667   -0.00541283   0.0142886    -0.140041    -0.0669464  
  0.0898721   -0.0111317    0.227541     0.00292417   0.0330412    0.0783033    0.0520825   -0.149829    0.0339119     0.0581608     0.100271     0.0337321    0.182721    -0.0920315     0.0330009   -0.0994807   -0.0182931    0.172761    -0.0172821    0.0905094    0.108384     0.0291024  -0.0581679    0.131635      0.0422399   -0.0398141  
  0.00627954  -0.0734922    0.0629751   -0.0305402   -0.0796664    0.15754      0.0132632   -0.156482    0.0455861    -0.00585048   -0.215908    -0.130425    -0.0267225   -0.15405       0.0519272    0.13082      0.169661     0.127547     0.0380141   -0.0245446    0.162298    -0.081422    0.147206     0.0735808    -0.0489178   -0.121862   
 -0.0421971   -0.117305    -0.205236    -0.134273    -0.0881526    0.00695196   0.0615893   -0.153774    0.020925      0.128492     -0.0169814   -0.0197905   -0.0688937    0.180214     -0.108014     0.0266818    0.0318657    0.0212414   -0.0966545    0.114222    -0.00523263   0.0289943   0.0936971   -0.0639405     0.148481    -0.0656164  
 -0.0785042   -0.00252323  -0.0521444   -0.0573829    0.0291845   -5.57917e-5   0.0126797    0.2154      0.102866     -0.167238     -0.0185377    0.00315801  -0.116633     0.0368708     0.0808258   -0.0164379   -0.0397902    0.00680272  -0.0126443   -0.0379747   -0.0288356   -0.0626482   0.0534101    0.12878      -0.10901      0.151831   
  0.135215    -0.0804721    0.141984    -0.00678808   0.20656     -0.0531336    0.00252365   0.0824863   0.0305463    -0.0947996     0.0684289   -0.112867    -0.0298547   -0.0307719    -0.175869     0.0429284    0.0188152   -0.0214395    0.102973     0.135522     0.0975192   -0.0479467  -0.159991    -0.0409963     0.0410773    0.0605364  
 -0.0940119    0.163546    -0.0416147   -0.0842334   -0.018322    -0.0790726   -0.0575352    0.0425704  -0.143196     -0.0278107    -0.109464    -0.023201     0.062879    -0.0134863     0.254585    -0.0190802    0.0058409   -0.0612153   -0.062051     0.121402     0.0353251    0.0027625   0.0688446    0.00457344    0.0365104   -0.106517   
  0.118087    -0.0667212   -0.140497    -0.117072    -0.00403364  -0.0956234    0.0952671    0.225186    0.0201871     0.017015      0.0602007   -0.098601     0.0662934    0.0460679    -0.147278    -0.0178857    0.00552801  -0.069496    -0.0796598    0.114212    -0.18932      0.101616    0.135965     0.096361      0.0503215   -0.0863459  
  0.123046     0.138815     0.0344089   -0.0910103   -0.116009     0.0166088   -0.0378547    0.09962    -0.000944929   0.145187     -0.160794    -0.00181297   0.096587     0.0630785    -0.13883      0.139781    -0.0715311    0.032429    -0.0542745    0.0604938    0.0361512   -0.012245    0.174157    -0.0321904     0.122215    -0.17487    
  0.0560454    0.132687     0.115463     0.167614     0.0283549   -0.030567     0.0213124    0.0840997   0.0813811    -0.0301046     0.0214547    0.00205978  -0.105666     0.0855378     0.0996514    0.0148278    0.0293899   -0.0138652    0.0175651    0.0793006   -0.0054544   -0.0146396   0.0147713    0.0255028    -0.0388689    0.0480743  
 -0.0844656   -0.20914      0.185646    -0.538598     0.0260011    0.0847201    0.0955077   -0.0433052   0.393923      0.0676798     0.061747     0.0922799   -0.032578    -0.0667468     0.0619867   -0.0516834   -0.194969     0.0386092   -0.134755     0.105114    -0.0110188   -0.0184251   0.0304224    0.015855     -0.0189752    0.0347677  
 -0.205192    -0.055978    -0.0313329    0.340763     0.10049      0.211395     0.0193611   -0.0457174   0.0699049     0.128369      0.028641     0.0487335    0.152867    -0.00576997    0.118458    -0.199355    -0.236104    -0.209861     0.0463434   -0.110944     0.184659     0.0831902  -0.0466541   -0.157935      0.0363822    0.0775495  
  0.0169111   -0.0272233    0.00313234  -0.0564375   -0.06199     -0.0622495    0.0838557    0.03877     0.0376955     0.0658208     0.178888    -0.0200583   -0.101442    -0.114506     -0.0862849    0.0910301    0.0447409    0.0325533   -0.11908      0.073825     0.0732419   -0.0285719   0.119582     0.231863     -0.0173639    0.000114201
 -0.0482407    0.075836    -0.0425885    0.0079245    0.0928972   -0.0227717   -0.0169521    0.0792591  -0.103912      0.000415489  -0.0544726   -0.0471489    0.02801     -0.0132711    -0.0389394    0.075758     0.00577802   0.0203916    0.1305      -0.138454     0.0257925   -0.0571787  -0.0761743    0.13797       0.0236282   -0.139821   
  0.0737324   -0.0195625    0.0774669   -0.0986484   -0.0487589   -0.0357969   -0.11798     -0.0858804   0.115821      0.0728973     0.0171193    0.0521987    0.0688677   -0.0532031    -0.190474    -0.0472621   -0.0344138    0.0230796    0.0405576    0.00944779  -0.0972937   -0.0993866  -0.0732467   -0.0250518    -0.034326     0.0181311  
  0.237588     0.123877     0.00532955   0.0763209    0.0266402    0.16648      0.00151697   0.0242431   0.16272       0.00945878   -0.1209       0.253417    -0.0596354    0.043339     -0.0268965    0.0745507   -0.102098    -0.0290677    0.141835    -0.215868    -0.0792374   -0.0787639   0.177571     0.0541917     0.0180735    0.059791   
 -0.0547959    0.0570727   -0.100197    -0.0155766    0.0154225    0.0637536   -0.0865553    0.0309006   0.0357858     0.0202007     0.0391853    0.0606439   -0.011454    -0.0186762     0.101927    -0.0351542   -0.0197514    0.0387149    0.0822071   -0.112774     0.160453    -0.0262907   0.0337829   -0.0549689     0.0933108   -0.024611   
  0.0944496    0.122143    -0.0709662    0.128577    -0.185024     0.0881177   -0.194069    -0.159324    0.116709      0.113465      0.0289203    0.0473947   -0.091457    -0.0698482    -0.00722407   0.104756     0.0724405   -0.390097    -0.00179611  -0.0543789   -0.0560373   -0.024151   -0.11927     -0.000728031  -0.104321     0.0160933  
 -0.058828    -0.0392123    0.154989     0.110613     0.0341235    0.0687404    0.0143142   -0.0169239   0.0396669     0.158325      0.121937     0.0309284    0.00822126   0.032966     -0.147135    -0.0145887   -0.125038    -0.0996652    0.069428    -0.0168817    0.0482604   -0.103599   -0.0653469   -0.107265     -0.245542     0.0806344  
  0.0502094    0.0380341    0.184302    -0.0752316    0.151567    -0.0280125    0.0227443    0.102232    0.0351802     0.00855804    0.0553406   -0.0648208   -0.226392    -0.121145      0.0520613   -0.262325     0.134012    -0.0404245    0.0829412    0.0401602   -0.0529976    0.0272627   0.0455219   -0.0872492     0.106777    -0.10096    
  0.107066     0.218421    -0.0842795   -0.0741913    0.135048    -0.0315681    0.0931502   -0.0551505  -0.0111073     0.0540528     0.0318318   -0.00221218   0.114588    -0.152798     -0.187072    -0.133424    -0.210018     0.12393      0.00891453   0.163787     0.104258     0.016001    0.0479859    0.0648225     0.0047445    0.131463   
  0.254841    -0.0725195   -0.186326     0.0571548    0.0533076   -0.0232352    0.0953536    0.0969609  -0.0275904    -0.0443083    -0.0280816   -0.00112977  -0.0116      -0.101115      0.118326    -0.0324853   -0.0941557   -0.229357     0.221202     0.171408     0.148409    -0.0483137  -0.0391181    0.0652939    -0.116418    -0.0769924  
  0.119237    -0.125235    -0.0834553    0.183873     0.155618     0.0905456   -0.116558    -0.0104032   0.12105      -0.00963503   -0.0334119   -0.00601181   0.0474122    0.0382129    -0.104045    -0.0445437    0.00790715  -0.135935     0.0409183    0.0409994    0.0797704    0.0942944  -0.0116098    0.0371788    -0.143664     0.0752206  
 -0.0920994   -0.063899    -0.0556645   -0.0236406   -0.1023       0.0144628   -0.185584    -0.0562739  -0.159171     -0.033842     -0.0807593   -0.0537003   -0.0358621    0.146076     [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
-0.174594     0.0876862   -0.0573003   -0.0303087   -0.26075     -0.0495803   -0.0724356    0.25086    -0.18168     -0.0131323     0.00324636   0.0134689  
 -0.0213466    0.0365816   -0.142734     0.0509998    0.0548329   -0.0411879    0.00457039   0.0552326   0.0187556     0.0167299     0.223617    -0.152179     0.113137    -0.000261312   0.0834899   -0.00808098   0.0896381   -0.0941627   -0.0236564   -0.048314     0.0272027   -0.0514466  -0.0308746    0.0998301    -0.0148756   -0.0695759  
  0.130597    -0.0132105    0.166446     0.0568364   -0.0492702   -0.119764    -0.146879     0.0736244  -0.0172298     0.0300925    -0.100483    -0.0718494   -0.0163492    0.140333     -0.0519674   -0.221998     0.0787675    0.0130239   -0.0036677    0.176121     0.0393969   -0.106915   -0.113376     0.104958      0.0577083    0.111734   
 -0.148007     0.0230987   -0.122644    -0.129387     0.104222     0.0173435    0.161882     0.0268488  -0.136576     -0.039065      0.0810036    0.1143       0.0653852    0.156232     -0.124798    -0.0927187    0.105711    -0.0754982    0.129698    -0.0229199   -0.0927362   -0.132447   -0.007074     0.193662     -0.113897     0.0486352  ┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      6
│     12
│     18
│     20
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.027863
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      6
│     12
│     13
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.987100
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      4
│      6
│      ⋮
│     24
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.998243
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      5
│      6
│     12
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.000573
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      6
│     12
│     18
│     20
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.012490
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      4
│      6
│      8
│     12
│      ⋮
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.977697
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      6
│     12
│     18
│     20
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.023266
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      4
│      6
│     12
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.986216
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      6
│      8
│      ⋮
│     24
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.999221
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      6
│     12
│     13
│      ⋮
│     25
│     26
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.001179
┌ Info: EM with 100000 data points 10 iterations avll -1.001179
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.209678    -0.0545731   -0.000319896   0.110504     0.0138713   -0.0850002    -0.0651041   -0.0164322    0.110601    -0.0182741     0.0364011    0.00561157  -0.0183733    0.0522255   -0.134664    -0.0415129  -0.000221807  -0.131201    -0.0862306    0.20625     -0.0610268   -0.157508     -0.0226085   -0.0351911   -0.164952     0.0865891 
  0.0526507   -0.145856    -0.0267895    -0.0755042   -0.0885753   -0.117337      0.0890463   -0.0375069   -0.0243894   -0.0435794    -0.0431188    0.0723025    0.0146066   -0.00811535  -0.0290006   -0.0705792  -0.137569      0.0314478   -0.00422251   0.085183    -0.0820818   -0.0169497     0.0131845    0.111887    -0.13055      0.00798426
  0.037499    -0.0220318    0.162893      0.14528     -0.0376034   -0.0516071    -0.0304448    0.0143082   -0.081657    -0.0984288    -0.0157618    0.0300741    0.0119134   -0.0898336   -0.100786     0.0632858   0.0471319     0.00193666   0.100862     0.0427752    0.135709    -0.0677095     0.0398936   -0.29734     -0.117857    -0.139432  
  0.00307454  -0.00074067   0.00483105   -0.0939275    0.0561781   -0.0513058     0.0806192    0.0932107   -0.0642495    0.106536      0.162654     0.0271431   -0.157363    -0.161594     0.163989     0.178636   -0.0216805    -0.0353155   -0.0867326   -0.0690784    0.110734    -0.0239206    -0.0689178    0.00447722  -0.0302265    0.0828685 
  0.0165064   -0.0408345    0.105779     -0.0839554    0.228714     0.0748976    -0.00825025   0.0241892    0.03907     -0.0430697     0.0360336   -0.0923223    0.0351056   -0.156351     0.00410326   0.133516    0.174004     -0.00332529   0.053811    -0.0159498   -0.066956    -0.133552     -0.0411563    0.0284753   -0.0629121    0.00985431
  0.164951    -0.0665714   -0.117254      0.134206     0.148978    -0.0470349    -0.0392042   -0.0931385   -0.0617343    0.0727039    -0.0146584   -0.0137036   -0.00768581  -0.0899674   -0.00481824  -0.0473879   0.108297      0.127576    -0.0324389   -0.0355298    0.0687723    0.207054      0.0108658    0.0311843    0.168739     0.0309002 
 -0.0126022   -0.0378699    0.0454149    -0.258617    -0.0694322    0.0340576    -0.147372    -0.0734028   -0.00711799   0.0944888    -0.00729181   0.0626828    0.022977     0.208666    -0.00894429   0.0184426   0.123146     -0.0529524   -0.141685    -0.116219    -0.0764145    0.0175664     0.0176209   -0.0888328   -0.198793     0.0672099 
 -0.154553     0.0755372   -0.126545     -0.144341     0.0257012    0.112911      0.00627816  -0.0548983   -0.0850748   -0.061627     -0.0382247   -0.110073     0.0397628    0.0313877   -0.0773321    0.145615   -0.0911375    -0.0180095   -0.0149154   -0.0667599   -0.0715072    0.0121277    -0.163041     0.12052     -0.00615718   0.131442  
  0.0445318   -0.097462    -0.135304     -0.00733478  -0.0165017    0.125781     -0.0374124    0.0354596   -0.0559994   -0.0241097     0.0469291   -0.0506559   -0.00940095   0.0316995    0.0355756   -0.147197   -0.0856644     0.0810289    0.0376047   -0.0303058   -0.00280623   0.0197423    -0.0999781   -0.134011     0.147883     0.0551433 
 -0.0986334   -0.0488055   -0.200198      0.011902    -0.0401388   -0.0750252     0.138632    -0.102134     0.28662      0.0583967     0.0552161    0.118618     0.0391598    0.192265    -0.124448     0.141054    0.0242036    -0.115181    -0.0852635   -0.0571457    0.00291556  -0.184021     -0.00299222  -0.0205806    0.0122362    0.0195586 
 -0.00649143  -0.198002     0.0773407    -0.0834429   -0.213282     0.11973       0.139766     0.0334443   -0.0839959    0.057947     -0.227154     0.0114475   -0.0192866    0.12498     -0.0197154    0.214044   -0.08845      -0.084224     0.0385049   -0.0769725   -0.031919    -0.0487032    -0.0485575   -0.0185504    0.0559942    0.00266529
  0.130326    -0.0953313   -0.0389234    -0.00742779   0.162313    -0.208208      0.0886128    0.00945659   0.00200168  -0.0480998    -0.099078     0.0746256    0.0418729    0.0610264   -0.0367098   -0.0457002  -0.159723      0.0866116   -0.130132    -0.0168715    0.0119263    0.183757     -0.056624     0.0472153   -0.00556023   0.108742  
  0.0120189    0.06241     -0.0114067    -0.0335915    0.0881611    0.011152     -0.0847447   -0.12792     -0.107774    -0.0103936     0.05546      0.118491    -0.126035     0.149087    -0.00815503  -0.0503275  -0.0129303     0.137723    -0.0168219    0.0913737    0.0736159   -0.198159      0.0241556   -0.00353441   0.117273     0.0128882 
 -0.0422183   -0.145734     0.0272227     0.0654659   -0.145925    -0.075739      0.133346    -0.0325911   -0.0921896    0.185893     -0.0642698    0.162813     0.0415616    0.0813033   -0.0277347   -0.138031   -0.0817954     0.00507082   0.217926    -0.0452376    0.211957     0.0600393    -0.0850878    0.0864792   -0.0305355    0.00184423
  0.0320079   -0.14764      0.000790825   0.0423751    0.154122     0.0333138    -0.0706751   -0.071843     0.108688    -0.00862615    0.0120706   -0.103446     0.0129744    0.00539649  -0.0593254    0.0695251   0.200202      0.242655    -0.0228444    0.0801001    0.0301646    0.0808808    -0.0468159    0.273913    -0.0237354    0.036547  
  0.00837129  -0.165623     0.262176     -0.0979141    0.122751     0.0462842     0.0356897   -0.119725    -0.0426072   -0.0826731    -0.0346323    0.015422    -0.0738279   -0.054631     0.0809503   -0.191594    0.0235689     0.0857909    0.130274     0.0147746    0.0851485    0.0224288     0.0876128   -0.0137741    0.223783     0.0791644 
  0.015208    -0.187736     0.00859099    0.0727602    0.0882804   -0.0164847    -0.0306674   -0.0305684   -0.0397527    0.000620664  -0.106756    -0.033572     0.00796579   0.0475883    0.0114737    0.07508     0.0272972    -0.144155     0.0426282    0.0609471    0.0502642    0.000641025   0.0678209    0.00830356   0.0624673   -0.0194971 
 -0.0555168   -0.00275363  -0.139441     -0.0445834   -0.0189011    0.13896       0.0418537   -0.0236121   -0.149387    -0.0253345     0.0650085   -0.0118559    0.0207157   -0.0595879    0.107302     0.119036   -0.151116     -0.0717905    0.0721003    0.0395616    0.17968     -0.00784023    0.124297     0.00914128  -0.0504097    0.0120414 
 -0.108626    -0.158623     0.00836934    0.0141148    0.0571788    0.0695667     0.182341     0.0428234    0.0472952   -0.0491038     0.0444316    0.0459473    0.0499671   -0.181971    -0.0308493    0.130175    0.0503016    -0.0725915    0.0358128   -0.192401     0.109865    -0.000332941  -0.0447646   -0.0196967   -0.131047    -0.245363  
 -0.0748251    0.0971944    0.0408991    -0.0200683   -0.0768267   -0.0475951     0.0990949    0.032851     0.145427     0.11831       0.10004      0.04596     -0.036421     0.028176    -0.166779     0.0708517  -0.007231      0.0265217   -0.037485     0.00325264  -0.0637922   -0.101353      0.0083866    0.100505    -0.181138     0.0364213 
 -0.0442685    0.118453     0.0443923    -0.0173979   -0.0226064   -0.0347027     0.223847    -0.022607     0.0757947    0.126718      0.0454095    0.195174     0.00364517   0.0580455    0.109469    -0.0869899  -0.00781491   -0.0641892    0.0077452    0.106135     0.144834    -0.0300282    -0.00409372   0.0512658    0.0356856   -0.0463611 
 -0.0428202    0.158659    -0.142703     -0.040598    -0.115321    -0.222504      0.103163    -0.0186699   -0.196629     0.114002     -0.0908785    0.00089613   0.224955    -0.112526     0.00655961   0.149791    0.0841151    -0.0205435   -0.100723     0.0690535   -0.0806664   -0.0344989     0.125673    -0.0467548   -0.134018    -0.0423222 
 -0.0154132    0.0385145    0.0924337    -0.0199236   -0.246517    -0.0826984    -0.0426498    0.0831615   -0.156658     0.07455       0.0976336    0.11468     -0.0458012    0.0570978    0.0842281    0.188194    0.00931253    0.0624535   -0.15752     -0.0290948    0.0261838    0.0707141    -0.0869896    0.0248698    0.0675102   -0.268473  
  0.0218907   -0.00306996   0.114035     -0.0466957    0.0297814    0.103772      0.192303    -0.0841733   -0.0642545    0.259156      0.0432769    0.098122    -0.0136165   -0.0645437    0.0493051   -0.0183759   0.0608149    -0.0579276    0.0554762    0.0397105   -0.132938    -0.0681189    -0.165646    -0.0910666   -0.0312363    0.0951367 
 -0.00834928  -0.0358461    0.153118      0.0310496   -0.0960837    0.0288221    -0.0838102   -0.192952    -0.0817396    0.0682465     0.145256     0.00323871  -0.16768      0.0348623   -0.0286162   -0.147308   -0.0435376    -0.0503402    0.0261115   -0.117388    -0.0941006    0.311632     -0.043479     0.107895     0.195655    -0.014461  
  0.0162177    0.0277488   -0.036504      0.0510168    0.00578926   0.000596747   0.0188173    0.0313353    0.0513742   -0.0912886     0.0355644    0.133632     0.00369971   0.0109349   -0.0543475    0.0722305  -0.16249      -0.14239     -0.0381015    0.0965558   -0.0857827    0.0512135    -0.0831678   -0.124281    -0.0531176    0.0460197 
  0.128792     0.080911     0.047725      0.00575393   0.03177     -0.0460538    -0.0396922    0.0371241    0.245085    -0.0234857     0.0487923    0.0338059    0.0388754   -0.0159316    0.224609     0.0158397   0.119349     -0.120499     0.0461494   -0.0593339    0.0309796   -0.0660635     0.286341     0.0732855    0.0689218    0.0770357 
  0.0138421    0.0482554   -0.150786     -0.0459683    0.0700059   -0.0704576    -0.193788    -0.155213     0.0620207   -0.0547064    -0.0568805   -0.178496    -0.179069    -0.00843688   0.0670564    0.0608498   0.0467707     0.214069     0.0700991   -0.0220974    0.024113    -0.129443     -0.0812054    0.108318     0.0399655    0.194751  
  0.00672173   0.021606     0.0904543     0.00352832   0.0685363    0.0785668    -0.137214    -0.00416929  -0.100569    -0.129104     -0.0229836    0.0396967   -0.118023     0.0580947    0.0355442    0.192389   -0.0279971     0.0146065   -0.0211645   -0.0425302    0.0989234    0.0467593     0.132786     0.131239     0.0170803   -0.0337159 
  0.0446578    0.0220324   -0.0458127     0.00870958  -0.134198     0.00820116    0.0625873    0.0895297    0.00589335  -0.0931386    -0.183312     0.046299     0.0966876    0.0317986    0.206535     0.124969   -0.150716     -0.0217565    0.168259     0.136577     0.186839    -0.0273221    -0.0986783   -0.0747485   -0.170871    -0.0045905 
 -0.0124884    0.170105     0.110932     -0.0588447    0.20702      0.00627761   -0.0369719    0.0372842   -0.0496479    0.106907     -0.0614       0.0408732    0.0853447   -0.0288317    0.0954134    0.100918    0.0321353    -0.134679    -0.039023     0.130967     0.0956103    0.0622686    -0.126795     0.041867     0.0421358   -0.131233  
 -0.073551    -0.0569801    0.00547017    0.0357665    0.0375612    0.0198996    -0.135605     0.108217    -0.0956151    0.023066      0.0166595   -0.00319232  -0.0868454   -0.0930655    0.0729028   -0.0119418  -0.0737476     0.0721829   -0.0759122   -0.0967343   -0.174902    -0.148496     -0.0267228    0.0690881    0.0331182   -0.218654  kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4256710048106496
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425692
[ Info: iteration 2, average log likelihood -1.425606
[ Info: iteration 3, average log likelihood -1.425526
[ Info: iteration 4, average log likelihood -1.425419
[ Info: iteration 5, average log likelihood -1.425270
[ Info: iteration 6, average log likelihood -1.425068
[ Info: iteration 7, average log likelihood -1.424792
[ Info: iteration 8, average log likelihood -1.424400
[ Info: iteration 9, average log likelihood -1.423833
[ Info: iteration 10, average log likelihood -1.423061
[ Info: iteration 11, average log likelihood -1.422184
[ Info: iteration 12, average log likelihood -1.421421
[ Info: iteration 13, average log likelihood -1.420912
[ Info: iteration 14, average log likelihood -1.420632
[ Info: iteration 15, average log likelihood -1.420493
[ Info: iteration 16, average log likelihood -1.420428
[ Info: iteration 17, average log likelihood -1.420397
[ Info: iteration 18, average log likelihood -1.420382
[ Info: iteration 19, average log likelihood -1.420375
[ Info: iteration 20, average log likelihood -1.420372
[ Info: iteration 21, average log likelihood -1.420370
[ Info: iteration 22, average log likelihood -1.420369
[ Info: iteration 23, average log likelihood -1.420369
[ Info: iteration 24, average log likelihood -1.420369
[ Info: iteration 25, average log likelihood -1.420369
[ Info: iteration 26, average log likelihood -1.420368
[ Info: iteration 27, average log likelihood -1.420368
[ Info: iteration 28, average log likelihood -1.420368
[ Info: iteration 29, average log likelihood -1.420368
[ Info: iteration 30, average log likelihood -1.420368
[ Info: iteration 31, average log likelihood -1.420368
[ Info: iteration 32, average log likelihood -1.420368
[ Info: iteration 33, average log likelihood -1.420368
[ Info: iteration 34, average log likelihood -1.420368
[ Info: iteration 35, average log likelihood -1.420368
[ Info: iteration 36, average log likelihood -1.420368
[ Info: iteration 37, average log likelihood -1.420368
[ Info: iteration 38, average log likelihood -1.420368
[ Info: iteration 39, average log likelihood -1.420368
[ Info: iteration 40, average log likelihood -1.420368
[ Info: iteration 41, average log likelihood -1.420368
[ Info: iteration 42, average log likelihood -1.420368
[ Info: iteration 43, average log likelihood -1.420368
[ Info: iteration 44, average log likelihood -1.420368
[ Info: iteration 45, average log likelihood -1.420368
[ Info: iteration 46, average log likelihood -1.420368
[ Info: iteration 47, average log likelihood -1.420368
[ Info: iteration 48, average log likelihood -1.420367
[ Info: iteration 49, average log likelihood -1.420367
[ Info: iteration 50, average log likelihood -1.420367
┌ Info: EM with 100000 data points 50 iterations avll -1.420367
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4256919252913496
│     -1.4256062642391214
│      ⋮                 
└     -1.4203674743448234
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420388
[ Info: iteration 2, average log likelihood -1.420299
[ Info: iteration 3, average log likelihood -1.420217
[ Info: iteration 4, average log likelihood -1.420111
[ Info: iteration 5, average log likelihood -1.419977
[ Info: iteration 6, average log likelihood -1.419825
[ Info: iteration 7, average log likelihood -1.419677
[ Info: iteration 8, average log likelihood -1.419551
[ Info: iteration 9, average log likelihood -1.419455
[ Info: iteration 10, average log likelihood -1.419386
[ Info: iteration 11, average log likelihood -1.419335
[ Info: iteration 12, average log likelihood -1.419298
[ Info: iteration 13, average log likelihood -1.419268
[ Info: iteration 14, average log likelihood -1.419245
[ Info: iteration 15, average log likelihood -1.419225
[ Info: iteration 16, average log likelihood -1.419208
[ Info: iteration 17, average log likelihood -1.419192
[ Info: iteration 18, average log likelihood -1.419179
[ Info: iteration 19, average log likelihood -1.419167
[ Info: iteration 20, average log likelihood -1.419155
[ Info: iteration 21, average log likelihood -1.419145
[ Info: iteration 22, average log likelihood -1.419136
[ Info: iteration 23, average log likelihood -1.419127
[ Info: iteration 24, average log likelihood -1.419119
[ Info: iteration 25, average log likelihood -1.419112
[ Info: iteration 26, average log likelihood -1.419105
[ Info: iteration 27, average log likelihood -1.419099
[ Info: iteration 28, average log likelihood -1.419093
[ Info: iteration 29, average log likelihood -1.419088
[ Info: iteration 30, average log likelihood -1.419083
[ Info: iteration 31, average log likelihood -1.419078
[ Info: iteration 32, average log likelihood -1.419073
[ Info: iteration 33, average log likelihood -1.419068
[ Info: iteration 34, average log likelihood -1.419064
[ Info: iteration 35, average log likelihood -1.419059
[ Info: iteration 36, average log likelihood -1.419054
[ Info: iteration 37, average log likelihood -1.419049
[ Info: iteration 38, average log likelihood -1.419044
[ Info: iteration 39, average log likelihood -1.419038
[ Info: iteration 40, average log likelihood -1.419033
[ Info: iteration 41, average log likelihood -1.419026
[ Info: iteration 42, average log likelihood -1.419020
[ Info: iteration 43, average log likelihood -1.419013
[ Info: iteration 44, average log likelihood -1.419006
[ Info: iteration 45, average log likelihood -1.418998
[ Info: iteration 46, average log likelihood -1.418990
[ Info: iteration 47, average log likelihood -1.418981
[ Info: iteration 48, average log likelihood -1.418973
[ Info: iteration 49, average log likelihood -1.418964
[ Info: iteration 50, average log likelihood -1.418955
┌ Info: EM with 100000 data points 50 iterations avll -1.418955
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4203880315575792
│     -1.4202991856269498
│      ⋮                 
└     -1.4189546196347926
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418957
[ Info: iteration 2, average log likelihood -1.418880
[ Info: iteration 3, average log likelihood -1.418808
[ Info: iteration 4, average log likelihood -1.418721
[ Info: iteration 5, average log likelihood -1.418610
[ Info: iteration 6, average log likelihood -1.418474
[ Info: iteration 7, average log likelihood -1.418317
[ Info: iteration 8, average log likelihood -1.418151
[ Info: iteration 9, average log likelihood -1.417994
[ Info: iteration 10, average log likelihood -1.417856
[ Info: iteration 11, average log likelihood -1.417744
[ Info: iteration 12, average log likelihood -1.417656
[ Info: iteration 13, average log likelihood -1.417589
[ Info: iteration 14, average log likelihood -1.417538
[ Info: iteration 15, average log likelihood -1.417498
[ Info: iteration 16, average log likelihood -1.417467
[ Info: iteration 17, average log likelihood -1.417441
[ Info: iteration 18, average log likelihood -1.417420
[ Info: iteration 19, average log likelihood -1.417401
[ Info: iteration 20, average log likelihood -1.417385
[ Info: iteration 21, average log likelihood -1.417371
[ Info: iteration 22, average log likelihood -1.417358
[ Info: iteration 23, average log likelihood -1.417346
[ Info: iteration 24, average log likelihood -1.417334
[ Info: iteration 25, average log likelihood -1.417324
[ Info: iteration 26, average log likelihood -1.417314
[ Info: iteration 27, average log likelihood -1.417305
[ Info: iteration 28, average log likelihood -1.417296
[ Info: iteration 29, average log likelihood -1.417288
[ Info: iteration 30, average log likelihood -1.417280
[ Info: iteration 31, average log likelihood -1.417273
[ Info: iteration 32, average log likelihood -1.417266
[ Info: iteration 33, average log likelihood -1.417260
[ Info: iteration 34, average log likelihood -1.417254
[ Info: iteration 35, average log likelihood -1.417249
[ Info: iteration 36, average log likelihood -1.417244
[ Info: iteration 37, average log likelihood -1.417240
[ Info: iteration 38, average log likelihood -1.417235
[ Info: iteration 39, average log likelihood -1.417232
[ Info: iteration 40, average log likelihood -1.417228
[ Info: iteration 41, average log likelihood -1.417225
[ Info: iteration 42, average log likelihood -1.417222
[ Info: iteration 43, average log likelihood -1.417219
[ Info: iteration 44, average log likelihood -1.417217
[ Info: iteration 45, average log likelihood -1.417214
[ Info: iteration 46, average log likelihood -1.417212
[ Info: iteration 47, average log likelihood -1.417210
[ Info: iteration 48, average log likelihood -1.417208
[ Info: iteration 49, average log likelihood -1.417207
[ Info: iteration 50, average log likelihood -1.417205
┌ Info: EM with 100000 data points 50 iterations avll -1.417205
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4189571138650507
│     -1.4188803183756578
│      ⋮                 
└     -1.4172049934641877
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417214
[ Info: iteration 2, average log likelihood -1.417161
[ Info: iteration 3, average log likelihood -1.417116
[ Info: iteration 4, average log likelihood -1.417065
[ Info: iteration 5, average log likelihood -1.417003
[ Info: iteration 6, average log likelihood -1.416929
[ Info: iteration 7, average log likelihood -1.416841
[ Info: iteration 8, average log likelihood -1.416743
[ Info: iteration 9, average log likelihood -1.416640
[ Info: iteration 10, average log likelihood -1.416536
[ Info: iteration 11, average log likelihood -1.416437
[ Info: iteration 12, average log likelihood -1.416345
[ Info: iteration 13, average log likelihood -1.416263
[ Info: iteration 14, average log likelihood -1.416191
[ Info: iteration 15, average log likelihood -1.416128
[ Info: iteration 16, average log likelihood -1.416073
[ Info: iteration 17, average log likelihood -1.416025
[ Info: iteration 18, average log likelihood -1.415983
[ Info: iteration 19, average log likelihood -1.415945
[ Info: iteration 20, average log likelihood -1.415911
[ Info: iteration 21, average log likelihood -1.415880
[ Info: iteration 22, average log likelihood -1.415851
[ Info: iteration 23, average log likelihood -1.415823
[ Info: iteration 24, average log likelihood -1.415797
[ Info: iteration 25, average log likelihood -1.415773
[ Info: iteration 26, average log likelihood -1.415749
[ Info: iteration 27, average log likelihood -1.415725
[ Info: iteration 28, average log likelihood -1.415703
[ Info: iteration 29, average log likelihood -1.415681
[ Info: iteration 30, average log likelihood -1.415659
[ Info: iteration 31, average log likelihood -1.415639
[ Info: iteration 32, average log likelihood -1.415619
[ Info: iteration 33, average log likelihood -1.415599
[ Info: iteration 34, average log likelihood -1.415581
[ Info: iteration 35, average log likelihood -1.415563
[ Info: iteration 36, average log likelihood -1.415546
[ Info: iteration 37, average log likelihood -1.415529
[ Info: iteration 38, average log likelihood -1.415514
[ Info: iteration 39, average log likelihood -1.415499
[ Info: iteration 40, average log likelihood -1.415485
[ Info: iteration 41, average log likelihood -1.415472
[ Info: iteration 42, average log likelihood -1.415459
[ Info: iteration 43, average log likelihood -1.415448
[ Info: iteration 44, average log likelihood -1.415436
[ Info: iteration 45, average log likelihood -1.415426
[ Info: iteration 46, average log likelihood -1.415416
[ Info: iteration 47, average log likelihood -1.415407
[ Info: iteration 48, average log likelihood -1.415398
[ Info: iteration 49, average log likelihood -1.415390
[ Info: iteration 50, average log likelihood -1.415381
┌ Info: EM with 100000 data points 50 iterations avll -1.415381
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4172135504166399
│     -1.4171607824478456
│      ⋮                 
└     -1.41538144427789  
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415382
[ Info: iteration 2, average log likelihood -1.415319
[ Info: iteration 3, average log likelihood -1.415257
[ Info: iteration 4, average log likelihood -1.415184
[ Info: iteration 5, average log likelihood -1.415092
[ Info: iteration 6, average log likelihood -1.414977
[ Info: iteration 7, average log likelihood -1.414841
[ Info: iteration 8, average log likelihood -1.414692
[ Info: iteration 9, average log likelihood -1.414539
[ Info: iteration 10, average log likelihood -1.414389
[ Info: iteration 11, average log likelihood -1.414248
[ Info: iteration 12, average log likelihood -1.414118
[ Info: iteration 13, average log likelihood -1.414000
[ Info: iteration 14, average log likelihood -1.413892
[ Info: iteration 15, average log likelihood -1.413795
[ Info: iteration 16, average log likelihood -1.413708
[ Info: iteration 17, average log likelihood -1.413629
[ Info: iteration 18, average log likelihood -1.413559
[ Info: iteration 19, average log likelihood -1.413496
[ Info: iteration 20, average log likelihood -1.413439
[ Info: iteration 21, average log likelihood -1.413388
[ Info: iteration 22, average log likelihood -1.413342
[ Info: iteration 23, average log likelihood -1.413299
[ Info: iteration 24, average log likelihood -1.413259
[ Info: iteration 25, average log likelihood -1.413222
[ Info: iteration 26, average log likelihood -1.413188
[ Info: iteration 27, average log likelihood -1.413155
[ Info: iteration 28, average log likelihood -1.413125
[ Info: iteration 29, average log likelihood -1.413096
[ Info: iteration 30, average log likelihood -1.413068
[ Info: iteration 31, average log likelihood -1.413041
[ Info: iteration 32, average log likelihood -1.413016
[ Info: iteration 33, average log likelihood -1.412992
[ Info: iteration 34, average log likelihood -1.412968
[ Info: iteration 35, average log likelihood -1.412946
[ Info: iteration 36, average log likelihood -1.412924
[ Info: iteration 37, average log likelihood -1.412904
[ Info: iteration 38, average log likelihood -1.412884
[ Info: iteration 39, average log likelihood -1.412865
[ Info: iteration 40, average log likelihood -1.412846
[ Info: iteration 41, average log likelihood -1.412828
[ Info: iteration 42, average log likelihood -1.412811
[ Info: iteration 43, average log likelihood -1.412795
[ Info: iteration 44, average log likelihood -1.412779
[ Info: iteration 45, average log likelihood -1.412764
[ Info: iteration 46, average log likelihood -1.412749
[ Info: iteration 47, average log likelihood -1.412735
[ Info: iteration 48, average log likelihood -1.412722
[ Info: iteration 49, average log likelihood -1.412709
[ Info: iteration 50, average log likelihood -1.412696
┌ Info: EM with 100000 data points 50 iterations avll -1.412696
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4153819740617095
│     -1.4153186156642519
│      ⋮                 
└     -1.4126961763200634
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4256710048106496
│     -1.4256919252913496
│     -1.4256062642391214
│     -1.425526304993986 
│      ⋮                 
│     -1.412721841009552 
│     -1.4127087857349723
└     -1.4126961763200634
32×26 Array{Float64,2}:
  0.317143     0.236372     0.193522    0.0938385     0.77543      0.703674    0.113696    0.180045   -0.0598572    0.404281     -0.725811    0.15396     -0.158053    -0.133286    -0.0530578   -0.418185     0.380579    -0.313348    0.030729    0.246376     -0.600781   -0.180224    -0.179051     -0.258252     0.287481   -0.43908  
  1.21931      0.105637    -0.175056    0.0582545    -0.414948     0.253713    0.180969    0.215075   -0.179254     0.181296      0.510265   -0.261236    -0.14766      0.221674    -0.402982    -0.395736     0.0190441   -0.140611    0.166229    0.563224      0.301386   -0.00630945  -0.182052     -0.100808    -0.135079    0.342943 
  0.295951     0.592269    -0.0800064  -0.225528      0.336215     0.0619342   0.439025   -0.0268631  -0.703435     0.0937503     0.0420164  -0.419092    -0.00880336  -0.386144     0.415345    -0.7796      -0.188288     0.81138     0.215025    0.175953      0.124092    0.00770405  -0.967277     -0.161276     1.05894    -0.279737 
 -0.0902294   -0.0839108    0.0732167  -0.126395     -0.154653     0.0608042   0.140797    0.236866   -0.707775     0.166569     -0.487616   -0.365994     0.282956    -0.335438     0.717713    -0.614093     0.342827     0.487543    0.613743   -0.0648818     0.433025   -0.0892821    0.512773      0.0846982    0.128917   -0.141811 
 -0.266418    -0.904566     0.279515    0.125804      0.018413     0.350439    0.194699    0.0625831  -0.0107961    0.200865     -0.729275   -0.224793    -0.0159738    0.443927     0.0323134    0.616654    -0.0355779   -0.100271   -0.0326823  -0.274336      0.741232    0.338815     0.39233       0.397709    -0.506296   -0.0189848
 -0.176794     0.00818179   0.0134242  -0.593034      0.0619184    0.248632    0.200676    0.334101   -0.130291    -0.306541     -0.716312   -0.0623861    0.086836     0.46495      0.564041     1.10029      0.43314     -0.0905624  -0.606394   -1.0706        0.0315749   0.296269    -0.23354       0.0331492   -9.2949e-5  -0.57411  
  0.0509781   -0.380762     0.529689   -0.131473      0.00161801  -0.430119    0.155481    0.194773    0.00756057  -0.138424      0.603319    0.102121    -0.211444    -0.507044    -0.597703     0.633101    -0.301425    -0.0722722  -0.689123   -0.27676       0.213025   -0.164845     0.156792     -0.335339    -0.413248    0.124736 
  0.20927     -0.235303     0.218985   -0.448941     -0.129869    -0.178074    0.206332    0.17905    -0.564679     0.828053      0.240732    0.196883    -0.204359    -0.16746     -0.127693     0.501533     0.492692     0.16518    -0.418862   -1.18858       0.260632    0.807428     0.000118142  -0.233721     0.0933203   0.374396 
 -0.465899    -0.365284    -0.0255936  -0.393051      0.0516507    0.341431   -0.472709   -0.0418057   0.537606    -0.354644     -0.601242   -0.0730905    0.0272042   -0.140338     0.820908    -0.261452    -0.275059    -0.0977583   0.794347    0.95929      -0.18881    -0.0558842   -0.402626      0.00775866  -0.568183    0.0673037
 -0.320706    -0.207397     0.144081   -0.320489      0.739358    -0.577156    0.0784282  -0.0843396   0.266795    -0.877318     -0.514393    0.108038     0.32421     -0.42227      0.739987     0.196943    -0.144411     0.471928   -0.602985    0.294516     -0.226052    0.20136     -0.0228338    -0.333591     0.208462   -0.123293 
 -0.78587      0.508845     0.043395    0.28059       0.120074     0.0691706  -0.215139   -0.776013    0.0973924   -0.237546      0.024645    0.32576      0.694686     0.462541    -0.207615     0.108783    -0.396538    -0.251806    0.0308447  -0.0937733    -0.415649   -0.11529     -0.0988867    -0.286302     0.0631695  -0.449709 
 -0.117082     0.835411    -0.364437    0.375441     -0.00468457   0.122902    0.163923   -0.488491   -0.0272763   -0.337971      0.555338    0.673283    -0.00230991  -0.102035    -0.196033    -0.0832894    0.739773     0.368702    0.0854959  -0.198651     -0.279791   -0.383065     0.0116304    -0.525882    -0.516388    0.220873 
 -0.519188    -0.109669     0.263222   -0.426339     -0.186547    -0.34274    -0.325063    0.284535    0.348916    -0.124395      0.711712    0.219187    -0.135306     0.200742     0.148314     0.514688    -0.0919506   -0.187476    0.144697   -0.189628      0.0670233  -0.800434     0.545242      0.699457    -0.661432   -0.0270794
 -0.116913    -0.132679    -0.12595     0.247709     -0.21936     -0.367668   -0.0506455  -0.246422    0.133734     0.0357813     0.230039   -0.0198591    0.100293    -0.0470932    0.0219499   -0.0740698   -0.2183       0.0219105   0.0427454   0.000918851   0.0283518   0.0159793   -0.206424      0.287071     0.3041      0.199901 
 -0.32806     -0.141588    -0.583845   -0.220053      0.303319    -0.305644   -0.225368   -0.334997    0.135252     0.0165945     0.236339   -0.128791    -0.0278887   -0.097434    -0.728716    -0.122957    -0.0295757    0.236756   -0.124839    0.646274      0.227128    0.170786     0.609907     -0.922903     0.164852   -0.142376 
  0.329876     0.0780102   -0.456162   -0.338803     -0.217792    -0.43761    -0.723008   -0.351615    0.572827     0.276286      0.430573    0.440078     0.0829116   -0.374203    -0.223749    -0.102977     0.00469474  -0.0117087  -0.468483    0.423247     -0.371036   -0.453931    -0.30811      -0.18762      0.727783    0.142634 
 -0.0024125    0.0510164   -0.374984    0.0429712     0.111506    -0.745638   -0.217714   -0.640532   -0.213905     0.407827     -0.0919901  -0.131237     0.144796    -0.133836    -0.0664112    0.0841507    0.0892139    0.101455    0.0203993   0.0998405     0.327765    0.909811    -0.19517      -0.0338282    0.314098    0.307717 
  0.176674     0.181671    -0.465195    0.000147413   0.100741     0.554424   -0.188552   -0.360356   -0.488358     0.644442     -0.886508    0.12552      0.13913      0.122022     0.0476555   -0.206872     0.0895262   -0.240192    0.524275   -0.0165933     0.198176    0.670371    -0.220831      0.0902323    0.337792    0.137061 
  0.0984406    0.241927    -0.145338    0.182435     -0.126556    -0.0765112   0.0640993  -0.229942   -0.160633     0.0349479     0.161924    0.0610884    0.0224607   -0.079427     0.027032    -0.393076     0.0775655    0.063227    0.171727    0.15374      -0.161265   -0.164284    -0.0494145    -0.0779816    0.063499    0.11208  
  0.109255     0.105698     0.0578572   0.134521     -0.0881607   -0.0062416   0.121092   -0.0433512  -0.256874     0.010688      0.0716306   0.15234     -0.103468    -0.147491    -0.338385     0.413608    -0.0700342    0.203474   -0.132792   -0.282122      0.263355    0.16728      0.000344231  -0.151       -0.032531    0.0735766
  0.699636    -0.384743     0.223098   -0.198813     -0.183418     0.160947   -0.180967    0.434823   -0.14507      0.43636      -0.10191    -0.376267    -0.741559    -0.346168    -0.0270218    0.0977457    0.372926     0.0621093   0.137342    0.112467      0.335639    0.244239    -0.173663      0.3732      -0.184333    0.378838 
  0.466249    -0.232152    -0.221605   -0.436422      0.161982     0.0783741   0.201063    0.608621    0.130636     0.000866778   0.0520998   0.244357    -0.36644     -0.332881    -0.00133984  -0.012605    -0.0239495    0.0687037  -0.0552786   0.522342      0.137586   -0.113039     0.441709     -0.0852733   -0.369667    0.178154 
 -0.377798    -0.303297     0.333732   -0.390263      0.310787     0.159276   -0.297813   -0.0731013  -0.503737     0.337723     -0.335393   -0.233563     0.275737    -0.4312      -0.288017    -0.0605898   -0.146005     0.28482     0.309504    0.0964512     0.0898859   0.0658214    0.283677     -0.54286      0.0372157  -0.370941 
 -0.310552    -0.256367     0.132834   -0.242769      0.156001    -0.0218825   0.100997    0.173876   -0.127142    -0.0002389    -0.209406   -0.0872466    0.114166     0.0263954    0.559711     0.00898011  -0.011076    -0.0612373   0.193095   -0.220303      0.254446    0.0870886    0.122059      0.260231    -0.0430858  -0.136908 
 -0.140178    -0.259009    -0.0967902  -0.119727      0.111407     0.171363   -0.239735   -0.0223259   0.570735    -0.0023686    -0.0425513   0.157477    -0.0528406    0.390307    -0.152013     0.400381    -0.0966822   -0.268489   -0.336786   -0.0471789    -0.13564     0.0609843   -0.127323      0.0930314    0.0281585  -0.149327 
 -0.0769478   -0.122456    -0.335454    0.175928      0.231758    -0.234175    0.171964    0.0462135   0.475335    -0.042702      0.734578    0.118639    -0.264113     0.725044    -0.162552     0.146225    -0.36935     -0.90165    -0.0485939   0.191478     -0.379502    0.188386     0.0147762     0.0817242   -0.100623   -0.0816828
 -0.380415     0.100446     0.24531     0.242014      0.2804      -0.486452    0.208198   -0.0377543   0.657376    -0.346615      0.467154    0.159574     0.141219     0.00368927  -0.0315508   -0.138756    -0.155356     0.327293   -0.187669    0.13251      -0.367125   -0.498494     0.0636143     0.0867775    0.189716   -0.224407 
  0.28333      0.033632     0.0889504   0.0341396     0.238033     0.28929     0.279751    0.314787   -0.217868    -0.285751     -0.0462923  -0.289438     0.285803     0.508546     0.0556114   -0.0741521    0.385653    -0.02365    -0.0999457   0.309805     -0.408806   -0.175032     0.201888     -0.60669     -0.115677   -0.364478 
 -0.00677518   0.110925     0.232935    0.143224     -0.392009     0.141906   -0.35273    -0.205921   -0.00581223  -0.145085     -0.263907   -0.12909      0.0154547   -0.1145       0.0981106   -0.183339     8.17767e-5  -0.0130683   0.20607    -0.0357342    -0.562248   -0.461533    -0.997436      0.380392    -0.0312525   0.302712 
 -0.245094     0.101526    -0.0211822   0.0954948    -0.41528     -0.340561   -0.163398   -0.465218    0.11255     -0.0515575     0.1464      0.40301      0.125578    -0.125039     0.246558     0.132353    -0.498741    -0.0885094   0.198051   -0.0316929     0.55387    -0.157485    -0.0161342     0.797445    -0.0758466   0.334116 
  0.214778     0.105255     0.248178    0.526867     -0.54347      0.144847    0.366923    0.307629   -0.230545    -0.0265183     0.116385   -0.00605453  -0.231527     0.282916     0.267362    -0.209907    -0.00835614  -0.283191    0.0140078  -0.862719      0.0402105  -0.306132    -0.0996126     0.783028     0.0603392   0.0778359
  0.581474     0.382097     0.149576    0.575281     -0.158365     0.373891    0.693666    0.0943571   0.317472    -0.315484     -0.220816    0.35776     -0.455381     0.344414    -0.324999     1.08261     -0.440328    -0.105116   -0.810592   -0.280409      0.129621    0.104375    -0.191835      0.515092    -0.103764   -0.0533184[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412684
[ Info: iteration 2, average log likelihood -1.412672
[ Info: iteration 3, average log likelihood -1.412661
[ Info: iteration 4, average log likelihood -1.412650
[ Info: iteration 5, average log likelihood -1.412639
[ Info: iteration 6, average log likelihood -1.412628
[ Info: iteration 7, average log likelihood -1.412618
[ Info: iteration 8, average log likelihood -1.412608
[ Info: iteration 9, average log likelihood -1.412598
[ Info: iteration 10, average log likelihood -1.412589
┌ Info: EM with 100000 data points 10 iterations avll -1.412589
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians LinearAlgebra.diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.323728e+05
      1       7.038412e+05      -2.285316e+05 |       32
      2       6.918067e+05      -1.203450e+04 |       32
      3       6.866373e+05      -5.169443e+03 |       32
      4       6.840220e+05      -2.615301e+03 |       32
      5       6.823147e+05      -1.707237e+03 |       32
      6       6.810641e+05      -1.250600e+03 |       32
      7       6.800629e+05      -1.001285e+03 |       32
      8       6.792587e+05      -8.041484e+02 |       32
      9       6.785310e+05      -7.277103e+02 |       32
     10       6.779226e+05      -6.084150e+02 |       32
     11       6.774366e+05      -4.859679e+02 |       32
     12       6.770307e+05      -4.058670e+02 |       32
     13       6.766901e+05      -3.406611e+02 |       32
     14       6.763886e+05      -3.015284e+02 |       32
     15       6.761105e+05      -2.780137e+02 |       32
     16       6.758602e+05      -2.503046e+02 |       32
     17       6.756369e+05      -2.233398e+02 |       32
     18       6.754463e+05      -1.906273e+02 |       32
     19       6.752500e+05      -1.962597e+02 |       32
     20       6.750687e+05      -1.812641e+02 |       32
     21       6.749043e+05      -1.644360e+02 |       32
     22       6.747582e+05      -1.460852e+02 |       32
     23       6.746168e+05      -1.414657e+02 |       32
     24       6.744863e+05      -1.304982e+02 |       32
     25       6.743743e+05      -1.119408e+02 |       32
     26       6.742679e+05      -1.064435e+02 |       32
     27       6.741618e+05      -1.060603e+02 |       32
     28       6.740635e+05      -9.829144e+01 |       32
     29       6.739741e+05      -8.937847e+01 |       32
     30       6.738890e+05      -8.514890e+01 |       32
     31       6.738167e+05      -7.225374e+01 |       32
     32       6.737452e+05      -7.158719e+01 |       32
     33       6.736696e+05      -7.557579e+01 |       32
     34       6.735878e+05      -8.181884e+01 |       32
     35       6.735154e+05      -7.234111e+01 |       32
     36       6.734559e+05      -5.947722e+01 |       32
     37       6.733966e+05      -5.936856e+01 |       32
     38       6.733511e+05      -4.549677e+01 |       32
     39       6.733073e+05      -4.373150e+01 |       32
     40       6.732610e+05      -4.637677e+01 |       32
     41       6.732138e+05      -4.721015e+01 |       32
     42       6.731680e+05      -4.575222e+01 |       32
     43       6.731265e+05      -4.149356e+01 |       32
     44       6.730960e+05      -3.056365e+01 |       32
     45       6.730693e+05      -2.664510e+01 |       32
     46       6.730451e+05      -2.424017e+01 |       32
     47       6.730183e+05      -2.675508e+01 |       32
     48       6.729963e+05      -2.204345e+01 |       32
     49       6.729773e+05      -1.896360e+01 |       32
     50       6.729593e+05      -1.795937e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672959.3434042213)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423994
[ Info: iteration 2, average log likelihood -1.419120
[ Info: iteration 3, average log likelihood -1.417866
[ Info: iteration 4, average log likelihood -1.416969
[ Info: iteration 5, average log likelihood -1.416014
[ Info: iteration 6, average log likelihood -1.415069
[ Info: iteration 7, average log likelihood -1.414347
[ Info: iteration 8, average log likelihood -1.413909
[ Info: iteration 9, average log likelihood -1.413662
[ Info: iteration 10, average log likelihood -1.413509
[ Info: iteration 11, average log likelihood -1.413401
[ Info: iteration 12, average log likelihood -1.413317
[ Info: iteration 13, average log likelihood -1.413246
[ Info: iteration 14, average log likelihood -1.413186
[ Info: iteration 15, average log likelihood -1.413132
[ Info: iteration 16, average log likelihood -1.413084
[ Info: iteration 17, average log likelihood -1.413041
[ Info: iteration 18, average log likelihood -1.413002
[ Info: iteration 19, average log likelihood -1.412966
[ Info: iteration 20, average log likelihood -1.412933
[ Info: iteration 21, average log likelihood -1.412902
[ Info: iteration 22, average log likelihood -1.412874
[ Info: iteration 23, average log likelihood -1.412847
[ Info: iteration 24, average log likelihood -1.412822
[ Info: iteration 25, average log likelihood -1.412798
[ Info: iteration 26, average log likelihood -1.412775
[ Info: iteration 27, average log likelihood -1.412754
[ Info: iteration 28, average log likelihood -1.412733
[ Info: iteration 29, average log likelihood -1.412714
[ Info: iteration 30, average log likelihood -1.412695
[ Info: iteration 31, average log likelihood -1.412677
[ Info: iteration 32, average log likelihood -1.412660
[ Info: iteration 33, average log likelihood -1.412643
[ Info: iteration 34, average log likelihood -1.412627
[ Info: iteration 35, average log likelihood -1.412611
[ Info: iteration 36, average log likelihood -1.412596
[ Info: iteration 37, average log likelihood -1.412581
[ Info: iteration 38, average log likelihood -1.412566
[ Info: iteration 39, average log likelihood -1.412553
[ Info: iteration 40, average log likelihood -1.412539
[ Info: iteration 41, average log likelihood -1.412526
[ Info: iteration 42, average log likelihood -1.412513
[ Info: iteration 43, average log likelihood -1.412501
[ Info: iteration 44, average log likelihood -1.412489
[ Info: iteration 45, average log likelihood -1.412478
[ Info: iteration 46, average log likelihood -1.412467
[ Info: iteration 47, average log likelihood -1.412456
[ Info: iteration 48, average log likelihood -1.412445
[ Info: iteration 49, average log likelihood -1.412435
[ Info: iteration 50, average log likelihood -1.412425
┌ Info: EM with 100000 data points 50 iterations avll -1.412425
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.569044    0.51024     -0.468428    0.135322   -0.651339    -0.145863      0.206458    -0.302231   -0.0266036  -0.189152    0.549856     0.326664   -0.0218841  -0.285613     0.105175    -0.18507    -0.0139159   0.101961    -0.0835431    0.306626    0.0832496   -0.441919   -0.0986674   -0.0621831  -0.171274    0.49825    
  0.701649   -0.631085     0.1648     -0.331817    0.134615    -0.0168713     0.0101732    0.673584    0.336634    0.10886     0.100702    -0.245521   -0.740926   -0.405197    -0.00339705   0.0141105   0.293239    0.171018    -0.00289223   0.267866    0.345417     0.0860003   0.127189     0.426105   -0.255414    0.291005   
 -0.545352    0.232302    -0.506747   -0.127131   -0.063652    -0.0175081    -0.269544    -0.173411   -0.308158   -0.130702   -0.547273     0.0498907   0.383927    0.146632     0.904821    -0.6626      1.10676     0.123365     0.797374    -0.205765    0.08731     -0.0270758   0.141656    -0.236141    0.23128     0.220385   
  0.635598    0.168516    -0.406069   -0.260743   -0.48506      0.230218     -0.144118     0.039921   -0.313198    0.744015    0.378648    -0.304705   -0.0530783   0.653376    -0.751944    -0.0634205  -0.0187883  -0.359722     0.688566    -0.0596467   0.402569     0.375604    0.0656379    0.0565636  -0.0159185   0.615967   
 -0.118135   -0.00925683   0.0884115  -0.391576    0.193982     0.135361      0.253261     0.211471   -0.121579   -0.169958   -0.626404     0.105316    0.114639    0.258363     0.421682     1.14882     0.316565    0.00384707  -0.69682     -0.943586   -0.00507811   0.490173   -0.285458    -0.014457    0.037337   -0.318466   
  0.145186   -0.0296716   -0.279617   -0.42636    -0.0159442   -0.380342     -0.720513    -0.173524    0.566355    0.200148    0.420365     0.190597   -0.0774554  -0.415952    -0.411335    -0.139961    0.0263417   0.0824224   -0.480341     0.597112   -0.305435    -0.592423   -0.0811157   -0.321188    0.546288    0.134493   
  0.0423344   0.107105     0.186369    0.0898028  -0.211983     0.056498      0.0885427    0.0418438  -0.241761   -0.141935   -0.0108357   -0.163595    0.0356725  -0.059073     0.231104    -0.214779    0.126497    0.252336     0.0838086   -0.167507   -0.255219    -0.249605   -0.333872    -0.0297411   0.0781033  -0.0549575  
 -0.113905    0.645434     0.181999    0.344095    0.490742     0.000565355  -0.138062    -0.518225    0.295619   -0.0687163  -0.0742024    0.200023    0.385487    0.369575    -0.193857    -0.286682    0.199133    0.211727     0.11514      0.218754   -0.596316    -0.174728   -0.504353     0.039151    0.387138   -0.47047    
  0.0822711  -0.0198935   -0.0340434  -0.0986457  -0.113576    -0.913424      0.343931     0.0348263  -0.0818483  -0.325701    0.943535    -0.367715    0.170197    0.20499      0.0204145    0.352274   -0.0824539   0.375203    -0.444562    -0.240833    0.568964     0.292389    0.450718    -0.0935627   0.0981048   0.169089   
 -0.256324    0.55086      0.18254     0.122096    0.262146    -0.00305331    0.0504152   -0.167018    0.14902    -0.403624    0.622902     0.670107   -0.178598   -0.235114    -0.58332      0.297433    0.412594    0.2033      -0.220511    -0.184931   -0.367903    -0.384317    0.102953    -0.744492   -0.880395    0.0162059  
  0.565607    0.105956     0.327501    0.485003   -0.00998975   0.175758      0.61136      0.185722    0.404016   -0.0793044   0.376268     0.198005   -0.533072    0.205677    -0.667884     0.773224   -0.760631   -0.305089    -0.698851    -0.248757    0.0522524    0.0603686  -0.144298     0.50817    -0.135525   -0.27248    
 -0.564032    0.0658081   -0.611933    0.447867    0.124704    -0.216473      0.388295    -0.511885    0.44614    -0.331245    0.197169     0.348972    0.44882     0.441674     0.0207545   -0.16308    -0.272016   -0.177888    -0.182559    -0.0913846  -0.310674    -0.189713    0.481477    -0.227785    0.558301   -0.114306   
 -0.62965     0.162109    -0.258578    0.165541   -0.233914    -0.0383861    -0.606419    -0.664964    0.0321238   0.0863179   0.128762     0.302995    0.103778    0.303303    -0.366903     0.496028   -0.353007   -0.420052    -0.04372     -0.308646   -0.0819749    0.307098   -0.267157    -0.0102895   0.0914491  -0.200721   
  0.220647    0.139775     0.144234   -0.100808    0.866026     0.236144      0.426528     0.453083   -0.0528022  -0.0431495   0.0441386   -0.284823    0.0616092   0.359374    -0.00436224  -0.0225376   0.251682   -0.149338    -0.030881     0.283893   -0.746758    -0.28418     0.349656    -0.574618   -0.0050155  -0.459298   
  0.518605   -0.235283    -0.0680682   0.645433   -0.0758413    0.011458     -0.0424001    0.018472   -0.345564   -0.234072   -0.101486    -0.185423    0.0590982   0.695214    -0.533023    -0.121632    0.41131    -0.0769613   -0.683662     0.899742    0.221716     0.228003    0.0267101   -1.05349    -0.32093    -0.149362   
  0.445538    0.413226    -0.12789     0.149535    0.241479     0.508022      0.371464    -0.0103352  -0.487097    0.292138   -0.362332    -0.0372163   0.0188817  -0.154705     0.136491    -0.70977     0.0868154   0.167182     0.296964     0.11772    -0.03045      0.102117   -0.42915     -0.145796    0.538402   -0.228807   
  0.443031   -0.392325    -0.0149897  -0.23037    -0.485667     0.12242       0.0695579    0.176395   -0.614028    0.516153    0.156958     0.173884   -0.427225   -0.780801    -0.447209     0.242584    0.360568    0.155168    -0.290419    -0.73666     0.159502     0.315755   -0.089391    -0.326838    0.0404825   0.597174   
 -0.460761   -0.44458      0.267515    0.443526   -0.0921226    0.248005     -0.400498    -0.130815    0.114935    0.0585554  -0.708249    -1.11945     0.0419189  -0.0683719   -0.288408    -0.0377315  -0.157826    0.335601    -0.350171    -0.482965   -0.0931053   -0.118102   -0.634673     1.03509     0.406056    0.412361   
 -0.305953   -0.252291     0.0572674  -0.142499    0.567078    -0.355707     -0.170333    -0.203964    0.377783   -0.238286   -0.129166     0.0836983   0.180731   -0.160428     0.120274     0.182696   -0.233928   -0.0442556   -0.25793      0.428259   -0.153193     0.116881    0.00679372  -0.196043    0.0660984  -0.168911   
 -0.512407   -0.368214     0.0530872  -0.0668924  -0.739156    -0.0979102    -0.243737    -0.269182    0.253725    0.419577    0.00895278   0.44624    -0.0744468   0.222537    -0.028342     0.750256   -0.142092   -0.165715     0.107682    -0.457893    0.518613    -0.141004    0.378198     0.609825   -0.514563    0.000517629
 -0.350731   -0.660024     0.389264   -0.0827779   0.454454     0.409864      0.377925     0.303157   -0.274868    0.0234661  -0.565134    -0.367441    0.0524339   0.535157     0.150718     0.436681    0.129739   -0.160423     0.0884165   -0.300306    0.574384     0.238534    0.620764     0.158369   -0.513689   -0.252953   
 -0.0218278  -0.206875    -0.0945292  -0.17995     0.132072    -0.0448048    -0.0288948    0.0932641   0.470487   -0.0630814   0.171252     0.146086   -0.0958404   0.180133    -0.0152467    0.176071   -0.111943   -0.245724    -0.13721      0.183253   -0.0718884   -0.0347735   0.00135636   0.0508439  -0.126115    0.00877369 
  0.398931    0.104857     0.0611507   0.550318   -0.668758     0.277915      0.196945     0.176623    0.0445207  -0.16149     0.0970417    0.165516   -0.239251    0.69842      0.392381    -0.060572    0.148077   -0.486113    -0.0151276   -0.569205   -0.0419845   -0.279596   -0.349888     0.876766   -0.16946     0.354834   
  0.0652874   0.00915167   0.106534    0.147857   -0.0737552    0.0608425     0.222659     0.182748   -0.302032    0.0568513  -0.0204606    0.152463   -0.0664924   0.017686    -0.11686      0.110435   -0.0847009   0.0434476    0.00586365  -0.331025    0.338069    -0.0147694   0.355074     0.141974   -0.0670117  -0.0184348  
  0.22304    -0.0299789   -0.372578   -0.174677    0.203805    -0.062929     -0.0735711   -0.211572   -0.327087    0.473311   -0.277616    -0.140372   -0.0655363  -0.196969    -0.106698     0.0274039   0.195764    0.120625     0.189679     0.243746    0.254958     0.685848   -0.0672326   -0.270577    0.263053    0.0912796  
 -0.072578   -0.248866    -0.22999    -0.462014   -0.216083     0.678495     -0.387233     0.234319    0.253652   -0.238628   -0.549388    -0.384301    0.0692186  -0.00396959   0.808374    -0.385062   -0.175902   -0.0850489    0.726939     1.02675    -0.159741    -0.155792    0.0244116    0.0859247  -0.313414   -0.166161   
 -0.350614    0.186657    -0.0566299   0.428352   -0.0624703   -0.618182     -0.0672819   -0.255975    0.219985    0.0873603   0.729869    -0.0361925   0.103166   -0.168287    -0.335811    -0.802135   -0.636495   -0.0370394    0.800311     0.980538   -0.397842    -0.470421   -0.274178     0.241296   -0.245345    0.399246   
 -0.538974   -0.0264891    0.435675   -0.260159   -0.118102    -0.389129      0.00935844   0.21682     0.286466   -0.57888     0.334099     0.338266    0.0887336  -0.0852606    0.668072     0.224152   -0.45835    -0.0480342    0.00970974  -0.217661   -0.175642    -0.690314   -0.0966161    0.601544   -0.185398   -0.122972   
  0.272389   -0.221517     0.419635   -0.131422   -0.454823    -0.00393329    0.0888737    0.4351     -1.03749     0.490485   -0.331703    -0.797783   -0.136913   -0.380566     0.516627    -0.274311   -0.0973544   0.0305758    0.427611    -0.199115    0.368322     0.0115062  -0.0236833    0.251775    0.0743916  -0.173412   
 -0.352722    0.0834159    0.220021    0.500907    0.0598096   -0.517376      0.0616193   -0.502487   -0.286816    0.280693   -0.229875     0.335161    0.123373   -0.646358     0.174671    -0.174353   -0.163582    0.449065     0.0564535   -0.18106     0.563854     0.184752    0.0404959    0.566353    0.311687    0.337005   
  0.315315    0.00557811   0.338962   -0.06163     0.0560968    0.343834     -0.365046    -0.30035    -0.0681938   0.322292   -0.831999     0.452273   -0.0452163  -0.242088     0.217641    -0.109797   -0.132836   -0.411807     0.496387     0.110881   -0.115245     0.228011   -0.707541     0.388176   -0.334213    0.236135   
 -0.522623   -0.310209     0.212284   -0.626824    0.398384     0.0432235    -0.24275     -0.196782   -0.263758    0.0260943  -0.225035    -0.141567    0.491693   -0.475672    -0.108216    -0.0687905  -0.228204    0.371981     0.174687     0.244186    0.223601     0.0494361   0.328686    -0.618137   -0.0352778  -0.390264   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412416
[ Info: iteration 2, average log likelihood -1.412406
[ Info: iteration 3, average log likelihood -1.412397
[ Info: iteration 4, average log likelihood -1.412388
[ Info: iteration 5, average log likelihood -1.412380
[ Info: iteration 6, average log likelihood -1.412371
[ Info: iteration 7, average log likelihood -1.412363
[ Info: iteration 8, average log likelihood -1.412355
[ Info: iteration 9, average log likelihood -1.412347
[ Info: iteration 10, average log likelihood -1.412339
┌ Info: EM with 100000 data points 10 iterations avll -1.412339
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians LinearAlgebra.diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
